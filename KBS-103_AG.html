<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>KBS-103 - Kubernetes administration &mdash; KBS-103 1.29 rev9 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            KBS-103
          </a>
              <div class="version">
                1.29
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">KBS-103 - Kubernetes administration</a><ul>
<li><a class="reference internal" href="#lab-1-health-check-the-kubernetes-environment">Lab 1:  Health check the Kubernetes environment</a><ul>
<li><a class="reference internal" href="#task-1-health-check">Task 1:  Health check</a></li>
<li><a class="reference internal" href="#task-2-observe-the-components-of-the-kubernetes-cluster">Task 2:  Observe the components of the Kubernetes cluster</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-2-accessing-the-kubernetes-api">Lab 2:  Accessing the kubernetes API</a><ul>
<li><a class="reference internal" href="#task-1-browse-the-kubernetes-api">Task 1:  Browse the kubernetes API</a></li>
<li><a class="reference internal" href="#task-2-use-rbac-to-control-access-to-the-api">Task 2:  Use RBAC to control access to the API</a></li>
<li><a class="reference internal" href="#task-3-using-customized-client-config">Task 3:  Using customized client config</a></li>
<li><a class="reference internal" href="#task-4-cleanup">Task 4:  Cleanup</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-3-kubernetes-workloads">Lab 3:  Kubernetes workloads</a><ul>
<li><a class="reference internal" href="#task-1-pod-operations">Task 1:  Pod operations</a></li>
<li><a class="reference internal" href="#task-2-replicaset-controller-operations">Task 2:  ReplicaSet controller operations</a></li>
<li><a class="reference internal" href="#task-3-working-with-deployments">Task 3:  Working with deployments</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-4-scheduling-and-node-management">Lab 4:  Scheduling and node management</a><ul>
<li><a class="reference internal" href="#task-1-scheduling-pods-to-nodes-node-selector">Task 1:  Scheduling Pods to nodes - node selector</a></li>
<li><a class="reference internal" href="#task-2-scheduling-pods-to-nodes-node-affinities">Task 2:  Scheduling Pods to nodes - node affinities</a></li>
<li><a class="reference internal" href="#task-3-scheduling-pods-to-nodes-pod-affinities">Task 3:  Scheduling Pods to nodes - pod affinities</a></li>
<li><a class="reference internal" href="#task-4-pod-priorities-optional">Task 4:  Pod priorities - OPTIONAL</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-5-accessing-the-applications">Lab 5:  Accessing the applications</a><ul>
<li><a class="reference internal" href="#task-1-working-with-services">Task 1:  Working with services</a></li>
<li><a class="reference internal" href="#task-2-working-with-ingress">Task 2:  Working with Ingress</a></li>
<li><a class="reference internal" href="#task-3-using-ingress-for-tcp-forwarding-optional">Task 3:  Using Ingress for TCP forwarding (OPTIONAL)</a></li>
<li><a class="reference internal" href="#id1">Task 4:  Cleanup</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-6-using-persistent-storage">Lab 6:  Using persistent storage</a><ul>
<li><a class="reference internal" href="#task-1-share-a-volume-in-two-containers">Task 1:  Share a volume in two containers</a></li>
<li><a class="reference internal" href="#task-2-dynamically-provision-a-pvc">Task 2:  Dynamically provision a PVC</a></li>
<li><a class="reference internal" href="#task-3-set-the-root-password-for-a-mysql-pod-using-secrets">Task 3:  Set the root password for a mysql pod using Secrets</a></li>
<li><a class="reference internal" href="#task-4-use-configmap-to-pass-a-file-to-a-pod">Task 4:  Use ConfigMap to pass a file to a pod</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-7-kubernetes-special-workloads">Lab 7:  Kubernetes special workloads</a><ul>
<li><a class="reference internal" href="#task-1-using-statefulsets">Task 1:  Using StatefulSets</a></li>
<li><a class="reference internal" href="#task-2-using-statefulsets-with-pvc">Task 2:  Using Statefulsets with PVC</a></li>
<li><a class="reference internal" href="#task-3-using-jobs">Task 3:  Using Jobs</a></li>
<li><a class="reference internal" href="#task-4-using-cronjobs">Task 4:  Using CronJobs</a></li>
<li><a class="reference internal" href="#task-5-using-daemonsets">Task 5:  Using DaemonSets</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-8-logging-monitoring-kubernetes">Lab 8:  Logging, monitoring kubernetes</a><ul>
<li><a class="reference internal" href="#task-1-investigate-the-logging-in-kubernetes">Task 1:  Investigate the logging in kubernetes</a></li>
<li><a class="reference internal" href="#task-2-processing-logs-in-a-pod-using-sidecar-containers">Task 2:  Processing logs in a pod using sidecar containers</a></li>
<li><a class="reference internal" href="#task-3-processing-logs-on-nodes">Task 3:  Processing logs on nodes</a></li>
<li><a class="reference internal" href="#task-4-monitoring-kubernetes-core-metrics-pipeline">Task 4:  Monitoring kubernetes core metrics pipeline</a></li>
<li><a class="reference internal" href="#task-5-monitoring-kubernetes-full-metrics-pipeline-optional">Task 5:  Monitoring kubernetes full metrics pipeline (<em>OPTIONAL</em>)</a></li>
<li><a class="reference internal" href="#task-6-debug-running-pods">Task 6:  Debug running pods</a></li>
<li><a class="reference internal" href="#task-7-managing-etcd">Task 7:  Managing ETCD</a></li>
<li><a class="reference internal" href="#task-8-create-and-restore-etcd-snapshot">Task 8:  Create and restore ETCD snapshot</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-9-kubernetes-installation-and-upgrade">Lab 9:  Kubernetes Installation and Upgrade</a><ul>
<li><a class="reference internal" href="#task-1-preparing-system-for-installation">Task 1:  Preparing system for installation</a></li>
<li><a class="reference internal" href="#task-2-prerequisites-to-be-verified">Task 2:  Prerequisites - to be verified</a></li>
<li><a class="reference internal" href="#task-3-installing-containerd">Task 3:  Installing Containerd</a></li>
<li><a class="reference internal" href="#task-4-install-kubelet-kubeadm-kubectl">Task 4:  Install kubelet, kubeadm, kubectl</a></li>
<li><a class="reference internal" href="#task-5-initialize-the-c-plane1-master-node">Task 5:  Initialize the c-plane1 (master) node</a></li>
<li><a class="reference internal" href="#task-6-join-the-worker-nodes-to-the-cluster">Task 6:  Join the worker nodes to the cluster</a></li>
<li><a class="reference internal" href="#task-7-install-dashboard">Task 7:  Install dashboard</a></li>
<li><a class="reference internal" href="#task-8-preparing-system-for-upgrade">Task 8:  Preparing system for upgrade</a></li>
<li><a class="reference internal" href="#task-9-search-for-and-select-a-newer-version">Task 9:  Search for and select a newer version</a></li>
<li><a class="reference internal" href="#task-10-upgrade-the-c-plane1-master-node">Task 10:  Upgrade the c-plane1 (master) node</a></li>
<li><a class="reference internal" href="#task-11-upgrade-worker-nodes">Task 11:  Upgrade worker nodes</a></li>
<li><a class="reference internal" href="#task-12-clean-up">Task 12:  Clean up</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lab-10-final-all-in-one-lab">Lab 10:  Final all-in-one lab</a><ul>
<li><a class="reference internal" href="#task-1-prepare-the-cluster">Task 1:  Prepare the cluster</a></li>
<li><a class="reference internal" href="#task-2-building-the-docker-image">Task 2:  Building the docker image</a></li>
<li><a class="reference internal" href="#task-3-creating-the-deployment">Task 3:  Creating the deployment</a></li>
<li><a class="reference internal" href="#task-4-expose-your-deployment-using-a-load-balancer-and-ingress">Task 4:  Expose your deployment using a <em>load-balancer</em> and <em>Ingress</em></a></li>
<li><a class="reference internal" href="#task-5-configure-network-policy">Task 5:  Configure network policy</a></li>
<li><a class="reference internal" href="#task-6-using-pvc">Task 6:  Using PVC</a></li>
</ul>
</li>
<li><a class="reference internal" href="#solutions-1-final-all-in-one-lab-solutions">Solutions 1:  Final all-in-one lab solutions</a><ul>
<li><a class="reference internal" href="#id2">Task 1:  Prepare the cluster</a></li>
<li><a class="reference internal" href="#id3">Task 2:  Building the docker image</a></li>
<li><a class="reference internal" href="#id4">Task 3:  Creating the deployment</a></li>
<li><a class="reference internal" href="#task-4-expose-your-deployment-using-load-balancer-and-ingress">Task 4:  Expose your deployment using <em>load-balancer</em> and <em>Ingress</em></a></li>
<li><a class="reference internal" href="#id5">Task 5:  Configure network policy</a></li>
<li><a class="reference internal" href="#id6">Task 6:  Using PVC</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">KBS-103</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">KBS-103 - Kubernetes administration</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="kbs-103-kubernetes-administration">
<h1>KBS-103 - Kubernetes administration<a class="headerlink" href="#kbs-103-kubernetes-administration" title="Permalink to this headline"></a></h1>
<section id="lab-1-health-check-the-kubernetes-environment">
<h2>Lab 1:  Health check the Kubernetes environment<a class="headerlink" href="#lab-1-health-check-the-kubernetes-environment" title="Permalink to this headline"></a></h2>
<section id="task-1-health-check">
<h3>Task 1:  Health check<a class="headerlink" href="#task-1-health-check" title="Permalink to this headline"></a></h3>
<p>Perform basic health check on your local kubernetes installation.</p>
<ul class="simple">
<li><p>On your  <strong>lab host</strong>, check whether your nodes are running</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can use BASH-like TAB completion for <em>os_nodes</em> script.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes list
<span class="go"> Id   Name       State</span>
<span class="go">--------------------------</span>
<span class="go"> 1    admin-ws   running</span>
<span class="go"> 2    c-plane1   running</span>
<span class="go"> 3    worker1    running</span>
<span class="go"> 4    worker2    running</span>
<span class="go"> 5    worker3    running</span>
<span class="go"> 6    service    running</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check whether VMs have the same system date and time ( 1-2 seconds of difference is OK). (Also check ssh connection)</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> admin-ws c-plane1 worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> -en <span class="s2">&quot;</span><span class="nv">$i</span><span class="s2"> :&quot;</span><span class="p">;</span> ssh <span class="nv">$i</span> <span class="s1">&#39;date&#39;</span><span class="p">;</span> <span class="k">done</span>
<span class="go">admin-ws :Wed Jan 31 15:36:08 UTC 2024</span>
<span class="go">c-plane1 :Wed Jan 31 15:36:09 UTC 2024</span>
<span class="go">worker1 :Wed Jan 31 15:36:09 UTC 2024</span>
<span class="go">worker2 :Wed Jan 31 15:36:09 UTC 2024</span>
<span class="go">worker3 :Wed Jan 31 15:36:10 UTC 2024</span>
</pre></div>
</div>
</section>
<section id="task-2-observe-the-components-of-the-kubernetes-cluster">
<h3>Task 2:  Observe the components of the Kubernetes cluster<a class="headerlink" href="#task-2-observe-the-components-of-the-kubernetes-cluster" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>List the control plane components running on the <cite>c-plane1</cite> node.</p></li>
</ul>
<p>Open a terminal on the <cite>c-plane1</cite> and look for the processes making up the control plane of Kubernetes: <cite>kube-apiserver</cite>, <cite>kube-controller-manager</cite>, <cite>kube-scheduler</cite>, and <cite>etcd</cite>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1:~#</span> pgrep -lx kube-apiserver
<span class="go">1043 kube-apiserver</span>
<span class="gp">root@c-plane1:~#</span> pgrep -lx kube-scheduler
<span class="go">1078 kube-scheduler</span>
<span class="gp">root@c-plane1:~#</span> pgrep -lf kube-controller-manager
<span class="go">1019 kube-controller</span>
<span class="gp">root@c-plane1:~#</span> pgrep -lx etcd
<span class="go">1087 etcd</span>
</pre></div>
</div>
<ul class="simple">
<li><p>List the node components running on the <cite>worker1</cite> node.</p></li>
</ul>
<p>Open a terminal on the <cite>worker1</cite> node and list the processes belonging to the Kubernetes node: <cite>kubelet</cite>, <cite>kube-proxy</cite>, container runtime <cite>containerd</cite>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1:~#</span> pgrep -lx kubelet
<span class="go">683 kubelet</span>

<span class="gp">root@worker1:~#</span> pgrep -lx kube-proxy
<span class="go">894 kube-proxy</span>

<span class="gp">root@worker1:~#</span> pgrep -lx containerd
<span class="go">517 containerd</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-2-accessing-the-kubernetes-api">
<h2>Lab 2:  Accessing the kubernetes API<a class="headerlink" href="#lab-2-accessing-the-kubernetes-api" title="Permalink to this headline"></a></h2>
<section id="task-1-browse-the-kubernetes-api">
<h3>Task 1:  Browse the kubernetes API<a class="headerlink" href="#task-1-browse-the-kubernetes-api" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Check the help page of the kubectl command</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl --help
<span class="go">kubectl controls the Kubernetes cluster manager.</span>

<span class="go">Find more information at https://github.com/kubernetes/kubernetes.</span>

<span class="go">Basic Commands (Beginner):</span>
<span class="go">  create         Create a resource by filename or stdin</span>
<span class="go">  expose         Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service</span>
<span class="go">  run            Run a particular image on the cluster</span>
<span class="go">  set            Set specific features on objects</span>

<span class="go">Basic Commands (Intermediate):</span>
<span class="go">  explain        Documentation of resources</span>
<span class="go">  get            Display one or many resources</span>
<span class="go"> ...</span>
<span class="go">  </span><span class="gs">proxy</span><span class="go">          Run a proxy to the Kubernetes API server</span>
<span class="go"> ...</span>
<span class="go"> Other Commands:</span>
<span class="go">   api-resources   Print the supported API resources on the server</span>
<span class="go">   api-versions    Print the supported API versions on the server, in the form of &quot;group/version&quot;</span>
<span class="go">   config          Modify kubeconfig files</span>
<span class="go">   plugin          Provides utilities for interacting with plugins</span>
<span class="go">   version         Print the client and server version information</span>

<span class="go"> Usage:</span>
<span class="go">   kubectl [flags] [options]</span>

<span class="go"> Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command.</span>
<span class="go"> Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands).</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Update your credentials on admin-ws</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> scp c-plane1:/etc/kubernetes/admin.conf /root/.kube/config
<span class="go">admin.conf                               100% 5635     7.4MB/s   00:00</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Start the kubectl proxy command on <em>admin-ws</em> to have a proxy to the API</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl proxy <span class="p">&amp;</span>
<span class="go">[1] 1303784</span>
<span class="go">Starting to serve on 127.0.0.1:8001           </span><span class="gs">&lt;press any key to get the prompt back&gt;</span><span class="go"></span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use curl to access the API</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> curl localhost:8001/api
<span class="go">{</span>
<span class="go">  &quot;kind&quot;: &quot;APIVersions&quot;,</span>
<span class="go">  &quot;versions&quot;: [</span>
<span class="go">    &quot;v1&quot;</span>
<span class="go">  ],</span>
<span class="go">  &quot;serverAddressByClientCIDRs&quot;: [</span>
<span class="go">    {</span>
<span class="go">      &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;,</span>
<span class="go">      &quot;serverAddress&quot;: &quot;10.10.10.51:6443&quot;</span>
<span class="go">    }</span>
<span class="go">  ]</span>
<span class="go">}</span>
<span class="gp">root@admin-ws $&gt;</span> curl localhost:8001/api/v1
<span class="go">{</span>
<span class="go">  &quot;kind&quot;: &quot;APIResourceList&quot;,</span>
<span class="go">  &quot;groupVersion&quot;: &quot;v1&quot;,</span>
<span class="go">  &quot;resources&quot;: [</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;bindings&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;Binding&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;</span>
<span class="go">      ]</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;componentstatuses&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: false,</span>
<span class="go">      &quot;kind&quot;: &quot;ComponentStatus&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;shortNames&quot;: [</span>
<span class="go">        &quot;cs&quot;</span>
<span class="go">      ]</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;configmaps&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;ConfigMap&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;shortNames&quot;: [</span>
<span class="go">        &quot;cm&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;qFsyl6wFWjQ=&quot;</span>
<span class="go">    },</span>
<span class="go">...</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;services&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;Service&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;shortNames&quot;: [</span>
<span class="go">        &quot;svc&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;categories&quot;: [</span>
<span class="go">        &quot;all&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;0/CO1lhkEBI=&quot;</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;services/proxy&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;ServiceProxyOptions&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;</span>
<span class="go">      ]</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;services/status&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;Service&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;</span>
<span class="go">      ]</span>
<span class="go">    }</span>
<span class="go">  ]</span>
<span class="go">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use the kubectl api-versions command to verify the supported API groups</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl api-versions
<span class="go">admissionregistration.k8s.io/v1</span>
<span class="go">apiextensions.k8s.io/v1</span>
<span class="go">apiregistration.k8s.io/v1</span>
<span class="go">apps/v1</span>
<span class="go">authentication.k8s.io/v1</span>
<span class="go">authorization.k8s.io/v1</span>
<span class="go">autoscaling/v1</span>
<span class="go">autoscaling/v2</span>
<span class="go">batch/v1</span>
<span class="go">certificates.k8s.io/v1</span>
<span class="go">coordination.k8s.io/v1</span>
<span class="go">crd.projectcalico.org/v1</span>
<span class="go">discovery.k8s.io/v1</span>
<span class="go">events.k8s.io/v1</span>
<span class="go">flowcontrol.apiserver.k8s.io/v1</span>
<span class="go">flowcontrol.apiserver.k8s.io/v1beta3</span>
<span class="go">networking.k8s.io/v1</span>
<span class="go">node.k8s.io/v1</span>
<span class="go">policy/v1</span>
<span class="go">rbac.authorization.k8s.io/v1</span>
<span class="go">scheduling.k8s.io/v1</span>
<span class="go">storage.k8s.io/v1</span>
<span class="go">v1</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use curl to see the content of the rbac.authorization.k8s.io/v1 API group</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> curl localhost:8001/apis/rbac.authorization.k8s.io/v1
<span class="go">{</span>
<span class="go">  &quot;kind&quot;: &quot;APIResourceList&quot;,</span>
<span class="go">  &quot;apiVersion&quot;: &quot;v1&quot;,</span>
<span class="go">  &quot;groupVersion&quot;: &quot;rbac.authorization.k8s.io/v1&quot;,</span>
<span class="go">  &quot;resources&quot;: [</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;clusterrolebindings&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;clusterrolebinding&quot;,</span>
<span class="go">      &quot;namespaced&quot;: false,</span>
<span class="go">      &quot;kind&quot;: &quot;ClusterRoleBinding&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;48tpQ8gZHFc=&quot;</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;clusterroles&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;clusterrole&quot;,</span>
<span class="go">      &quot;namespaced&quot;: false,</span>
<span class="go">      &quot;kind&quot;: &quot;ClusterRole&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;bYE5ZWDrJ44=&quot;</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;rolebindings&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;rolebinding&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;RoleBinding&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;eGsCzGH6b1g=&quot;</span>
<span class="go">    },</span>
<span class="go">    {</span>
<span class="go">      &quot;name&quot;: &quot;roles&quot;,</span>
<span class="go">      &quot;singularName&quot;: &quot;role&quot;,</span>
<span class="go">      &quot;namespaced&quot;: true,</span>
<span class="go">      &quot;kind&quot;: &quot;Role&quot;,</span>
<span class="go">      &quot;verbs&quot;: [</span>
<span class="go">        &quot;create&quot;,</span>
<span class="go">        &quot;delete&quot;,</span>
<span class="go">        &quot;deletecollection&quot;,</span>
<span class="go">        &quot;get&quot;,</span>
<span class="go">        &quot;list&quot;,</span>
<span class="go">        &quot;patch&quot;,</span>
<span class="go">        &quot;update&quot;,</span>
<span class="go">        &quot;watch&quot;</span>
<span class="go">      ],</span>
<span class="go">      &quot;storageVersionHash&quot;: &quot;7FuwZcIIItM=&quot;</span>
<span class="go">    }</span>
<span class="go">  ]</span>
<span class="go">}</span>
</pre></div>
</div>
</section>
<section id="task-2-use-rbac-to-control-access-to-the-api">
<h3>Task 2:  Use RBAC to control access to the API<a class="headerlink" href="#task-2-use-rbac-to-control-access-to-the-api" title="Permalink to this headline"></a></h3>
<p>In this task we will make use of the RBAC concepts to provide different levels of access to different users.</p>
<blockquote>
<div><p>Our task is to create the needed RBAC resources for two users of the cluster ( user1 and user2) so they will have the following permissions:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>user1</cite> should be able to read pods and services cluster wide (access the <cite>get</cite>, <cite>watch</cite> and <cite>list</cite> verbs)</p></li>
<li><p><cite>user2</cite> should be able to read pods and services only in the default namespace.</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<ul class="simple">
<li><p>Review the content of the clrole.yaml file from the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Accessing_API</span></code> directory. The file defines a <code class="docutils literal notranslate"><span class="pre">ClusterRole</span></code> which can access the <code class="docutils literal notranslate"><span class="pre">get</span></code>, <code class="docutils literal notranslate"><span class="pre">watch</span></code> and <code class="docutils literal notranslate"><span class="pre">list</span></code> verbs of the <code class="docutils literal notranslate"><span class="pre">Pods</span></code> and <code class="docutils literal notranslate"><span class="pre">Services</span></code> objects of the core API. Observe that there is no namespace metadata field for this object.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_API/
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> cat clrole.yaml
<span class="gs">kind: ClusterRole</span><span class="go"></span>
<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">metadata:</span>
<span class="go">  name: pod-reader</span>
<span class="go">rules:</span>
<span class="go">- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group</span>
<span class="go">  resources: [&quot;pods&quot;,&quot;services&quot;]</span>
<span class="go">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Review the content of the binding.yaml file from the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Accessing_API</span></code> directory. The file defines a <code class="docutils literal notranslate"><span class="pre">RoleBinding</span></code> in the default namespace. This is binding the <code class="docutils literal notranslate"><span class="pre">ClusterRole</span></code> <em>pod-reader</em> to the <em>user2</em> user. Observe the namespace value in the metadata field.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_API
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> cat binding.yaml
<span class="gs">kind: RoleBinding</span><span class="go"></span>
<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">metadata:</span>
<span class="go">  name: binding1</span>
<span class="go">  </span><span class="gs">namespace: default</span><span class="go"></span>
<span class="go">subjects:</span>
<span class="go">- kind: User</span>
<span class="go">  </span><span class="gs">name: user2</span><span class="go"></span>
<span class="go">  apiGroup: rbac.authorization.k8s.io</span>
<span class="go">roleRef:</span>
<span class="go">  kind: ClusterRole</span>
<span class="go">  name: pod-reader</span>
<span class="go">  apiGroup: rbac.authorization.k8s.io</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Review the content of the clbinding.yaml file from the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Accessing_API</span></code> directory. The file defines a <code class="docutils literal notranslate"><span class="pre">ClusterRoleBinding</span></code>. This is binding the <em>pod-reader</em> <code class="docutils literal notranslate"><span class="pre">ClusterRole</span></code> to the <em>user1</em> user.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> cat clbinding.yaml
<span class="gs">kind: ClusterRoleBinding</span><span class="go"></span>
<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">metadata:</span>
<span class="go">  name: clbinding1</span>
<span class="go">subjects:</span>
<span class="go">- kind: User</span>
<span class="go">  </span><span class="gs">name: user1</span><span class="go"></span>
<span class="go">  apiGroup: rbac.authorization.k8s.io</span>
<span class="go">roleRef:</span>
<span class="go">  kind: ClusterRole</span>
<span class="go">  name: pod-reader</span>
<span class="go">  apiGroup: rbac.authorization.k8s.io</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the users <em>user1</em> and <em>user2</em> still cannot access the pods in the cluster, because they don’t have the authorization.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user1 get pod
<span class="go">Error from server (Forbidden): pods is forbidden: User &quot;user1&quot; cannot list resource &quot;pods&quot;</span>
<span class="go">in API group &quot;&quot; in the namespace &quot;default&quot;</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user2 get pod
<span class="go">Error from server (Forbidden): pods is forbidden: User &quot;user2&quot; cannot list resource &quot;pods&quot;</span>
<span class="go">in API group &quot;&quot; in the namespace &quot;default&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the ClusterRole, and the two bindings.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl create -f clrole.yaml
<span class="go">clusterrole.rbac.authorization.k8s.io/pod-reader created</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl create -f binding.yaml
<span class="go">rolebinding.rbac.authorization.k8s.io/binding1 created</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl create -f clbinding.yaml
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/clbinding1 created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>List the pods from the default namespace as <em>user1</em> and <em>user2</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user2 get pod
<span class="go">No resources found in default namespace.</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl create -f ubuntu.yaml
<span class="go">pod/ubuntu created</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user2 get pod
<span class="go">NAME      READY     STATUS    RESTARTS   AGE</span>
<span class="go">ubuntu    1/1       Running   0          35s</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user1 get pod
<span class="go">NAME      READY     STATUS    RESTARTS   AGE</span>
<span class="go">ubuntu    1/1       Running   0          1m</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can see that both users can list pod in <em>default</em> namespace.</p>
</div>
<ul class="simple">
<li><p>List the pods from <em>all</em> the namespaces as <em>user1</em> and <em>user2</em></p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user1 get pod --all-namespaces
<span class="go">NAMESPACE              NAME                                         READY   STATUS    RESTARTS     AGE</span>
<span class="go">default                ubuntu                                       1/1     Running   0            37s</span>
<span class="go">kube-system            calico-kube-controllers-786b679988-5tjjz     1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            calico-node-45wdx                            1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            calico-node-948pz                            1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            calico-node-hhbdc                            1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            calico-node-vwkpv                            1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            coredns-5d78c9869d-7p5vc                     1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            coredns-5d78c9869d-qv8br                     1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            etcd-c-plane1                                1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            kube-apiserver-c-plane1                      1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            kube-controller-manager-c-plane1             1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            kube-proxy-9586s                             1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            kube-proxy-crr56                             1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            kube-proxy-ldjfq                             1/1     Running   2 (3d ago)   6d</span>
<span class="go">kube-system            kube-proxy-mv4d7                             1/1     Running   1 (3d ago)   6d</span>
<span class="go">kube-system            kube-scheduler-c-plane1                      1/1     Running   2 (3d ago)   6d</span>
<span class="go">kubernetes-dashboard   dashboard-metrics-scraper-5cb4f4bb9c-jkxr2   1/1     Running   1 (3d ago)   6d</span>
<span class="go">kubernetes-dashboard   kubernetes-dashboard-6967859bff-g8jmh        1/1     Running   1 (3d ago)   6d</span>

<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> kubectl --as user2 get pod --all-namespaces
<span class="go">Error from server (Forbidden): pods is forbidden: User &quot;user2&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope</span>
<span class="gp">root@admin-ws:/labfiles/k8s/Accessing_API $&gt;</span> <span class="nb">cd</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can see that <em>user2</em> cannot list pods outside the <em>default</em> namespace but <em>user1</em> can do it, because <em>user1</em> has <em>ClusterRoleBinding</em>.</p>
</div>
</section>
<section id="task-3-using-customized-client-config">
<h3>Task 3:  Using customized client config<a class="headerlink" href="#task-3-using-customized-client-config" title="Permalink to this headline"></a></h3>
<p>Managing applications deployed in Kubernetes may require us to access different environments located in clusters or different namespaces sometimes using different identities. The <cite>kubectl</cite> contexts provide us a convenient way of switching between the different environments.</p>
<p>In this exercise, you will create a client configuration file that you will use to control cluster access using separate contexts. The goal is to create a context that will use a user certificate for authenticating as <cite>developer</cite> and will use the <cite>myapp</cite> namespace.</p>
<p>Perform the following operations on the <cite>admin-ws</cite> machine.</p>
<ul class="simple">
<li><p>Create a certificate for the <cite>developer</cite> user using the <cite>/labfiles/k8s/Accessing_API/mkusercert.sh</cite> script.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span>

<span class="gp">root@admin-ws:~$&gt;</span> /labfiles/k8s/Accessing_API/mkusercert.sh
<span class="go">certificatesigningrequest.certificates.k8s.io/developer-csr created</span>
<span class="go">certificatesigningrequest.certificates.k8s.io/developer-csr approved</span>
<span class="go">certificatesigningrequest.certificates.k8s.io &quot;developer-csr&quot; deleted</span>
<span class="gp">root@admin-ws:~$&gt;</span> ls developer*
<span class="go">developer.crt  developer.csr  developer.key</span>
<span class="gp">root@admin-ws:~$&gt;</span> openssl x509 -noout -text -in developer.crt <span class="p">|</span> grep Subject:
<span class="go">     Subject: CN = developer</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create your own customized client configuration file ‘config-demo’ using the existing configuration file as a starting point.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:~$&gt;</span> cp ~/.kube/config ~/config-demo
<span class="gp">root@admin-ws:~$&gt;</span> kubectl --kubeconfig config-demo config view
<span class="go">apiVersion: v1</span>
<span class="go">clusters:</span>
<span class="go">- cluster:</span>
<span class="go">    certificate-authority-data: DATA+OMITTED</span>
<span class="go">    server: https://10.10.10.51:6443</span>
<span class="go">  name: kubernetes</span>
<span class="go">contexts:</span>
<span class="go">- context:</span>
<span class="go">    cluster: kubernetes</span>
<span class="go">    user: kubernetes-admin</span>
<span class="go">  name: kubernetes-admin@kubernetes</span>
<span class="go">current-context: kubernetes-admin@kubernetes</span>
<span class="go">kind: Config</span>
<span class="go">preferences: {}</span>
<span class="go">users:</span>
<span class="go">- name: kubernetes-admin</span>
<span class="go">  user:</span>
<span class="go">    client-certificate-data: DATA+OMITTED</span>
<span class="go">    client-key-data: DATA+OMITTED</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>Modify the configuration by adding</dt><dd><ul>
<li><p>the <cite>developer</cite> user entry using the previously created certificate and key,</p></li>
<li><p>the <cite>kube-devel</cite> context that uses the <cite>developer</cite> user identity in the <cite>myapp</cite> namespace,</p></li>
<li><p>and the <cite>kube-sys</cite> context that uses the <cite>kubernetes-admin</cite> identity in the <cite>kube-system</cite> namespace</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig<span class="o">=</span>config-demo config set-credentials developer <span class="se">\</span>
<span class="gp">&gt;</span> --username<span class="o">=</span>developer --client-certificate<span class="o">=</span>./developer.crt --client-key<span class="o">=</span>./developer.key <span class="se">\</span>
<span class="gp">&gt;</span> --embed-certs<span class="o">=</span><span class="nb">true</span>
<span class="go">User &quot;developer&quot; set.</span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig<span class="o">=</span>config-demo config set-context kube-devel <span class="se">\</span>
<span class="gp">&gt;</span> --cluster<span class="o">=</span>kubernetes --namespace<span class="o">=</span>myapp --user<span class="o">=</span>developer
<span class="go">Context &quot;kube-devel&quot; created.</span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig<span class="o">=</span>config-demo config set-context kube-sys <span class="se">\</span>
<span class="gp">&gt;</span> --cluster<span class="o">=</span>kubernetes --namespace<span class="o">=</span>kube-system --user<span class="o">=</span>kubernetes-admin
<span class="go">Context &quot;kube-sys&quot; created.</span>
<span class="gp">root@admin-ws:~#</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check your custom configuration ‘config-demo’ by performing the following steps:</p>
<ul>
<li><p>Create the <cite>myapp</cite> namespace as kubernetes administrator.</p></li>
<li><p>Create a RoleBinding in the <cite>myapp</cite> namespace that grants the <cite>cluster-admin</cite> cluster role to the developer user.</p></li>
<li><p>List the pods using both the <cite>kube-devel</cite> and <cite>kube-sys</cite> contexts.</p></li>
</ul>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo config get-contexts
<span class="go">CURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE</span>
<span class="go">          kube-devel                    kubernetes   developer          myapp</span>
<span class="go">          kube-sys                      kubernetes   kubernetes-admin   kube-system</span>
<span class="gs">*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin</span><span class="go"></span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo create namespace myapp
<span class="go">namespace/myapp created</span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo -n myapp create rolebinding myapp-admin <span class="se">\</span>
<span class="gp">&gt;</span> --clusterrole cluster-admin --user developer
<span class="go">rolebinding.rbac.authorization.k8s.io/myapp-admin created</span>

<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo config use-context kube-sys
<span class="gs">Switched to context &quot;kube-sys&quot;</span><span class="go">.</span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo get pod
<span class="go">NAME                                       READY   STATUS    RESTARTS      AGE</span>
<span class="go">calico-kube-controllers-5857bf8d58-p9zzl   1/1     Running   1 (24h ago)   8d</span>
<span class="go">calico-node-6nhz7                          1/1     Running   1 (24h ago)   8d</span>
<span class="go">calico-node-ksmdm                          1/1     Running   1 (24h ago)   8d</span>
<span class="go">calico-node-wxmld                          1/1     Running   1 (24h ago)   8d</span>
<span class="go">calico-node-zv9rf                          1/1     Running   1 (24h ago)   8d</span>
<span class="go">coredns-787d4945fb-g5zjn                   1/1     Running   1 (24h ago)   8d</span>
<span class="go">coredns-787d4945fb-kfjpf                   1/1     Running   1 (24h ago)   8d</span>
<span class="go">etcd-c-plane1                              1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-apiserver-c-plane1                    1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-controller-manager-c-plane1           1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-proxy-7qwfr                           1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-proxy-gwxrm                           1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-proxy-hw65n                           1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-proxy-knsqq                           1/1     Running   1 (24h ago)   8d</span>
<span class="go">kube-scheduler-c-plane1                    1/1     Running   1 (24h ago)   8d</span>

<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo config use-context kube-devel
<span class="gs">Switched to context &quot;kube-devel&quot;</span><span class="go">.</span>
<span class="gp">root@admin-ws:~#</span> kubectl --kubeconfig ./config-demo get pod
<span class="go">No resources found in </span><span class="gs">myapp</span><span class="go"> namespace.</span>
<span class="gp">root@admin-ws:~#</span>
</pre></div>
</div>
<p>We can observe that the <cite>kube-sys</cite> context operates on the <cite>kube-system</cite> namespace by default, while the <cite>kube-devel</cite> context operates on the <cite>myapp</cite> namespace.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In most cases we use an existing authorized <em>ServiceAccount</em> or <em>User</em> to reduce access rights.
Here is a simple sample script which creates client config:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nv">clusterName</span><span class="o">=</span><span class="s1">&#39;&lt;YOUR-CLUSTER-NAME&gt;&#39;</span>
<span class="nv">server</span><span class="o">=</span><span class="s1">&#39;https://&lt;IP-ADDRESS-OFF-ENTRY-POINT&gt;:6443&#39;</span>
<span class="nv">serviceAccount</span><span class="o">=</span><span class="s1">&#39;&lt;SERVICE-ACCOUNT-NAME&gt;&#39;</span>
<span class="nv">namespace</span><span class="o">=</span><span class="s1">&#39;&lt;NAMESPACE-NAME&gt;&#39;</span>
<span class="nv">secretName</span><span class="o">=</span><span class="s1">&#39;&lt;SECRET-NAME&gt;&#39;</span>
<span class="nv">ca</span><span class="o">=</span><span class="k">$(</span>kubectl --namespace<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$namespace</span><span class="s2">&quot;</span> get secret/<span class="s2">&quot;</span><span class="nv">$secretName</span><span class="s2">&quot;</span> -o<span class="o">=</span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.ca\.crt}&#39;</span><span class="k">)</span>
<span class="nv">token</span><span class="o">=</span><span class="k">$(</span>kubectl --namespace<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$namespace</span><span class="s2">&quot;</span> get secret/<span class="s2">&quot;</span><span class="nv">$secretName</span><span class="s2">&quot;</span> -o<span class="o">=</span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.token}&#39;</span> <span class="p">|</span> base64 --decode<span class="k">)</span>

<span class="nb">echo</span> <span class="s2">&quot;</span>
<span class="s2">---</span>
<span class="s2">apiVersion: v1</span>
<span class="s2">kind: Config</span>
<span class="s2">clusters:</span>
<span class="s2">  - name: </span><span class="si">${</span><span class="nv">clusterName</span><span class="si">}</span><span class="s2"></span>
<span class="s2">    cluster:</span>
<span class="s2">      certificate-authority-data: </span><span class="si">${</span><span class="nv">ca</span><span class="si">}</span><span class="s2"></span>
<span class="s2">      server: </span><span class="si">${</span><span class="nv">server</span><span class="si">}</span><span class="s2"></span>
<span class="s2">contexts:</span>
<span class="s2">  - name: </span><span class="si">${</span><span class="nv">serviceAccount</span><span class="si">}</span><span class="s2">@</span><span class="si">${</span><span class="nv">clusterName</span><span class="si">}</span><span class="s2"></span>
<span class="s2">    context:</span>
<span class="s2">      cluster: </span><span class="si">${</span><span class="nv">clusterName</span><span class="si">}</span><span class="s2"></span>
<span class="s2">      namespace: </span><span class="si">${</span><span class="nv">namespace</span><span class="si">}</span><span class="s2"></span>
<span class="s2">      user: </span><span class="si">${</span><span class="nv">serviceAccount</span><span class="si">}</span><span class="s2"></span>
<span class="s2">users:</span>
<span class="s2">  - name: </span><span class="si">${</span><span class="nv">serviceAccount</span><span class="si">}</span><span class="s2"></span>
<span class="s2">    user:</span>
<span class="s2">      token: </span><span class="si">${</span><span class="nv">token</span><span class="si">}</span><span class="s2"></span>
<span class="s2">current-context: </span><span class="si">${</span><span class="nv">serviceAccount</span><span class="si">}</span><span class="s2">@</span><span class="si">${</span><span class="nv">clusterName</span><span class="si">}</span><span class="s2"></span>
<span class="s2">&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="task-4-cleanup">
<h3>Task 4:  Cleanup<a class="headerlink" href="#task-4-cleanup" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Delete the objects created during this lab.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:~#</span> kubectl delete pod ubuntu
<span class="go">pod &quot;ubuntu&quot; deleted</span>
<span class="gp">root@admin-ws:~#</span> kubectl delete clusterrolebinding clbinding1
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;clbinding1&quot; deleted</span>
<span class="gp">root@admin-ws:~#</span> kubectl delete rolebinding binding1
<span class="go">rolebinding.rbac.authorization.k8s.io &quot;binding1&quot; deleted</span>
<span class="gp">root@admin-ws:~#</span> kubectl delete clusterrole pod-reader
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;pod-reader&quot; deleted</span>
<span class="gp">root@admin-ws:~#</span> kubectl delete namespace myapp
<span class="go">namespace &quot;myapp&quot; deleted</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-3-kubernetes-workloads">
<h2>Lab 3:  Kubernetes workloads<a class="headerlink" href="#lab-3-kubernetes-workloads" title="Permalink to this headline"></a></h2>
<section id="task-1-pod-operations">
<h3>Task 1:  Pod operations<a class="headerlink" href="#task-1-pod-operations" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a manifest file for a pod that uses the <em>busybox:1.27</em> image and it runs the <em>sleep 3600</em> command.  You can find the manifest files in the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Workloads</span></code> directory.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat pod1.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: pod1</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">   - name: bbox</span>
<span class="go">     image: busybox:1.27</span>
<span class="go">     command:</span>
<span class="go">       - sleep</span>
<span class="go">     args:</span>
<span class="go">       - &quot;3600&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a Pod in the default namespace using this template</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create -f pod1.yaml
<span class="go">pod/pod1 created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME      READY     STATUS    RESTARTS   AGE</span>
<span class="go">pod1      1/1       Running   0          36s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a new namespace named test-ns, and create a pod in it using the same template</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create namespace test-ns
<span class="go">namespace/test-ns created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl --namespace<span class="o">=</span>test-ns create -f pod1.yaml
<span class="go">pod/pod1 created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl --namespace<span class="o">=</span>test-ns get pod
<span class="go">NAME      READY     STATUS    RESTARTS   AGE</span>
<span class="go">pod1      1/1       Running   0          12s</span>
</pre></div>
</div>
<p>Pods (resources) with the same name can exist in different namespaces.</p>
<ul class="simple">
<li><p>Get more information about a pod.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod pod1 -o yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  annotations:</span>
<span class="go">    cni.projectcalico.org/containerID: 8ef82faacb01cd6d9cc751a3d0cecfa13931d967917d90ead5fbc88d684141af</span>
<span class="go">    cni.projectcalico.org/podIP: 192.168.182.2/32</span>
<span class="go">    cni.projectcalico.org/podIPs: 192.168.182.2/32</span>
<span class="go">  creationTimestamp: &quot;2024-02-01T14:17:25Z&quot;</span>
<span class="go">  name: pod1</span>
<span class="go">  namespace: default</span>
<span class="go">  resourceVersion: &quot;168069&quot;</span>
<span class="go">  uid: c0aa6055-e918-4562-a812-22c7acaf87b1</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - args:</span>
<span class="go">    - &quot;3600&quot;</span>
<span class="go">    command:</span>
<span class="go">    - sleep</span>
<span class="go">    image: busybox:1.27</span>
<span class="go">    imagePullPolicy: IfNotPresent</span>
<span class="go">    name: bbox</span>
<span class="go">    resources: {}</span>
<span class="go">    terminationMessagePath: /dev/termination-log</span>
<span class="go">    terminationMessagePolicy: File</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span>
<span class="go">      name: kube-api-access-75wlg</span>
<span class="go">      readOnly: true</span>
<span class="go">  dnsPolicy: ClusterFirst</span>
<span class="go">  enableServiceLinks: true</span>
<span class="go">  nodeName: worker3</span>
<span class="go">  preemptionPolicy: PreemptLowerPriority</span>
<span class="go">  priority: 0</span>
<span class="go">  restartPolicy: Always</span>
<span class="go">  schedulerName: default-scheduler</span>
<span class="go">  securityContext: {}</span>
<span class="go">  serviceAccount: default</span>
<span class="go">  serviceAccountName: default</span>
<span class="go">  terminationGracePeriodSeconds: 30</span>
<span class="go">  tolerations:</span>
<span class="go">  - effect: NoExecute</span>
<span class="go">    key: node.kubernetes.io/not-ready</span>
<span class="go">    operator: Exists</span>
<span class="go">    tolerationSeconds: 300</span>
<span class="go">  - effect: NoExecute</span>
<span class="go">    key: node.kubernetes.io/unreachable</span>
<span class="go">    operator: Exists</span>
<span class="go">    tolerationSeconds: 300</span>
<span class="go">  volumes:</span>
<span class="go">  - name: kube-api-access-75wlg</span>
<span class="go">    projected:</span>
<span class="go">      defaultMode: 420</span>
<span class="go">      sources:</span>
<span class="go">      - serviceAccountToken:</span>
<span class="go">          expirationSeconds: 3607</span>
<span class="go">          path: token</span>
<span class="go">      - configMap:</span>
<span class="go">          items:</span>
<span class="go">          - key: ca.crt</span>
<span class="go">            path: ca.crt</span>
<span class="go">          name: kube-root-ca.crt</span>
<span class="go">      - downwardAPI:</span>
<span class="go">          items:</span>
<span class="go">          - fieldRef:</span>
<span class="go">              apiVersion: v1</span>
<span class="go">              fieldPath: metadata.namespace</span>
<span class="go">            path: namespace</span>
<span class="go">status:</span>
<span class="go">  conditions:</span>
<span class="go">  - lastProbeTime: null</span>
<span class="go">    lastTransitionTime: &quot;2024-02-01T14:17:28Z&quot;</span>
<span class="go">    status: &quot;True&quot;</span>
<span class="go">    type: PodReadyToStartContainers</span>
<span class="go">  - lastProbeTime: null</span>
<span class="go">    lastTransitionTime: &quot;2024-02-01T14:17:25Z&quot;</span>
<span class="go">    status: &quot;True&quot;</span>
<span class="go">    type: Initialized</span>
<span class="go">  - lastProbeTime: null</span>
<span class="go">    lastTransitionTime: &quot;2024-02-01T14:17:28Z&quot;</span>
<span class="go">    status: &quot;True&quot;</span>
<span class="go">    type: Ready</span>
<span class="go">  - lastProbeTime: null</span>
<span class="go">    lastTransitionTime: &quot;2024-02-01T14:17:28Z&quot;</span>
<span class="go">    status: &quot;True&quot;</span>
<span class="go">    type: ContainersReady</span>
<span class="go">  - lastProbeTime: null</span>
<span class="go">    lastTransitionTime: &quot;2024-02-01T14:17:25Z&quot;</span>
<span class="go">    status: &quot;True&quot;</span>
<span class="go">    type: PodScheduled</span>
<span class="go">  containerStatuses:</span>
<span class="go">  - containerID: containerd://3e9871212a4f8f4ec5833e6bd27a1449e0dbb039c4479cacea05f9e7fcdd0623</span>
<span class="go">    image: docker.io/library/busybox:1.27</span>
<span class="go">    imageID: docker.io/library/busybox@sha256:bbc3a03235220b170ba48a157dd097dd1379299370e1ed99ce976df0355d24f0</span>
<span class="go">    lastState: {}</span>
<span class="go">    name: bbox</span>
<span class="go">    ready: true</span>
<span class="go">    restartCount: 0</span>
<span class="go">    started: true</span>
<span class="go">    state:</span>
<span class="go">      running:</span>
<span class="go">        startedAt: &quot;2024-02-01T14:17:27Z&quot;</span>
<span class="go">  hostIP: 10.10.10.54</span>
<span class="go">  hostIPs:</span>
<span class="go">  - ip: 10.10.10.54</span>
<span class="go">  phase: Running</span>
<span class="go">  podIP: 192.168.182.2</span>
<span class="go">  podIPs:</span>
<span class="go">  - ip: 192.168.182.2</span>
<span class="go">  qosClass: BestEffort</span>
<span class="go">  startTime: &quot;2024-02-01T14:17:25Z&quot;</span>
</pre></div>
</div>
<p>The yaml output of the kubectl get command will list all the fields of an object as they are known in the API server. We can observe that besides the values provided by us the specification of the pod also includes default values for many fields.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl describe pod pod1
<span class="go">Name:             pod1</span>
<span class="go">Namespace:        default</span>
<span class="go">Priority:         0</span>
<span class="go">Service Account:  default</span>
<span class="go">Node:             worker3/10.10.10.54</span>
<span class="go">Start Time:       Thu, 01 Feb 2024 14:17:25 +0000</span>
<span class="go">Labels:           &lt;none&gt;</span>
<span class="go">Annotations:      cni.projectcalico.org/containerID: 8ef82faacb01cd6d9cc751a3d0cecfa13931d967917d90ead5fbc88d684141af</span>
<span class="go">                  cni.projectcalico.org/podIP: 192.168.182.2/32</span>
<span class="go">                  cni.projectcalico.org/podIPs: 192.168.182.2/32</span>
<span class="go">Status:           Running</span>
<span class="go">IP:               192.168.182.2</span>
<span class="go">IPs:</span>
<span class="go">  IP:  192.168.182.2</span>
<span class="go">Containers:</span>
<span class="go">  bbox:</span>
<span class="go">    Container ID:  containerd://3e9871212a4f8f4ec5833e6bd27a1449e0dbb039c4479cacea05f9e7fcdd0623</span>
<span class="go">    Image:         busybox:1.27</span>
<span class="go">    Image ID:      docker.io/library/busybox@sha256:bbc3a03235220b170ba48a157dd097dd1379299370e1ed99ce976df0355d24f0</span>
<span class="go">    Port:          &lt;none&gt;</span>
<span class="go">    Host Port:     &lt;none&gt;</span>
<span class="go">    Command:</span>
<span class="go">      sleep</span>
<span class="go">    Args:</span>
<span class="go">      3600</span>
<span class="go">    State:          Running</span>
<span class="go">      Started:      Thu, 01 Feb 2024 14:17:27 +0000</span>
<span class="go">    Ready:          True</span>
<span class="go">    Restart Count:  0</span>
<span class="go">    Environment:    &lt;none&gt;</span>
<span class="go">    Mounts:</span>
<span class="go">      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-75wlg (ro)</span>
<span class="go">Conditions:</span>
<span class="go">  Type                        Status</span>
<span class="go">  PodReadyToStartContainers   True</span>
<span class="go">  Initialized                 True</span>
<span class="go">  Ready                       True</span>
<span class="go">  ContainersReady             True</span>
<span class="go">  PodScheduled                True</span>
<span class="go">Volumes:</span>
<span class="go">  kube-api-access-75wlg:</span>
<span class="go">    Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="go">    TokenExpirationSeconds:  3607</span>
<span class="go">    ConfigMapName:           kube-root-ca.crt</span>
<span class="go">    ConfigMapOptional:       &lt;nil&gt;</span>
<span class="go">    DownwardAPI:             true</span>
<span class="go">QoS Class:                   BestEffort</span>
<span class="go">Node-Selectors:              &lt;none&gt;</span>
<span class="go">Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
<span class="go">                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="go">Events:</span>
<span class="go">  Type    Reason     Age    From               Message</span>
<span class="go">  ----    ------     ----   ----               -------</span>
<span class="go">  Normal  Scheduled  5m14s  default-scheduler  Successfully assigned default/pod1 to worker3</span>
<span class="go">  Normal  Pulling    5m13s  kubelet            Pulling image &quot;busybox:1.27&quot;</span>
<span class="go">  Normal  Pulled     5m12s  kubelet            Successfully pulled image &quot;busybox:1.27&quot; in 1.501s (1.501s including waiting)</span>
<span class="go">  Normal  Created    5m12s  kubelet            Created container bbox</span>
<span class="go">  Normal  Started    5m12s  kubelet            Started container bbox</span>
</pre></div>
</div>
<p>The describe command besides listing the details of a resource, will also list the events occurred on that resource. This could be very valuable when troubleshooting.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default events are retained for one hour only. This is a setting of the API server. If long term retention is desired then events should be transmitted to an external logging system.</p>
</div>
<ul class="simple">
<li><p>Execute a shell in the pod and check its hostname, IP address, network connectivity, and the running processes</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti pod1 -- sh
<span class="gp">root@pod1 / #&gt;</span> hostname
<span class="go">pod1</span>
<span class="gp">root@pod1 / #&gt;</span> ip a
<span class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</span>
<span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span>
<span class="go">    inet 127.0.0.1/8 scope host lo</span>
<span class="go">       valid_lft forever preferred_lft forever</span>
<span class="go">    inet6 ::1/128 scope host</span>
<span class="go">       valid_lft forever preferred_lft forever</span>
<span class="go">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop qlen 1000</span>
<span class="go">    link/ipip 0.0.0.0 brd 0.0.0.0</span>
<span class="go">4: eth0@if34: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1480 qdisc noqueue</span>
<span class="go">    link/ether 4a:ac:f4:fa:a0:f7 brd ff:ff:ff:ff:ff:ff</span>
<span class="go">    inet 192.168.182.2/32 scope global eth0</span>
<span class="go">       valid_lft forever preferred_lft forever</span>
<span class="go">    inet6 fe80::48ac:f4ff:fefa:a0f7/64 scope link</span>
<span class="go">       valid_lft forever preferred_lft forever</span>
<span class="gp">root@pod1 / #&gt;</span> ping -c1 kubernetes.io
<span class="go">PING kubernetes.io (147.75.40.148): 56 data bytes</span>
<span class="go">64 bytes from 147.75.40.148: seq=0 ttl=54 time=11.595 ms</span>

<span class="go">--- kubernetes.io ping statistics ---</span>
<span class="go">1 packets transmitted, 1 packets received, 0% packet loss</span>
<span class="go">round-trip min/avg/max = 11.595/11.595/11.595 ms</span>
<span class="gp">root@pod1 / #&gt;</span> ps -ef
<span class="go">PID   USER     TIME   COMMAND</span>
<span class="go">    1 root       0:00 sleep 3600</span>
<span class="go">    7 root       0:00 sh</span>
<span class="go">   16 root       0:00 ps -ef</span>
<span class="gp">root@pod1 / #&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Identify the node on which the pod is running and simulate a failure by pausing the corresponding VM. Check what is happening with the pod.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please be aware that the time required for detecting node failures and evict pods from a failed node depends on the following parameters:</p>
<ul class="simple">
<li><p>for the <code class="docutils literal notranslate"><span class="pre">kube-controller-manager</span></code> we have the <code class="docutils literal notranslate"><span class="pre">--node-monitor-period</span></code> that specifies the period for syncing NodeStatus in NodeController (5s), the <code class="docutils literal notranslate"><span class="pre">--node-monitor-grace-period</span></code> represents the amount of time which we allow running Node to be unresponsive before marking it unhealthy (40s).
When the node is marked unhealthy the node will be tainted, and this will trigger the eviction of the pods.</p></li>
<li><p>for the <code class="docutils literal notranslate"><span class="pre">kube-apiserver</span></code> we have the <code class="docutils literal notranslate"><span class="pre">--default-not-ready-toleration-seconds</span></code> and <code class="docutils literal notranslate"><span class="pre">--default-unreachable-toleration-seconds</span></code> parameters that defines the toleration seconds that are automatically added by the API server to any pod that doesn’t has any toleration specified in its <code class="docutils literal notranslate"><span class="pre">spec</span></code>.
By default the API server adds a toleration for <code class="docutils literal notranslate"><span class="pre">node.kubernetes.io/not-ready</span></code> and <code class="docutils literal notranslate"><span class="pre">node.kubernetes.io/unreachable</span></code> with <code class="docutils literal notranslate"><span class="pre">tolerationSeconds=300</span></code>. This means that the pods will be evicted only after 5 minutes after the node is tainted.</p></li>
</ul>
<p>To reduce the default toleration we can modify the parameters of the API server by setting the <code class="docutils literal notranslate"><span class="pre">--default-not-ready-toleration-seconds=30</span></code> and  <code class="docutils literal notranslate"><span class="pre">--default-unreachable-toleration-seconds=30</span></code> parameters for the <code class="docutils literal notranslate"><span class="pre">kube-apiserver</span></code> (in our environment these can be set in the <code class="docutils literal notranslate"><span class="pre">/etc/kubernetes/manifest/kube-apiserver.yaml</span></code> file on <code class="docutils literal notranslate"><span class="pre">c-plane1</span></code> node).</p>
<p>More details: <a class="reference external" href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/#taint-based-evictions">Taint based Evictions</a> .</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod pod1 -o wide
<span class="go">NAME   READY   STATUS    RESTARTS   AGE   IP               NODE    ...</span>
<span class="go">pod1   1/1     Running   0          6m26s 192.168.182.33   </span><span class="gs">worker3</span><span class="go">  ...</span>

<span class="gp">root@lab_machine $&gt;</span> virsh list
<span class="go">Id    Name                           State</span>
<span class="go">----------------------------------------------------</span>
<span class="go"> 1    worker1    running</span>
<span class="go"> 2    worker2    running</span>
<span class="go"> 3    admin-ws   running</span>
<span class="go"> 4    c-plane1   running</span>
<span class="go"> 5    worker3    running</span>
<span class="go"> 6    service    running</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Stop relevant node from <strong>lab_machine</strong>. In this case <strong>worker3</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> virsh <span class="nb">suspend</span> <span class="gs">worker3</span>      <span class="c1"># &lt;-- Worker node from above.</span>
<span class="go">Domain worker3 suspended</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the state of nodes and pod on <strong>admin-ws</strong>. Observe that the node status is updated only after the <cite>node-monitor-grace-period</cite> has elapsed, while the pod status update will happen after <cite>default-not-ready-toleration-seconds</cite> has passed after the node is declared not ready.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get node
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   6d2h   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker3    </span><span class="gs">Ready</span><span class="go">    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get node
<span class="go">NAME       STATUS     ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready      control-plane   6d2h   v1.29.0</span>
<span class="go">worker1    Ready      &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker2    Ready      &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker3    </span><span class="gs">NotReady</span><span class="go">   &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti pod1 -- sh
<span class="go">Error from server: error dialing backend: dial tcp 10.10.10.54:10250: i/o timeout</span>
<span class="go">to host</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME      READY     STATUS        RESTARTS   AGE</span>
<span class="go">pod1      1/1       Running       0          5m</span>
<span class="gp">root@admin-ws $&gt;</span> sleep <span class="m">200</span> <span class="c1"># WAIT FOR REPORTING TIMEOUT TO C-PLANE1</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME      READY     STATUS        RESTARTS   AGE</span>
<span class="go">pod1      1/1       Terminating   0          10m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Resume the VM on <strong>lab_machine</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> virsh resume <span class="gs">worker3</span>
<span class="go">Domain worker3 resumed</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the status of the pod again on <strong>admin-ws</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span>  kubectl get node
<span class="go">NAME       STATUS   ROLES           AGE    VERSION</span>
<span class="go">c-plane1   Ready    control-plane   6d2h   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the pod from the test-ns namespace, and the test-ns namespace also.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete namespace test-ns
<span class="go">namespace &quot;test-ns&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod --namespace<span class="o">=</span>test-ns
<span class="go">No resources found in test-ns namespace.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get namespace
<span class="go">NAME          STATUS    AGE</span>
<span class="go">default                Active   43d</span>
<span class="go">kube-node-lease        Active   43d</span>
<span class="go">kube-public            Active   43d</span>
<span class="go">kube-system            Active   43d</span>
<span class="go">kubernetes-dashboard   Active   43d</span>
</pre></div>
</div>
</section>
<section id="task-2-replicaset-controller-operations">
<h3>Task 2:  ReplicaSet controller operations<a class="headerlink" href="#task-2-replicaset-controller-operations" title="Permalink to this headline"></a></h3>
<p>In this task we will observe how a ReplicaSet is recovering a failed pod for us.</p>
<p>To reduce the time needed to detect a pod failure in case of a node becomes not ready or unreachable we will modify the configuration of the API server by adding the <code class="docutils literal notranslate"><span class="pre">--default-not-ready-toleration-seconds=30</span></code> and <code class="docutils literal notranslate"><span class="pre">--default-unreachable-toleration-seconds=30</span></code> parameters to its command line arguments.</p>
<ul class="simple">
<li><p>Edit the manifest file of the kube-apiserver on the <code class="docutils literal notranslate"><span class="pre">c-plane1</span></code> node and add the following command line arguments:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--default-not-ready-toleration-seconds=30</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--default-unreachable-toleration-seconds=30</span></code></p></li>
</ul>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1:~#</span> vi /etc/kubernetes/manifests/kube-apiserver.yaml
<span class="gp">root@c-plane1:~#</span> grep -C3 toleration /etc/kubernetes/manifests/kube-apiserver.yaml
<span class="go">    - --service-cluster-ip-range=10.96.0.0/12</span>
<span class="go">    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span>
<span class="go">    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span>
<span class="go">    </span><span class="gs">- --default-not-ready-toleration-seconds=30</span><span class="go"></span>
<span class="go">    </span><span class="gs">- --default-unreachable-toleration-seconds=30</span><span class="go"></span>
<span class="go">    image: registry.k8s.io/kube-apiserver:v1.29.0</span>
<span class="go">    imagePullPolicy: IfNotPresent</span>
<span class="go">    livenessProbe:</span>
<span class="gp">root@c-plane1:~#</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the kube-apiserver has been restarted with the new parameters:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1:~#</span> ps -ef <span class="p">|</span> grep <span class="o">[</span>k<span class="o">]</span>ube-api
<span class="go">root     1548295 1548217  4 12:25 ?        00:00:32 kube-apiserver --advertise-address=10.10.10.51 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-account-signing-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key </span><span class="gs">--default-not-ready-toleration-seconds=30</span><span class="go"> </span><span class="gs">--default-unreachable-toleration-seconds=30</span><span class="go"></span>
<span class="gp">root@c-plane1:~#</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the API server is running without the mentioned parameters, then restart the kubelet ( <code class="docutils literal notranslate"><span class="pre">systemctl</span> <span class="pre">restart</span> <span class="pre">kubelet</span></code>) on the <code class="docutils literal notranslate"><span class="pre">c-plane</span></code> machine in order to force the restart of the kube-apiserver.</p>
</div>
<ul class="simple">
<li><p>Create a ReplicaSet resource that runs <em>sleep 1000</em> in a busybox container, and it has 2 replicas. Perform the following steps on the <code class="docutils literal notranslate"><span class="pre">admin-ws</span></code> machine.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Workloads/rs1.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat rs1.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: ReplicaSet</span>
<span class="go">metadata:</span>
<span class="go">  name: rs1</span>
<span class="go">  labels:</span>
<span class="go">    app: bb</span>
<span class="go">spec:</span>
<span class="go">  replicas: 2</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">       app: bb</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      name: bbox</span>
<span class="go">      labels:</span>
<span class="go">        app: bb</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: bb</span>
<span class="go">        image: busybox</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        command:</span>
<span class="go">        - sleep</span>
<span class="go">        - &quot;1000&quot;</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f rs1.yaml
<span class="go">replicaset.apps/rs1 created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get rs -o wide
<span class="go">NAME   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES    SELECTOR</span>
<span class="go">rs1    2         2         2       26s   bb           busybox   app=bb</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS    RESTARTS   AGE   IP                NODE      ...</span>
<span class="go">rs1-p4xft   1/1     Running   0          40s   192.168.235.134   worker1   ...</span>
<span class="go">rs1-smdd4   1/1     Running   0          40s   192.168.189.68    worker3   ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Scale the replication controller to have 3 replicas</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl scale replicaset rs1 --replicas<span class="o">=</span><span class="m">3</span>
<span class="go">replicaset.apps/rs1 scaled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get replicaset -o wide
<span class="go">NAME   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES    SELECTOR</span>
<span class="go">rs1    3         3         3       96s   bb           busybox   app=bb</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS    RESTARTS   AGE    IP                NODE      ...</span>
<span class="go">rs1-p4xft   1/1     Running   0          103s   192.168.235.134   worker1   ...</span>
<span class="go">rs1-s5rkq   1/1     Running   0          27s    192.168.182.7     </span><span class="gs">worker2</span><span class="go">   ...</span>
<span class="go">rs1-smdd4   1/1     Running   0          103s   192.168.189.68    worker3   ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Simulate again the failure of a node. Suspend relevant node from <strong>lab_machine</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> virsh <span class="nb">suspend</span> <span class="gs">worker2</span>
<span class="go">Domain worker2 suspended</span>
</pre></div>
</div>
<p>With the modified API server configuration it will take approximately 70 seconds for the pod to be terminated.</p>
<ul class="simple">
<li><p>Check pod status on <strong>admin-ws</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> sleep <span class="m">70</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get node
<span class="go">NAME       STATUS     ROLES           AGE    VERSION</span>
<span class="go">c-plane1   Ready      control-plane   6d2h   v1.29.0</span>
<span class="go">worker1    Ready      &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gs">worker2    NotReady</span><span class="go">   &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker3    Ready      &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS        RESTARTS   AGE    IP                NODE      ...</span>
<span class="go">rs1-6phpd   1/1     </span><span class="gs">Running</span><span class="go">       0          3m5s   192.168.189.70    </span><span class="gs">worker3</span><span class="go">   ...</span>
<span class="go">rs1-p4xft   1/1     Running       0          11m    192.168.235.134   worker1   ...</span>
<span class="go">rs1-s5rkq   1/1     </span><span class="gs">Terminating</span><span class="go">   0          10m    192.168.182.7     </span><span class="gs">worker2</span><span class="go">   ...</span>
<span class="go">rs1-smdd4   1/1     Running       0          11m    192.168.189.68    worker3   ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Resume the node. Check the status of the pods once the node is back in the cluster.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> virsh resume worker2
<span class="go">Domain worker2 resumed</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get node
<span class="go">NAME       STATUS   ROLES           AGE    VERSION</span>
<span class="go">c-plane1   Ready    control-plane   6d2h   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gs">worker2    Ready</span><span class="go">    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          6d2h   v1.29.0</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS    RESTARTS   AGE     IP                NODE      ...</span>
<span class="go">rs1-6phpd   1/1     Running   0          4m10s   192.168.189.70    worker3   ...</span>
<span class="go">rs1-p4xft   1/1     Running   0          12m     192.168.235.134   worker1   ...</span>
<span class="go">rs1-smdd4   1/1     Running   0          12m     192.168.189.68    worker3   ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete one of the rs’s pod. Check the status of the pods again. Delete the replicaset controller.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete pod <span class="gs">rs1-6phpd</span>
<span class="go">pod &quot;rs1-6phpd&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS    RESTARTS   AGE   IP                NODE      ...</span>
<span class="go">rs1-p4xft   1/1     Running   0          14m   192.168.235.134   worker1   ...</span>
<span class="go">rs1-smdd4   1/1     Running   0          14m   192.168.189.68    worker3   ...</span>
<span class="gs">rs1-vkcdl</span><span class="go">   1/1     Running   0           </span><span class="gs">4s</span><span class="go">   192.168.182.8     worker2   ...</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete rs rs1
<span class="go">replicaset.apps &quot;rs1&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get rs
<span class="go">No resources found in default namespace.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME        READY   STATUS        RESTARTS   AGE   IP                NODE      ...</span>
<span class="go">rs1-p4xft   1/1     </span><span class="gs">Terminating</span><span class="go">   0          15m   192.168.235.134   worker1   ...</span>
<span class="go">rs1-smdd4   1/1     </span><span class="gs">Terminating</span><span class="go">   0          15m   192.168.189.68    worker3   ...</span>
<span class="go">rs1-vkcdl   1/1     </span><span class="gs">Terminating</span><span class="go">   0          72s   192.168.182.8     worker2   ...</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
</section>
<section id="task-3-working-with-deployments">
<h3>Task 3:  Working with deployments<a class="headerlink" href="#task-3-working-with-deployments" title="Permalink to this headline"></a></h3>
<p>In this task we will investigate how applications can be launched and managed in Kubernetes with the help of Deployments.</p>
<p>The goal is to deploy 2 replicas of the nginx version 1.23.0 container image, then upgrade it to 1.25.0, and finally roll back to the original version.</p>
<ul class="simple">
<li><p>Create a deployment that runs 2 replicas of nginx version 1.23.0</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Workloads/dep1.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat dep1.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: nginx-deployment</span>
<span class="go">spec:</span>
<span class="go">  replicas: 2</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">      app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: nginx:1.23.0</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        ports:</span>
<span class="go">        - containerPort: 80</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f dep1.yaml --record
<span class="go">Flag --record has been deprecated, --record will be removed in the future</span>
<span class="go">deployment.apps/nginx-deployment created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pods,rs,deploy
<span class="go">NAME                                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-deployment-54587d8b5d-2wmn4   1/1     Running   0          13s</span>
<span class="go">pod/nginx-deployment-54587d8b5d-nnx74   1/1     Running   0          13s</span>

<span class="go">NAME                                          DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   2         2         2       13s</span>

<span class="go">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx-deployment   2/2     2            2           13s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Upgrade the nginx containers to image 1.25.0</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">set</span> image deployment/nginx-deployment <span class="nv">nginx</span><span class="o">=</span>nginx:1.25.0 --record
<span class="go">Flag --record has been deprecated, --record will be removed in the future</span>
<span class="go">deployment.apps/nginx-deployment image updated</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-deployment-54587d8b5d-2wmn4   1/1     Running   0          13s</span>
<span class="go">pod/nginx-deployment-54587d8b5d-nnx74   1/1     </span><span class="gs">Terminating</span><span class="go">   0          13s</span>
<span class="go">pod/nginx-deployment-89f9774c6-zbw9z    0/1     </span><span class="gs">ContainerCreating</span><span class="go">   0          0s</span>

<span class="go">NAME                                          DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   2         2         2       13s</span>

<span class="go">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx-deployment   2/2     2            2           13s</span>

<span class="go">NAME                                         DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-89f9774c6   </span><span class="gs">2         2         1</span><span class="go">       1s</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   </span><span class="gs">1         1         1</span><span class="go">       17s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                                   READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-deployment-89f9774c6-d4rqm   1/1     Running   0          9s</span>
<span class="go">pod/nginx-deployment-89f9774c6-zbw9z   1/1     Running   0          14s</span>

<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   6d2h</span>

<span class="go">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx-deployment   2/2     2            2           2m5s</span>

<span class="go">NAME                                          DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   </span><span class="gs">0         0         0</span><span class="go">       2m5s</span>
<span class="go">replicaset.apps/nginx-deployment-89f9774c6    </span><span class="gs">2         2         2</span><span class="go">       14s</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the rollout history of the deployment, and rollback to the previous version</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl rollout <span class="nb">history</span> deployment nginx-deployment
<span class="go">deployment.apps/nginx-deployment</span>
<span class="go">REVISION  CHANGE-CAUSE</span>
<span class="go">1         kubectl apply --filename=dep1.yaml --record=true</span>
<span class="go">2         kubectl set image deployment/nginx-deployment nginx=nginx:1.25.0 --record=true</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl rollout undo deployment nginx-deployment
<span class="go">deployment.apps/nginx-deployment rolled back</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                                   READY   STATUS              RESTARTS   AGE</span>
<span class="go">pod/nginx-deployment-89f9774c6-d4rqm   1/1     </span><span class="gs">Terminating</span><span class="go">         0          6m50s</span>
<span class="go">pod/nginx-deployment-8668b5484-l57kl   1/1     Running             0          6m49s</span>
<span class="go">pod/nginx-deployment-f7ccf9478-664p6   0/1     </span><span class="gs">ContainerCreating</span><span class="go">   0          0s</span>
<span class="go">pod/nginx-deployment-f7ccf9478-jjv7q   1/1     Running             0          1s</span>

<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   70d</span>

<span class="go">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx-deployment   2/2     2            2           7m6s</span>

<span class="go">NAME                                         DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-89f9774c6   </span><span class="gs">1         1         1</span><span class="go">       6m50s</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   </span><span class="gs">2         2         1</span><span class="go">       7m6s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-deployment-54587d8b5d-5s78j   1/1     Running   0          2m45s</span>
<span class="go">pod/nginx-deployment-54587d8b5d-gxln4   1/1     Running   0          2m46s</span>

<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   6d3h</span>

<span class="go">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx-deployment   2/2     2            2           13m</span>

<span class="go">NAME                                          DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-deployment-54587d8b5d   </span><span class="gs">2         2         2</span><span class="go">       13m</span>
<span class="go">replicaset.apps/nginx-deployment-89f9774c6    </span><span class="gs">0         0         0</span><span class="go">       11m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the deployment</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete deployment nginx-deployment
<span class="go">deployment.extensions &quot;nginx-deployment&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   70d</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-4-scheduling-and-node-management">
<h2>Lab 4:  Scheduling and node management<a class="headerlink" href="#lab-4-scheduling-and-node-management" title="Permalink to this headline"></a></h2>
<section id="task-1-scheduling-pods-to-nodes-node-selector">
<h3>Task 1:  Scheduling Pods to nodes - node selector<a class="headerlink" href="#task-1-scheduling-pods-to-nodes-node-selector" title="Permalink to this headline"></a></h3>
<p>Deploy the nginx container image and make sure that it only runs on the nodes that have SSD storage. The nodes are identified by the <code class="docutils literal notranslate"><span class="pre">ssd=yes</span></code> label.</p>
<p><strong>Preparation:</strong> Label the nodes <code class="docutils literal notranslate"><span class="pre">worker1</span></code> and <code class="docutils literal notranslate"><span class="pre">worker2</span></code> with <code class="docutils literal notranslate"><span class="pre">ssd=yes</span></code>, and the nodes <code class="docutils literal notranslate"><span class="pre">worker2</span></code> and <code class="docutils literal notranslate"><span class="pre">worker3</span></code> with <code class="docutils literal notranslate"><span class="pre">spinning=yes</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl label node worker1 <span class="nv">ssd</span><span class="o">=</span>yes
<span class="go">node/worker1 labeled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl label node worker2 <span class="nv">ssd</span><span class="o">=</span>yes
<span class="go">node/worker2 labeled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl label node worker2 <span class="nv">spinning</span><span class="o">=</span>yes
<span class="go">node/worker2 labeled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl label node worker3 <span class="nv">spinning</span><span class="o">=</span>yes
<span class="go">node/worker3 labeled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get node --show-labels
<span class="go">NAME       STATUS   ROLES           AGE     VERSION   LABELS</span>
<span class="gs">c-plane1</span><span class="go">   Ready    control-plane   6d22h   v1.29.0   // lude-from-external-load-balancers=</span>
<span class="gs">worker1</span><span class="go">    Ready    &lt;none&gt;          6d22h   v1.29.0   // s.io/os=linux,</span><span class="gs">ssd=yes</span><span class="go"></span>
<span class="gs">worker2</span><span class="go">    Ready    &lt;none&gt;          6d22h   v1.29.0   // s.io/os=linux,</span><span class="gs">spinning=yes,ssd=yes</span><span class="go"></span>
<span class="gs">worker3</span><span class="go">    Ready    &lt;none&gt;          6d22h   v1.29.0   //s.io/os=linux,</span><span class="gs">spinning=yes</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a deployment named <cite>with-ssd</cite> that will start 2 nginx pods on the nodes that have the label <cite>ssd=yes</cite> using the <cite>nodeSelector</cite></p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Scheduling/nodeselector.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat nodeselector.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: with-ssd</span>
<span class="go">spec:</span>
<span class="go">  replicas: 2</span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      </span><span class="gs">nodeSelector:</span><span class="go"></span>
<span class="go">        </span><span class="gs">ssd: &quot;yes&quot;</span><span class="go"></span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: nginx</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        ports:</span>
<span class="go">        - containerPort: 80</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f nodeselector.yaml
<span class="go">deployment.apps/with-ssd created</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                        READY   STATUS    RESTARTS   AGE   IP                NODE //</span>
<span class="go">with-ssd-7cfb6b5b88-8n5cj   1/1     Running   0          10s   192.168.189.70    </span><span class="gs">worker2</span><span class="go"> //</span>
<span class="go">with-ssd-7cfb6b5b88-lhddv   1/1     Running   0          10s   192.168.235.136   </span><span class="gs">worker1</span><span class="go"> //</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Increase the number of replicas for the deployment and verify that only the <code class="docutils literal notranslate"><span class="pre">worker1</span></code> and <code class="docutils literal notranslate"><span class="pre">worker2</span></code> nodes are used.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl scale deployment with-ssd --replicas<span class="o">=</span><span class="m">4</span>
<span class="go">deployment.extensions/with-ssd scaled</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                        READY   STATUS    RESTARTS   AGE     IP                NODE //</span>
<span class="go">with-ssd-7cfb6b5b88-8n5cj   1/1     Running   0          2m28s   192.168.189.70    </span><span class="gs">worker2</span><span class="go"> //</span>
<span class="go">with-ssd-7cfb6b5b88-kvq4t   1/1     Running   0          5s      192.168.189.71    </span><span class="gs">worker2</span><span class="go"> //</span>
<span class="go">with-ssd-7cfb6b5b88-lhddv   1/1     Running   0          2m28s   192.168.235.136   </span><span class="gs">worker1</span><span class="go"> //</span>
<span class="go">with-ssd-7cfb6b5b88-pvxtv   1/1     Running   0          5s      192.168.235.137   </span><span class="gs">worker1</span><span class="go"> //</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the deployment</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete -f nodeselector.yaml
<span class="go">deployment.apps &quot;with-ssd&quot; deleted</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">No resources found in default namespace.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get deployment
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
</section>
<section id="task-2-scheduling-pods-to-nodes-node-affinities">
<h3>Task 2:  Scheduling Pods to nodes - node affinities<a class="headerlink" href="#task-2-scheduling-pods-to-nodes-node-affinities" title="Permalink to this headline"></a></h3>
<p>Node affinities broadens the possibilities on how can we assign pods to nodes. In this task your duty is to deploy 3 replicas of the redis container image and make sure that these will not run on nodes that have spinning disks. These nodes are identifies by the <code class="docutils literal notranslate"><span class="pre">spinning=yes</span></code> label.</p>
<ul class="simple">
<li><p>Create a deployment named <cite>no-spinning</cite> that will run 3 replicas of <code class="docutils literal notranslate"><span class="pre">redis</span></code>. The deployment should define a <code class="docutils literal notranslate"><span class="pre">nodeAffinity</span></code> that will match the nodes that don’t have the <code class="docutils literal notranslate"><span class="pre">spinning=yes</span></code> label.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Scheduling/node_affinity.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat node_affinity.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: no-spinning</span>
<span class="go">spec:</span>
<span class="go">  replicas: 3</span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: redis</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: redis</span>
<span class="go">    spec:</span>
<span class="go">      </span><span class="gs">affinity:</span><span class="go"></span>
<span class="go">        </span><span class="gs">nodeAffinity:</span><span class="go"></span>
<span class="go">          </span><span class="gs">requiredDuringSchedulingIgnoredDuringExecution:</span><span class="go"></span>
<span class="go">            </span><span class="gs">nodeSelectorTerms:</span><span class="go"></span>
<span class="go">            </span><span class="gs">- matchExpressions:</span><span class="go"></span>
<span class="go">                </span><span class="gs">- key: spinning</span><span class="go"></span>
<span class="go">                  </span><span class="gs">operator: NotIn</span><span class="go"></span>
<span class="go">                  </span><span class="gs">values:</span><span class="go"></span>
<span class="go">                  </span><span class="gs">- &quot;yes&quot;</span><span class="go"></span>
<span class="go">      containers:</span>
<span class="go">      - name: redis</span>
<span class="go">        image: redis</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f node_affinity.yaml
<span class="go">deployment.apps/no-spinning created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                         READY STATUS   RESTARTS  AGE  IP               NODE    //</span>
<span class="go">no-spinning-66c4bc6bd9-jkwtq   1/1     Running   0          21s   192.168.235.139   </span><span class="gs">worker1</span><span class="go"> //</span>
<span class="go">no-spinning-66c4bc6bd9-k7qdk   1/1     Running   0          21s   192.168.235.140   </span><span class="gs">worker1</span><span class="go"> //</span>
<span class="go">no-spinning-66c4bc6bd9-w6nss   1/1     Running   0          21s   192.168.235.138   </span><span class="gs">worker1</span><span class="go"> //</span>
</pre></div>
</div>
</section>
<section id="task-3-scheduling-pods-to-nodes-pod-affinities">
<h3>Task 3:  Scheduling Pods to nodes - pod affinities<a class="headerlink" href="#task-3-scheduling-pods-to-nodes-pod-affinities" title="Permalink to this headline"></a></h3>
<p>Deploy an <code class="docutils literal notranslate"><span class="pre">nginx</span></code> container image that will only run on nodes that are already running a <code class="docutils literal notranslate"><span class="pre">redis</span></code> pod deployed in the previous task.</p>
<ul class="simple">
<li><p>Create a deployment named <cite>next-to-redis</cite> that will run <code class="docutils literal notranslate"><span class="pre">nginx</span></code>. The deployment should define a <code class="docutils literal notranslate"><span class="pre">podAffinity</span></code> on pods that have the label <code class="docutils literal notranslate"><span class="pre">app=redis</span></code>, and the topology key being <code class="docutils literal notranslate"><span class="pre">kubernetes.io/hostname</span></code>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Scheduling/pod_affinity.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat pod_affinity.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: next-to-redis</span>
<span class="go">spec:</span>
<span class="go">  replicas: 1</span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      </span><span class="gs">affinity:</span><span class="go"></span>
<span class="go">        </span><span class="gs">podAffinity:</span><span class="go"></span>
<span class="go">          </span><span class="gs">requiredDuringSchedulingIgnoredDuringExecution:</span><span class="go"></span>
<span class="go">          </span><span class="gs">- labelSelector:</span><span class="go"></span>
<span class="go">              </span><span class="gs">matchExpressions:</span><span class="go"></span>
<span class="go">                </span><span class="gs">- key: app</span><span class="go"></span>
<span class="go">                  </span><span class="gs">operator: In</span><span class="go"></span>
<span class="go">                  </span><span class="gs">values:</span><span class="go"></span>
<span class="go">                   </span><span class="gs">- redis</span><span class="go"></span>
<span class="go">            </span><span class="gs">topologyKey: kubernetes.io/hostname</span><span class="go"></span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: nginx</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f pod_affinity.yaml
<span class="go">deployment.apps/next-to-redis created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">      NAME                           READY STATUS  RESTARTS AGE  IP               NODE    //</span>
<span class="go">next-to-redis-8656944fbb-ksnv4   1/1     Running   0          16s     192.168.235.141   </span><span class="gs">worker1</span><span class="go"> //</span>
<span class="go">no-spinning-66c4bc6bd9-jkwtq     1/1     Running   0          6m21s   192.168.235.139   worker1 //</span>
<span class="go">no-spinning-66c4bc6bd9-k7qdk     1/1     Running   0          6m21s   192.168.235.140   worker1 //</span>
<span class="go">no-spinning-66c4bc6bd9-w6nss     1/1     Running   0          6m21s   192.168.235.138   worker1 //</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete both deployments</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete -f node_affinity.yaml
<span class="go">deployment.apps &quot;no-spinning&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete -f pod_affinity.yaml
<span class="go">deployment.apps &quot;next-to-redis&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create again the <cite>next-to-redis</cite> deployment using the same .yaml file, and check pod status</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f pod_affinity.yaml
<span class="go">deployment.apps/next-to-redis created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="go">next-to-redis-8656944fbb-cx45s  0/1     </span><span class="gs">Pending</span><span class="go">   0          68s</span>
</pre></div>
</div>
<p>The <strong>next-to-redis</strong> pod is <strong>Pending</strong> state until the pod with label <strong>app=redis</strong> does not run. The <strong>hard pod affinity</strong> prohibits the pod from starting.</p>
<ul>
<li><p>Fix the issue to have the pod in running state. (You can watch the events in a different terminal using the <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">pod</span> <span class="pre">-o</span> <span class="pre">wide</span> <span class="pre">--watch</span></code> command.)</p>
<p>( Hint: Recreate deployment from node_affinity.yaml )</p>
</li>
<li><p>Delete the deployments created during the exercise.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete -f node_affinity.yaml
<span class="go">deployment.apps &quot;no-spinning&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete -f pod_affinity.yaml
<span class="go">deployment.apps &quot;next-to-redis&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
</section>
<section id="task-4-pod-priorities-optional">
<h3>Task 4:  Pod priorities - OPTIONAL<a class="headerlink" href="#task-4-pod-priorities-optional" title="Permalink to this headline"></a></h3>
<p>In this task we are generating a situation where a new pod cannot be scheduled due to lack of resources, and afterwards we will mitigate this situation by adding priorities to the new pod.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please clean up all the workloads you may have created so far, in order to have enough resources available for this task.</p>
</div>
<ul class="simple">
<li><p>Create a deployment with 3 replicas using the nginx image, and the memory requirement being set to 512MB. Verify that the pods belonging to this deployment are running.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Scheduling/prio*.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat prio1.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: nginx</span>
<span class="go">spec:</span>
<span class="go">  replicas: 3</span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: nginx</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        resources:</span>
<span class="go">          requests:</span>
<span class="go">             memory: &quot;512Mi&quot;</span>
<span class="gp">root@admin-ws $&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f prio1.yaml
<span class="go">deployment.apps/nginx created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                     READY   STATUS   // IP              NODE    NOMINATED NODE //</span>
<span class="go">nginx-66499b995f-5q7mx   1/1     Running  // 192.168.189.74  worker2 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-fvdlt   1/1     Running  // 192.168.182.9   worker3 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-hzjh4   1/1     Running  // 192.168.235.139 worker1 &lt;none&gt;         //</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a new deployment with 3 replicas using the busybox image, and the memory requirement being set to 512MB. Run the <code class="docutils literal notranslate"><span class="pre">sleep</span> <span class="pre">36000</span></code> command in the container. Verify that the pods belonging to this deployment are running.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat prio2.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: bb</span>
<span class="go">spec:</span>
<span class="go">  replicas: 3</span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: bb</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: bb</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: bb</span>
<span class="go">        image: busybox</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        command:</span>
<span class="go">          - sleep</span>
<span class="go">        args:</span>
<span class="go">          - &quot;36000&quot;</span>
<span class="go">        resources:</span>
<span class="go">          requests:</span>
<span class="go">             memory: &quot;512Mi&quot;</span>

<span class="gp">root@admin-ws $&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f prio2.yaml
<span class="go">deployment.apps/bb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                     READY   STATUS  //  IP              NODE    NOMINATED NODE //</span>
<span class="go">bb-7577fc9647-2j6v8      1/1     Running //  192.168.235.140 worker1 &lt;none&gt;         //</span>
<span class="go">bb-7577fc9647-cw5rd      1/1     Running //  192.168.189.75  worker2 &lt;none&gt;         //</span>
<span class="go">bb-7577fc9647-kkwdk      1/1     Running //  192.168.182.10  worker3 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-5q7mx   1/1     Running  // 192.168.189.74  worker2 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-fvdlt   1/1     Running  // 192.168.182.9   worker3 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-hzjh4   1/1     Running  // 192.168.235.139 worker1 &lt;none&gt;         //</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All pods are supposed to be running at this point. If you have Pending pods, then you have already reached the situation where the requirements of the new pod cannot be satisfied.</p>
</div>
<ul class="simple">
<li><p>Increase the number of replicas of the second deployment until you reach the resource limits, and new pods cannot be scheduled.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl scale deployment bb --replicas<span class="o">=</span><span class="m">4</span>
<span class="go">deployment.extensions/bb scaled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME                     READY   STATUS    RESTARTS   AGE</span>
<span class="go">bb-7577fc9647-2j6v8      1/1     Running   0          9m47s</span>
<span class="go">bb-7577fc9647-cw5rd      1/1     Running   0          9m47s</span>
<span class="go">bb-7577fc9647-kkwdk      1/1     Running   0          9m47s</span>
<span class="gs">bb-7577fc9647-v7tt5      0/1     Pending</span><span class="go">   0          8s</span>
<span class="go">nginx-66499b995f-5q7mx   1/1     Running   0          27m</span>
<span class="go">nginx-66499b995f-fvdlt   1/1     Running   0          27m</span>
<span class="go">nginx-66499b995f-hzjh4   1/1     Running   0          27m</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl describe pod <span class="gs">bb-7577fc9647-v7tt5</span>
<span class="go">Name:           bb-7577fc9647-v7tt5</span>
<span class="go">Namespace:      default</span>
<span class="go">Priority:       0</span>
<span class="go">Node:           &lt;none&gt;</span>
<span class="go">Labels:         app=bb</span>
<span class="go">                pod-template-hash=7577fc9647</span>
<span class="go">Annotations:    &lt;none&gt;</span>
<span class="go">Status:         Pending</span>
<span class="go">IP:</span>
<span class="go">Controlled By:  ReplicaSet/bb-7577fc9647</span>
<span class="go">Containers:</span>
<span class="go">  bb:</span>
<span class="go">    Image:      busybox</span>
<span class="go">    Port:       &lt;none&gt;</span>
<span class="go">    Host Port:  &lt;none&gt;</span>
<span class="go">    Command:</span>
<span class="go">      sleep</span>
<span class="go">    Args:</span>
<span class="go">      36000</span>
<span class="go">    Requests:</span>
<span class="go">      memory:     512Mi</span>
<span class="go">    Environment:  &lt;none&gt;</span>
<span class="go">    Mounts:</span>
<span class="go">      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vvtrj (ro)</span>
<span class="go">Conditions:</span>
<span class="go">  Type           Status</span>
<span class="go">  PodScheduled   False</span>
<span class="go">Volumes:</span>
<span class="go">  kube-api-access-vvtrj:</span>
<span class="go">    Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="go">    TokenExpirationSeconds:  3607</span>
<span class="go">    ConfigMapName:           kube-root-ca.crt</span>
<span class="go">    ConfigMapOptional:       &lt;nil&gt;</span>
<span class="go">    DownwardAPI:             true</span>

<span class="go">QoS Class:       Burstable</span>
<span class="go">Node-Selectors:  &lt;none&gt;</span>
<span class="go">Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
<span class="go">                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="go">Events:</span>
<span class="go">  Type     Reason            Age   From               Message</span>
<span class="go">  ----     ------            ---   ----               -------</span>
<span class="go">  Warning  </span><span class="gs">FailedScheduling  49s   default-scheduler  0/4 nodes are available: 1 node(s) had untolerated taint</span><span class="go"> {node-role.kubernetes.io/control-plane: }, </span><span class="gs">3 Insufficient memory.</span><span class="go"> preemption: 0/4 nodes are available: 1 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">PriorityClass</span></code> named <code class="docutils literal notranslate"><span class="pre">high-prio</span></code> and set its value to <code class="docutils literal notranslate"><span class="pre">1000</span></code>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create priorityclass high-prio --value<span class="o">=</span><span class="m">1000</span>
<span class="go">priorityclass.scheduling.k8s.io/high-prio created</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Update the definition for the second deployment (bb) to use the afore created priority class, and apply the change.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat prio3.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: Deployment</span>
<span class="go">metadata:</span>
<span class="go">  name: bb</span>
<span class="go">spec:</span>
<span class="go">  replicas: </span><span class="gs">4</span><span class="go"></span>
<span class="go">  selector:</span>
<span class="go">   matchLabels:</span>
<span class="go">    app: bb</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: bb</span>
<span class="go">    spec:</span>
<span class="go">      </span><span class="gs">priorityClassName: high-prio</span><span class="go"></span>
<span class="go">      containers:</span>
<span class="go">      - name: bb</span>
<span class="go">        image: busybox</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        command:</span>
<span class="go">          - sleep</span>
<span class="go">        args:</span>
<span class="go">          - &quot;36000&quot;</span>
<span class="go">        resources:</span>
<span class="go">          requests:</span>
<span class="go">             memory: &quot;512Mi&quot;</span>

<span class="gp">root@admin-ws $&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f prio3.yaml
<span class="go">deployment.apps/bb configured</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Watch the changes of the pods after applying the change, and check the final state.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide -w
<span class="go">NAME                   READY STATUS            // IP              NODE    NOMINATED NODE //</span>
<span class="go">bb-7577fc9647-4rcs7    1/1   Terminating       // 192.168.189.72  worker2 &lt;none&gt;         //</span>
<span class="go">bb-7577fc9647-grglx    1/1   Terminating       // 192.168.235.140 worker1 &lt;none&gt;         //</span>
<span class="go">...</span>
<span class="go">bb-b6f4f7b86-tskwb     0/1   Pending           // &lt;none&gt;          </span><span class="gs">&lt;none&gt;  worker1</span><span class="go">   //</span>
<span class="go">nginx-66499b995f-hzjh4 1/1   Terminating       // 192.168.235.143 </span><span class="gs">worker1</span><span class="go"> &lt;none&gt;    //</span>
<span class="go">nginx-66499b995f-pzgr7 0/1   Pending           // &lt;none&gt;          &lt;none&gt;  &lt;none&gt;    //</span>
<span class="go">nginx-66499b995f-pzgr7 0/1   Pending           // &lt;none&gt;          &lt;none&gt;  &lt;none&gt;    //</span>
<span class="go">nginx-66499b995f-hzjh4 0/1   Terminating       // 192.168.235.143 worker1 &lt;none&gt;    //</span>
<span class="go">bb-b6f4f7b86-tskwb     0/1   Pending           // &lt;none&gt;          </span><span class="gs">worker1 worker1</span><span class="go">   //</span>
<span class="go">bb-b6f4f7b86-tskwb     0/1   ContainerCreating // &lt;none&gt;          worker1 &lt;none&gt;    //</span>
<span class="go">bb-b6f4f7b86-tskwb     1/1   Running           // 192.168.235.141 </span><span class="gs">worker1</span><span class="go"> &lt;none&gt;    //</span>
<span class="go">^C</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME                   READY STATUS   IP              NODE    NOMINATED NODE //</span>
<span class="go">bb-b6f4f7b86-fjc77     1/1   Running  192.168.189.73  worker2 &lt;none&gt;         //</span>
<span class="go">bb-b6f4f7b86-fvhrx     1/1   Running  192.168.235.142 worker1 &lt;none&gt;         //</span>
<span class="go">bb-b6f4f7b86-lz75x     1/1   Running  192.168.182.8   worker3 &lt;none&gt;         //</span>
<span class="go">bb-b6f4f7b86-tskwb     1/1   Running  192.168.235.141 worker1 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-5q7mx 1/1   Running  192.168.189.74  worker2 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-fvdlt 1/1   Running  192.168.182.9   worker3 &lt;none&gt;         //</span>
<span class="go">nginx-66499b995f-pzgr7 0/1   </span><span class="gs">Pending</span><span class="go">  &lt;none&gt;          &lt;none&gt;  &lt;none&gt;         //</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<p>Observe that the higher priority pod has evicted the lower priority pod in order to be able to start.</p>
<ul class="simple">
<li><p>Remove all the deployments created at this task.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete deploy --all
<span class="go">deployment.apps &quot;bb&quot; deleted</span>
<span class="go">deployment.apps &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-5-accessing-the-applications">
<h2>Lab 5:  Accessing the applications<a class="headerlink" href="#lab-5-accessing-the-applications" title="Permalink to this headline"></a></h2>
<section id="task-1-working-with-services">
<h3>Task 1:  Working with services<a class="headerlink" href="#task-1-working-with-services" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create an nginx service that has 2 replicas and it is exposing port 80.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create deployment --image<span class="o">=</span>nginx nginx
<span class="go">deployment.apps/nginx created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl expose deployment nginx --port<span class="o">=</span><span class="m">80</span>
<span class="go">service/nginx exposed</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl scale deployment nginx --replicas<span class="o">=</span><span class="m">2</span>
<span class="go">deployment.extensions/nginx scaled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-554b9c67f9-jmrpn   1/1     Running   0          3m31s</span>
<span class="go">pod/nginx-554b9c67f9-zbvbl   1/1     Running   0          25s</span>


<span class="go">NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   27h</span>
<span class="go">service/nginx        ClusterIP   </span><span class="gs">10.104.60.11</span><span class="go">     &lt;none&gt;        80/TCP    73s</span>


<span class="go">NAME                    READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx   2/2     2            2           3m31s</span>

<span class="go">NAME                               DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-554b9c67f9   2         2         2       3m31s</span>

<span class="gp">root@admin-ws $&gt;</span> ssh c-plane1 curl http://<span class="gs">10.104.60.11</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>
<span class="go">html {</span>

<span class="go">...</span>

<span class="go">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span>
<span class="go">&lt;/body&gt;</span>
<span class="go">&lt;/html&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the endpoints belonging to the service</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get endpoints nginx
<span class="go">NAME    ENDPOINTS                            AGE</span>
<span class="go">nginx   192.168.182.12:80,192.168.189.77:80  4m3s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Increase the number of replicas in the nginx service, and check the endpoints again</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl scale deployment nginx --replicas<span class="o">=</span><span class="m">3</span>
<span class="go">deployment.extensions/nginx scaled</span>
<span class="gp">root@admin-ws $&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME                      READY   STATUS    RESTARTS   AGE</span>
<span class="go">nginx-554b9c67f9-jmrpn    1/1     Running   0          7m8s</span>
<span class="go">nginx-554b9c67f9-qzmln    1/1     Running   0          8s</span>
<span class="go">nginx-554b9c67f9-zbvbl    1/1     Running   0          4m2s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get endpoints nginx
<span class="go">NAME    ENDPOINTS                                              AGE</span>
<span class="go">nginx   192.168.182.12:80,192.168.189.77:80,192.168.235.144:80 5m26s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Remove the label <em>app=nginx</em> from one of the pods, and check what’s going on.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod --show-labels
<span class="go">NAME                      READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="go">nginx-554b9c67f9-jmrpn    1/1     Running   0          17m   app=nginx,pod-template-hash=</span>
<span class="go">554b9c67f9</span>
<span class="gs">nginx-554b9c67f9-qzmln</span><span class="go">    1/1     Running   0          10m   app=nginx,pod-template-hash=</span>
<span class="go">554b9c67f9</span>
<span class="go">nginx-554b9c67f9-zbvbl    1/1     Running   0          14m   app=nginx,pod-template-hash=</span>
<span class="go">554b9c67f9</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl label pod <span class="gs">nginx-554b9c67f9-qzmln</span> app-
<span class="go">pod/nginx-554b9c67f9-qzmln unlabeled</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod --show-labels
<span class="go">NAME                      READY   STATUS  //  LABELS</span>
<span class="go">nginx-554b9c67f9-h2868    1/1     Running //  app=nginx,pod-template-hash=554b9c67f9</span>
<span class="go">nginx-554b9c67f9-jmrpn    1/1     Running //  app=nginx,pod-template-hash=554b9c67f9</span>
<span class="go">nginx-554b9c67f9-qzmln    1/1     Running //  pod-template-hash=554b9c67f9</span>
<span class="go">nginx-554b9c67f9-zbvbl    1/1     Running //  app=nginx,pod-template-hash=554b9c67f9</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get endpoints nginx
<span class="go">NAME    ENDPOINTS                                                AGE</span>
<span class="go">nginx   192.168.182.12:80,192.168.189.77:80,</span><span class="gs">192.168.235.145:80</span><span class="go">   20m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Start a new busybox container and verify that the nginx service is known.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl run --image<span class="o">=</span>busybox:1.27 pod1 -- top
<span class="go">pod/pod1 created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti pod1 -- sh
<span class="gp">root@pod1 / #&gt;</span> env
<span class="go">KUBERNETES_PORT=tcp://10.96.0.1:443</span>
<span class="go">KUBERNETES_SERVICE_PORT=443</span>
<span class="go">HOSTNAME=pod1</span>
<span class="go">SHLVL=1</span>
<span class="go">HOME=/root</span>
<span class="go">NGINX_PORT_80_TCP=tcp://10.104.60.11:80</span>
<span class="go">TERM=xterm</span>
<span class="go">KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1</span>
<span class="go">NGINX_SERVICE_HOST=10.104.60.11</span>
<span class="go">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</span>
<span class="go">KUBERNETES_PORT_443_TCP_PORT=443</span>
<span class="go">KUBERNETES_PORT_443_TCP_PROTO=tcp</span>
<span class="go">NGINX_PORT=tcp://10.104.60.11:80</span>
<span class="go">NGINX_SERVICE_PORT=80</span>
<span class="go">KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443</span>
<span class="go">KUBERNETES_SERVICE_PORT_HTTPS=443</span>
<span class="go">PWD=/</span>
<span class="go">KUBERNETES_SERVICE_HOST=10.96.0.1</span>
<span class="go">NGINX_PORT_80_TCP_ADDR=10.104.60.11</span>
<span class="go">NGINX_PORT_80_TCP_PORT=80</span>
<span class="go">NGINX_PORT_80_TCP_PROTO=tcp</span>

<span class="gp">root@pod1 / #&gt;</span> nslookup nginx
<span class="go">Server:    10.96.0.10</span>
<span class="go">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span>

<span class="go">Name:      nginx</span>
<span class="go">Address 1: 10.104.60.11 nginx.default.svc.cluster.local</span>

<span class="gp">root@pod1 / #&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
<p>We can observe that the name of the service is resolvable from a pod running in the cluster. This allows workloads running in the cluster to easily reach each other with the help of the services.</p>
<ul class="simple">
<li><p>Create a new service object of type <em>NodePort</em> that is exposing port 80 of the nginx pods</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl expose deployment nginx --type<span class="o">=</span>NodePort --port<span class="o">=</span><span class="m">80</span> --name<span class="o">=</span>nginx-np
<span class="go">service/nginx-np exposed</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get service
<span class="go">NAME         TYPE         CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span>
<span class="go">kubernetes   ClusterIP    10.96.0.1        &lt;none&gt;        443/TCP        27h</span>
<span class="go">nginx        ClusterIP    10.104.60.11     &lt;none&gt;        80/TCP         25m</span>
<span class="go">nginx-np     NodePort     10.106.140.88    &lt;none&gt;        80:</span><span class="gs">31928</span><span class="go">/TCP   11s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>From your lab machine try to access the retrieved port using the addresses of your nodes</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="nv">NODES</span><span class="o">=</span><span class="s2">&quot;c-plane1 worker1 worker2 worker3&quot;</span>
<span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="nv">$NODES</span>
<span class="gp">&gt;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="gp">&gt;</span> curl <span class="si">${</span><span class="nv">i</span><span class="si">}</span>:<span class="gs">31928</span> <span class="p">|</span> head -5
<span class="gp">&gt;</span> <span class="nb">echo</span>
<span class="gp">&gt;</span> <span class="k">done</span>
<span class="go">c-plane1</span>
<span class="gp">%</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                                Dload Upload   Total   Spent    Left  Speed</span>
<span class="go">100   612  100   612    0     0  99674      0 --:--:-- --:--:-- --:--:--   99k</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>

<span class="go">worker1</span>
<span class="gp">%</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                              Dload  Upload   Total   Spent    Left  Speed</span>
<span class="go">100   612  100   612    0     0  99029      0 --:--:-- --:--:-- --:--:--   99k</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>

<span class="go">worker2</span>
<span class="gp">%</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                               Dload  Upload   Total   Spent    Left  Speed</span>
<span class="go">100   612  100   612    0     0   512k      0 --:--:-- --:--:-- --:--:--  597k</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>

<span class="go">worker3</span>
<span class="gp">%</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                               Dload  Upload   Total   Spent    Left  Speed</span>
<span class="go">100   612  100   612    0     0   272k      0 --:--:-- --:--:-- --:--:--  298k</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>
</pre></div>
</div>
<p>We can observe that the services of the type NodePort allows us to expose workloads running in the cluster (our nginx pods) to clients running outside the cluster (curl running on the lab_machine).</p>
<p>A drawback of the NodePort service is that the ports used for exposing the workloads outside the cluster are randomly allocated from the high port range. This makes the service discovery difficult, and also needs modifications of the firewalls. To overcome this Kubernetes provides the <em>LoadBalancer</em> type service. This will configure external load balancers to expose the service on well known/accepted ports and redirect traffic to the node ports.</p>
<p>In order to use <em>LoadBalancer</em> service type you need to have a controller that can interact with the underlying infrastructure to provision and configure the load balancer. In a cloud based infrastructure your cloud-provider can offer <em>Load Balancer as a Service</em> (LBaaS). In these cases the cloud-provider will also provide the controller that can interact with its infrastructure. On bare-metal/on-prem cluster you have to deploy it by yourself. The <a class="reference external" href="https://metallb.universe.tf/">MetalLB</a> project provides a solution for provisioning LoadBalancer type of services.</p>
<ul class="simple">
<li><p>Install <em>metallb</em> load balancer and configure its <em>address pool</em> and <em>l2advertisements</em>. The <em>l2advertisements</em> is responsible for servicing ARP requests.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will install the metallb using a local manifest file, but you can use the remote source:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.9/config/manifests/metallb-native.yaml
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_applications/
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f metallb-native.yaml
<span class="go">namespace/metallb-system created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/addresspools.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created</span>
<span class="go">serviceaccount/controller created</span>
<span class="go">serviceaccount/speaker created</span>
<span class="go">role.rbac.authorization.k8s.io/controller created</span>
<span class="go">role.rbac.authorization.k8s.io/pod-lister created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/metallb-system:controller created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/controller created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/pod-lister created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created</span>
<span class="go">secret/webhook-server-cert created</span>
<span class="go">service/webhook-service created</span>
<span class="go">deployment.apps/controller created</span>
<span class="go">daemonset.apps/speaker created</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Wait for all pods of metallb become <em>running</em> state. Then add an address pool from which the load-balancer can get its IP address. Configure an l2advertisement in order to make ARP work.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get po -n metallb-system
<span class="go">NAME                          READY   STATUS    RESTARTS   AGE</span>
<span class="go">controller-68bf958bf9-8cplh   1/1     Running   0          31s</span>
<span class="go">speaker-9hrfh                 1/1     Running   0          31s</span>
<span class="go">speaker-h4dzv                 1/1     Running   0          31s</span>
<span class="go">speaker-hr7dp                 1/1     Running   0          31s</span>
<span class="go">speaker-nqdqb                 1/1     Running   0          31s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f metallb-address-pool.yaml
<span class="go">ipaddresspool.metallb.io/first-pool created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get ipaddresspools -n metallb-system
<span class="go">NAME         AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES</span>
<span class="go">first-pool   true          false             [&quot;10.10.10.110-10.10.10.120&quot;]</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f metallb-advertise.yaml
<span class="go">l2advertisement.metallb.io/example created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get l2advertisements -n metallb-system
<span class="go">NAME      IPADDRESSPOOLS   IPADDRESSPOOL SELECTORS   INTERFACES</span>
<span class="go">example</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a LoadBalancer type service for the nginx deployment.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Usually, LBaaS assigns an IP address to the load-balancer, and this address is transmitted to kubernetes, where load-balancer services can get it from.</p>
<p>In our case, we need to do this with annotations.</p>
</div>
<blockquote>
<div><p>Your service manifest file looks like this:</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat depl-lb.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Service</span>
<span class="go">metadata:</span>
<span class="go">  name: nginx-lb</span>
<span class="go">  annotations:</span>
<span class="go">    metallb.universe.tf/loadBalancerIPs: 10.10.10.111</span>
<span class="go">spec:</span>
<span class="go">  ports:</span>
<span class="go">  - port: 80</span>
<span class="go">    targetPort: 80</span>
<span class="go">  selector:</span>
<span class="go">    app: nginx</span>
<span class="go">  </span><span class="gs">type: LoadBalancer</span><span class="go"></span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>Create <em>nginx-lb</em> service resource and test it.</p></li>
</ul>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f depl-lb.yaml
<span class="go">service/nginx-lb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get svc nginx-lb
<span class="go">NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE</span>
<span class="go">nginx-lb   </span><span class="gs">LoadBalancer</span><span class="go">   10.96.226.252   </span><span class="gs">10.10.10.111</span><span class="go">   80:31615/TCP   33s</span>
<span class="gp">root@admin-ws $&gt;</span> curl <span class="gs">10.10.10.111</span>
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can access your deployment from admin-ws, which is located outside of the cluster.</p>
</div>
<ul class="simple">
<li><p>Delete the nginx, nginx-np  and nginx-lb services, the nginx deployment, and any pods that may have left over from the exercise</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete svc nginx-lb
<span class="go">service &quot;nginx-lb&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete svc nginx-np
<span class="go">service &quot;nginx-np&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete svc nginx
<span class="go">service &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete deployment nginx
<span class="go">deployment.extensions &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-554b9c67f9-qzmln   1/1     Running   0          25m</span>
<span class="go">pod/pod1                     1/1     Running   0          7m26s</span>


<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   27h</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod --all
<span class="go">pod &quot;nginx-554b9c67f9-qzmln&quot; deleted</span>
<span class="go">pod &quot;pod1&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-2-working-with-ingress">
<h3>Task 2:  Working with Ingress<a class="headerlink" href="#task-2-working-with-ingress" title="Permalink to this headline"></a></h3>
<p>In many cases, you will have a limited number of public IP addresses which may be assigned to your load-balancer(s). If you want to make multiple HTTP-based services accessible from the Internet on the same IP Address, you will need to use an Ingress resource to ensure that the different URLs serve the correct endpoints. In this setup the ingress controllers will be exposed with the help of a load balancer service (so they are publicly reachable) and these ingress controllers will ingest Ingress resources which will configure the routing of the incoming requests to the various services running in the cluster.</p>
<ul class="simple">
<li><p>Use the <em>ingress-controller.yaml</em> file from the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Accessing_applications</span></code> directory to create the ingress controller and the default backend.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will install the ingress-controller using a local manifest file, but you can use the remote source:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/cloud/deploy.yaml
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_applications/
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f ingress-controller.yaml
<span class="go">namespace/ingress-nginx created</span>
<span class="go">serviceaccount/ingress-nginx created</span>
<span class="go">serviceaccount/ingress-nginx-admission created</span>
<span class="go">role.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">role.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">configmap/ingress-nginx-controller created</span>
<span class="go">service/ingress-nginx-controller created</span>
<span class="go">service/ingress-nginx-controller-admission created</span>
<span class="go">deployment.apps/ingress-nginx-controller created</span>
<span class="go">job.batch/ingress-nginx-admission-create created</span>
<span class="go">job.batch/ingress-nginx-admission-patch created</span>
<span class="go">ingressclass.networking.k8s.io/nginx created</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created</span>
</pre></div>
</div>
<p>Observe that the ingress-controller automatically creates a load-balancer service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get svc -n ingress-nginx
<span class="go">NAME                                 TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)                      AGE</span>
<span class="go">ingress-nginx-controller             </span><span class="gs">LoadBalancer   10.96.63.228   10.10.10.110   80:31729/TCP,443:31810/TCP</span><span class="go">   32m</span>
<span class="go">ingress-nginx-controller-admission   ClusterIP      10.108.32.1    &lt;none&gt;         443/TCP                      32m</span>
</pre></div>
</div>
<p>You can set the load-balancer specific configuration parameters as <em>annotation</em> of this service. These parameters are cloud-provider specific.</p>
<ul class="simple">
<li><p>Change IP address of the load-balancer to  <em>10.10.10.111</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl annotate svc -n ingress-nginx ingress-nginx-controller metallb.universe.tf/loadBalancerIPs<span class="o">=</span><span class="m">10</span>.10.10.111
<span class="go">service/ingress-nginx-controller annotated</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get svc -n ingress-nginx  ingress-nginx-controller
<span class="go">NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)                      AGE</span>
<span class="go">ingress-nginx-controller   LoadBalancer   10.96.63.228   </span><span class="gs">10.10.10.111</span><span class="go">   80:31729/TCP,443:31810/TCP   66m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a service that runs the nginx image, and expose it. This ClusterIP service will be the service backend of ingress.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create deployment --image<span class="o">=</span>nginx nginx
<span class="go">deployment.apps/nginx created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl expose deployment nginx --port<span class="o">=</span><span class="m">80</span>
<span class="go">service/nginx exposed</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/nginx-748c667d99-985r7   1/1     Running   0          22s</span>

<span class="go">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   64d</span>
<span class="gs">service/nginx</span><span class="go">        ClusterIP   10.105.71.131   &lt;none&gt;        </span><span class="gs">80/TCP</span><span class="go">    12s</span>

<span class="go">NAME                    READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/nginx   1/1     1            1           22s</span>

<span class="go">NAME                               DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/nginx-748c667d99   1         1         1       22s</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>At this point, you should select a hostname for your service which is accessible from outside. This typically means that the ingress IP address must be configured in the domain’s DNS server, because in the ingress definition, the <em>spec.rules.host</em> field must be a host name, and not an IP address. Your lab environment does not have a configurable DNS server, so you will need to use a different solution.</p>
<ul class="simple">
<li><p>For access from web you can use <em>nip.io</em> wildcard DNS solution which maps your IP based host name to IP address.</p></li>
<li><p>Add the <em>load-balancer IP address</em> and <em>hostname</em> referenced by <em>ingress</em> to you local <em>/etc/hosts</em> file on client machine. (On the Guacamole servers we prepared the hosts file)</p></li>
</ul>
</div>
<ul class="simple">
<li><p>Verify your <em>ingress-lb.yaml</em> inside of <em>/labfiles/k8s/Accessing_applications</em> directory.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_applications
<span class="gp">root@admin-ws $&gt;</span> cat ingress-lb.yaml
<span class="go">apiVersion: networking.k8s.io/v1</span>
<span class="go">kind: Ingress</span>
<span class="go">metadata:</span>
<span class="go">  name: ingress-lb</span>
<span class="go">  namespace: default</span>
<span class="go">spec:</span>
<span class="go">  ingressClassName: nginx</span>
<span class="go">  rules:</span>
<span class="go">  - host: </span><span class="gs">www.10.10.10.111.nip.io</span><span class="go"></span>
<span class="go">    http:</span>
<span class="go">      paths:</span>
<span class="go">      - backend:</span>
<span class="go">          service:</span>
<span class="go">            name: </span><span class="gs">nginx</span><span class="go"></span>
<span class="go">            port:</span>
<span class="go">              number: </span><span class="gs">80</span><span class="go"></span>
<span class="go">        path: /</span>
<span class="go">        pathType: Exact</span>
<span class="go">  - host: </span><span class="gs">www.111.student</span><span class="go"></span>
<span class="go">    http:</span>
<span class="go">      paths:</span>
<span class="go">      - backend:</span>
<span class="go">          service:</span>
<span class="go">            name: </span><span class="gs">nginx</span><span class="go"></span>
<span class="go">            port:</span>
<span class="go">              number: </span><span class="gs">80</span><span class="go"></span>
<span class="go">        path: /</span>
<span class="go">        pathType: Exact</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create ingress resource using this file.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f ingress-lb.yaml
<span class="go">ingress.networking.k8s.io/ingress-lb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl describe ingress ingress-lb
<span class="go">Name:             ingress-lb</span>
<span class="go">Labels:           &lt;none&gt;</span>
<span class="go">Namespace:        default</span>
<span class="go">Address:          10.10.10.111</span>
<span class="go">Ingress Class:    nginx</span>
<span class="go">Default backend:  &lt;default&gt;</span>
<span class="go">Rules:</span>
<span class="go">  Host                 Path  Backends</span>
<span class="go">  ----                 ----  --------</span>
<span class="go">  www.10.10.10.111.nip.io</span>
<span class="go">                       /   nginx:80 (192.168.182.6:80)</span>
<span class="go">  www.111.student</span>
<span class="go">                       /   nginx:80 (192.168.182.6:80)</span>
<span class="go">Annotations:           &lt;none&gt;</span>
<span class="go">Events:</span>
<span class="go">  Type    Reason  Age                From                      Message</span>
<span class="go">  ----    ------  ----               ----                      -------</span>
<span class="go">  Normal  Sync    44s (x2 over 73s)  nginx-ingress-controller  Scheduled for sync</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Add the <em>www.111.student</em> to /etc/hosts on <em>admin-ws</em> and check it.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">echo</span> <span class="s2">&quot;10.10.10.111 www.111.student&quot;</span> &gt;&gt; /etc/hosts
<span class="gp">root@admin-ws $&gt;</span> getent hosts www.111.student
<span class="go">10.10.10.111    www.111.student</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the connection to your nginx service from <em>admin-ws</em> which not part of the cluster.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> curl http://www.10.10.10.111.nip.io
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>
<span class="go">...</span>
<span class="gp">root@admin-ws $&gt;</span> curl http://www.111.student
<span class="go">&lt;!DOCTYPE html&gt;</span>
<span class="go">&lt;html&gt;</span>
<span class="go">&lt;head&gt;</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="go">&lt;style&gt;</span>
<span class="go">...</span>
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can check these urls from the <em>guacamole desktop</em> using your web-browser. Do not forget to start the <em>tunnel</em>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As you can see from this exercise, ingress is a great way to separate different services that are available on the same IP address. This eliminates the need for multiple load-balancers, which means simpler configuration and lower costs.</p>
</div>
</section>
<section id="task-3-using-ingress-for-tcp-forwarding-optional">
<h3>Task 3:  Using Ingress for TCP forwarding (OPTIONAL)<a class="headerlink" href="#task-3-using-ingress-for-tcp-forwarding-optional" title="Permalink to this headline"></a></h3>
<p>In this task you will configure your <em>ingress-controller</em> to forward 25/TCP port to a <em>mail</em> service resource.</p>
<ul class="simple">
<li><p>Create a deployment named <em>mail</em> and expose it.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create deployment mail --image namshi/smtp
<span class="go">deployment.apps/mail created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl expose deployment mail --port <span class="m">25</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get svc mail
<span class="go">NAME   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">mail   ClusterIP   10.111.55.246   &lt;none&gt;        25/TCP    9m59s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a <em>ConfigMap</em> resource which defines the port forwarding and edit <em>ingress-controller</em> deployment in order to use it.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will discuss ConfigMaps in <em>Persistent storage</em> module.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat ingress-tcp.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: ConfigMap</span>
<span class="go">metadata:</span>
<span class="go">  name: tcp-services</span>
<span class="go">  namespace: ingress-nginx</span>
<span class="go">data:</span>
<span class="go">  </span><span class="gs">25: &quot;default/mail:25&quot;</span><span class="go"></span>

<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f ingress-tcp.yaml
<span class="go">configmap/tcp-services created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl edit deployments.apps -n ingress-nginx ingress-nginx-controller
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span>...

   containers:
    - args:
      - /nginx-ingress-controller
      <span class="gs">- --tcp-services-configmap=ingress-nginx/tcp-services</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Edit <em>ingress-nginx-controller</em> load-balancer service resource to accept 25/TCP connections.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl edit svc -n ingress-nginx ingress-nginx-controller
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">...</span>


<span class="go">ports:</span>
<span class="go">  - appProtocol: http</span>
<span class="go">    name: http</span>
<span class="go">    nodePort: 31729</span>
<span class="go">    port: 80</span>
<span class="go">    protocol: TCP</span>
<span class="go">    targetPort: http</span>
<span class="go">  - appProtocol: https</span>
<span class="go">    name: https</span>
<span class="go">    nodePort: 31810</span>
<span class="go">    port: 443</span>
<span class="go">    protocol: TCP</span>
<span class="go">    targetPort: https</span>
<span class="go">  </span><span class="gs">- name: mail</span><span class="go"></span>
<span class="go">    </span><span class="gs">port: 25</span><span class="go"></span>
<span class="go">    </span><span class="gs">protocol: TCP</span><span class="go"></span>
<span class="go">    </span><span class="gs">targetPort: 25</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Test mail service from <em>admin-ws</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> nc <span class="m">10</span>.10.10.111 <span class="m">25</span>
<span class="go">220 mail-546f7c985c-cgbtl ESMTP Exim 4.92 Fri, 02 Feb 2024 13:23:16 +0000</span>

<span class="go">&lt;Press CTRL+C&gt;</span>
</pre></div>
</div>
</section>
<section id="id1">
<h3>Task 4:  Cleanup<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Remove the ingress, and the associated service and deployment.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete ingress ingress-lb
<span class="go">ingress.networking.k8s.io &quot;ingress-lb&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete svc --all
<span class="go">service &quot;kubernetes&quot; deleted</span>
<span class="go">service &quot;mail&quot; deleted</span>
<span class="go">service &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete deployment --all
<span class="go">deployment.apps &quot;mail&quot; deleted</span>
<span class="go">deployment.apps &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   59s</span>
<span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Accessing_applications/
<span class="gp">root@admin-ws $&gt;</span> kubectl delete -f ingress-controller.yaml
<span class="go">namespace &quot;ingress-nginx&quot; deleted</span>
<span class="go">serviceaccount &quot;ingress-nginx&quot; deleted</span>
<span class="go">serviceaccount &quot;ingress-nginx-admission&quot; deleted</span>
<span class="go">role.rbac.authorization.k8s.io &quot;ingress-nginx&quot; deleted</span>
<span class="go">role.rbac.authorization.k8s.io &quot;ingress-nginx-admission&quot; deleted</span>
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;ingress-nginx&quot; deleted</span>
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;ingress-nginx-admission&quot; deleted</span>
<span class="go">rolebinding.rbac.authorization.k8s.io &quot;ingress-nginx&quot; deleted</span>
<span class="go">rolebinding.rbac.authorization.k8s.io &quot;ingress-nginx-admission&quot; deleted</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;ingress-nginx&quot; deleted</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;ingress-nginx-admission&quot; deleted</span>
<span class="go">configmap &quot;ingress-nginx-controller&quot; deleted</span>
<span class="go">service &quot;ingress-nginx-controller&quot; deleted</span>
<span class="go">service &quot;ingress-nginx-controller-admission&quot; deleted</span>
<span class="go">deployment.apps &quot;ingress-nginx-controller&quot; deleted</span>
<span class="go">job.batch &quot;ingress-nginx-admission-create&quot; deleted</span>
<span class="go">job.batch &quot;ingress-nginx-admission-patch&quot; deleted</span>
<span class="go">ingressclass.networking.k8s.io &quot;nginx&quot; deleted</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io &quot;ingress-nginx-admission&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> cat metallb-*<span class="p">|</span>kubectl delete -f -
<span class="go">namespace &quot;metallb-system&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;addresspools.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;bfdprofiles.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;bgpadvertisements.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;bgppeers.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;communities.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;ipaddresspools.metallb.io&quot; deleted</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io &quot;l2advertisements.metallb.io&quot; deleted</span>
<span class="go">serviceaccount &quot;controller&quot; deleted</span>
<span class="go">serviceaccount &quot;speaker&quot; deleted</span>
<span class="go">role.rbac.authorization.k8s.io &quot;controller&quot; deleted</span>
<span class="go">role.rbac.authorization.k8s.io &quot;pod-lister&quot; deleted</span>
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;metallb-system:controller&quot; deleted</span>
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;metallb-system:speaker&quot; deleted</span>
<span class="go">rolebinding.rbac.authorization.k8s.io &quot;controller&quot; deleted</span>
<span class="go">rolebinding.rbac.authorization.k8s.io &quot;pod-lister&quot; deleted</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;metallb-system:controller&quot; deleted</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;metallb-system:speaker&quot; deleted</span>
<span class="go">secret &quot;webhook-server-cert&quot; deleted</span>
<span class="go">service &quot;webhook-service&quot; deleted</span>
<span class="go">deployment.apps &quot;controller&quot; deleted</span>
<span class="go">daemonset.apps &quot;speaker&quot; deleted</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io &quot;metallb-webhook-configuration&quot; deleted</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-6-using-persistent-storage">
<h2>Lab 6:  Using persistent storage<a class="headerlink" href="#lab-6-using-persistent-storage" title="Permalink to this headline"></a></h2>
<section id="task-1-share-a-volume-in-two-containers">
<h3>Task 1:  Share a volume in two containers<a class="headerlink" href="#task-1-share-a-volume-in-two-containers" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a pod with 2 busybox containers that are sharing the same volume of <em>emptyDir</em> type. The first container should mount it as <em>/data</em>, while the second as <em>/input</em> .</p></li>
</ul>
<p>You can find <code class="docutils literal notranslate"><span class="pre">shvol.yaml</span></code> in <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Persistent_storage</span></code> directory.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Persistent_storage/shvol.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat shvol.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">    name: shvol1</span>
<span class="go">    namespace: default</span>

<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - image: busybox</span>
<span class="go">    command:</span>
<span class="go">    - sleep</span>
<span class="go">    - &quot;3600&quot;</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - mountPath: /data</span>
<span class="go">      name: test</span>
<span class="go">    name: processor</span>
<span class="go">  - image: busybox</span>
<span class="go">    command:</span>
<span class="go">    - sleep</span>
<span class="go">    - &quot;3600&quot;</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - mountPath: /input</span>
<span class="go">      name: test</span>
<span class="go">    name: reader</span>
<span class="go">  volumes:</span>
<span class="go">  - name: test</span>
<span class="go">    emptyDir: {}</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f shvol.yaml
<span class="go">pod/shvol1 created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME      READY     STATUS              RESTARTS   AGE</span>
<span class="go">shvol1    2/2       Running   0          29s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Execute an interactive shell in the containers and test the availability of the mountpoints, and the sharing of data</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> shvol1 --container<span class="o">=</span>reader -ti -- sh
<span class="gp">root@shvol1-reader #&gt;</span> df -h /input
<span class="go">Filesystem                Size      Used Available Use% Mounted on</span>
<span class="go">/dev/vda1                 36.8G    4.1G     32.7G  11% /input</span>
<span class="gp">root@shvol1-reader #&gt;</span> <span class="nb">echo</span> reader &gt; /input/f1
<span class="gp">root@shvol1-reader #&gt;</span> cat /input/f1
<span class="go">reader</span>
<span class="gp">root@shvol1-reader #&gt;</span> <span class="nb">exit</span>
<span class="gp">root@admin-ws $&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> shvol1 --container<span class="o">=</span>processor -ti -- sh
<span class="gp">root@shvol1-processor #&gt;</span> df -h /data
<span class="go">Filesystem                Size     Used Available  Use% Mounted on</span>
<span class="go">/dev/vda1                 36.8G    4.1G     32.7G  11% /data</span>
<span class="gp">root@shvol1-processor #&gt;</span> cat /data/f1
<span class="go">reader</span>
<span class="gp">root@shvol1-processor #&gt;</span> <span class="nb">echo</span> processor &gt;&gt; /data/f1
<span class="gp">root@shvol1-processor #&gt;</span> cat /data/f1
<span class="go">reader</span>
<span class="go">processor</span>
<span class="gp">root@shvol1-processor #&gt;</span> <span class="nb">exit</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span>  shvol1 --container<span class="o">=</span>reader -ti -- cat /input/f1
<span class="go">reader</span>
<span class="go">processor</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that nfs server is sharing the /vol1, /vol2, and the /vol3 directories on your <strong>service</strong> node using <em>showmount -e</em> command on <strong>service</strong> node.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@service $&gt;</span> showmount -e
<span class="go">Export list for service:</span>
<span class="go">/vol3 *</span>
<span class="go">/vol2 *</span>
<span class="go">/vol1 *</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Review the content of the nfs-pv.yml file from directory <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Persistent_storage</span></code>, and use it to create the persistent volumes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Persistent_storage
<span class="gp">root@admin-ws $&gt;</span> cat nfs-pv.yml
<span class="go">---</span>
<span class="go">apiVersion: v1</span>
<span class="go">kind: PersistentVolume</span>
<span class="go">metadata:</span>
<span class="go">  name: pv0001</span>
<span class="go">spec:</span>
<span class="go">  capacity:</span>
<span class="go">    storage: 15Gi</span>
<span class="go">  accessModes:</span>
<span class="go">    - ReadWriteOnce</span>
<span class="go">  nfs:</span>
<span class="go">    server: 10.10.10.61</span>
<span class="go">    path: &quot;/vol1&quot;</span>
<span class="go">  mountOptions:</span>
<span class="go">    - nfsvers=4.2</span>
<span class="go">---</span>
<span class="go">apiVersion: v1</span>
<span class="go">kind: PersistentVolume</span>
<span class="go">metadata:</span>
<span class="go">  name: pv0002</span>
<span class="go">spec:</span>
<span class="go">  capacity:</span>
<span class="go">    storage: 2Gi</span>
<span class="go">  accessModes:</span>
<span class="go">    - ReadWriteOnce</span>
<span class="go">  nfs:</span>
<span class="go">    server: 10.10.10.61</span>
<span class="go">    path: &quot;/vol2&quot;</span>
<span class="go">  mountOptions:</span>
<span class="go">    - nfsvers=4.2</span>
<span class="go">---</span>
<span class="go">apiVersion: v1</span>
<span class="go">kind: PersistentVolume</span>
<span class="go">metadata:</span>
<span class="go">  name: pv0003</span>
<span class="go">spec:</span>
<span class="go">  capacity:</span>
<span class="go">    storage: 500Mi</span>
<span class="go">  accessModes:</span>
<span class="go">    - ReadWriteOnce</span>
<span class="go">  nfs:</span>
<span class="go">    server: 10.10.10.61</span>
<span class="go">    path: &quot;/vol3&quot;</span>
<span class="go">  mountOptions:</span>
<span class="go">    - nfsvers=4.2</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f nfs-pv.yml
<span class="go">persistentvolume/pv0001 created</span>
<span class="go">persistentvolume/pv0002 created</span>
<span class="go">persistentvolume/pv0003 created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pv
<span class="go">NAME      CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS      CLAIM //   AGE</span>
<span class="go">pv0001    15Gi       RWO           Retain          Available         //   25s</span>
<span class="go">pv0002    2Gi        RWO           Retain          Available         //   25s</span>
<span class="go">pv0003    500Mi      RWO           Retain          Available         //   25s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a persistent volume claim for 1.5G of storage capacity. Identify the persistent volume that is backing the claim</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat nfs-pvc.yml
<span class="go">kind: PersistentVolumeClaim</span>
<span class="go">apiVersion: v1</span>
<span class="go">metadata:</span>
<span class="go">  name: nfs-pvc1</span>
<span class="go">spec:</span>
<span class="go">  accessModes:</span>
<span class="go">    - ReadWriteOnce</span>
<span class="go">  resources:</span>
<span class="go">    requests:</span>
<span class="go">      storage: </span><span class="gs">1.5Gi</span><span class="go"></span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f nfs-pvc.yml
<span class="go">persistentvolumeclaim/nfs-pvc1 created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pvc
<span class="go">NAME       STATUS    VOLUME    CAPACITY   ACCESSMODES   STORAGECLASS   AGE</span>
<span class="go">nfs-pvc1   Bound     </span><span class="gs">pv0002</span><span class="go">    </span><span class="gs">2Gi</span><span class="go">        RWO                          6s</span>
</pre></div>
</div>
<p>Observe that the PVC has been bound to the PV with the best fit.</p>
<ul class="simple">
<li><p>Create a pod that is mounting this volume on /mnt/nfs1, and generate some content in it.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat nfs-pod.yml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: nfs</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - name: nfs</span>
<span class="go">    image: nginx</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - </span><span class="gs">mountPath: &quot;/mnt/nfs1&quot;</span><span class="go"></span>
<span class="go">      </span><span class="gs">name: nfsvol1</span><span class="go"></span>
<span class="go">  volumes:</span>
<span class="go">  - </span><span class="gs">name: nfsvol1</span><span class="go"></span>
<span class="go">    persistentVolumeClaim:</span>
<span class="go">      </span><span class="gs">claimName: nfs-pvc1</span><span class="go"></span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f nfs-pod.yml
<span class="go">pod/nfs created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the <em>nfs</em> pod status.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod nfs
<span class="go">NAME   READY   STATUS              RESTARTS   AGE</span>
<span class="go">nfs    0/1     ContainerCreating   0          93s</span>
</pre></div>
</div>
<p>The nfs pod remains in <strong>ContainerCreating</strong> state. Check with <em>kubectl describe pod</em> command why?</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl describe pod nfs
<span class="go">Name:             nfs</span>
<span class="go">Namespace:        default</span>
<span class="go">Priority:         0</span>
<span class="go">Service Account:  default</span>
<span class="go">Node:             worker1/10.10.10.52</span>
<span class="go">Start Time:       Fri, 02 Feb 2024 13:23:16 +0000</span>
<span class="go">Labels:           &lt;none&gt;</span>
<span class="go">Annotations:      &lt;none&gt;</span>
<span class="go">Status:           Pending</span>
<span class="go">...</span>

<span class="go">Events:</span>
<span class="go">  Type     Reason       Age               From               Message</span>
<span class="go">  ----     ------       ----              ----               -------</span>
<span class="go">  Normal   Scheduled    19s               default-scheduler  Successfully assigned default/nfs to worker1</span>
<span class="go">  Warning  </span><span class="gs">FailedMount</span><span class="go">  3s (x6 over 19s)  kubelet            MountVolume.SetUp failed for volume &quot;pv0002&quot; : mount failed: exit status 32</span>
<span class="go">Mounting command: mount</span>
<span class="go">Mounting arguments: </span><span class="gs">-t nfs -o nfsvers=4.2 10.10.10.61:/vol2 /var/lib/kubelet/pods/80e5817d-c059-44d0-99fe-b15e402789db/volumes/kubernetes.io~nfs/pv0002</span><span class="go"></span>
<span class="go">Output: mount: /var/lib/kubelet/pods/80e5817d-c059-44d0-99fe-b15e402789db/volumes/kubernetes.io~nfs/pv0002: bad option; </span><span class="gs">for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.&lt;type&gt; helper program.</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>You can see that the kubelet cannot mount the nfs file system. Install the nfs filesystem on the worker nodes. Since we will also use the cifs filesystem in later exercises, install that as well.</p></li>
<li><p>Open another session to <strong>lab_machine</strong> and run shell script, which installs filesystems on worker nodes.</p></li>
<li><p>In <em>admin-ws</em> session observe the change of pod</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod nfs -w
<span class="go">NAME   READY   STATUS              RESTARTS   AGE</span>
<span class="go">nfs    0/1     ContainerCreating   0          30s</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> cat /labfiles/k8s/Persistent_storage/install_filesystems.sh
<span class="gp">#</span>!/bin/bash

<span class="go">for node in worker{1..3}</span>
<span class="go">  do</span>
<span class="go">     ssh ${node} &quot;apt update &amp;&amp; apt install -y nfs-common cifs-utils&quot;</span>
<span class="go">  done</span>
<span class="gp">root@lab_machine $&gt;</span> /labfiles/k8s/Persistent_storage/install_filesystems.sh
<span class="go">Warning: Permanently added &#39;worker1,10.10.10.52&#39; (ECDSA) to the list of known hosts.</span>

<span class="go">...</span>

<span class="go">Service restarts being deferred:</span>
<span class="go"> systemctl restart networkd-dispatcher.service</span>
<span class="go"> systemctl restart systemd-logind.service</span>
<span class="go"> systemctl restart unattended-upgrades.service</span>
<span class="go"> systemctl restart user@0.service</span>

<span class="go">No containers need to be restarted.</span>

<span class="go">No user sessions are running outdated binaries.</span>

<span class="go">No VM guests are running outdated hypervisor (qemu) binaries on this host.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>In <em>admin-ws</em> session you can see if nfs filesystem is installed on node wich runs the pod.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod nfs -w
<span class="go">NAME   READY   STATUS              RESTARTS   AGE</span>
<span class="go">nfs    0/1     ContainerCreating   0          30s</span>
<span class="go">nfs    0/1     ContainerCreating   0          2m16s</span>
<span class="go">nfs    1/1     </span><span class="gs">Running</span><span class="go">             0          2m17s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Show filesystem mount inside of pod and create a file inside of it.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti nfs -- bash
<span class="gp">root@nfs $&gt;</span> df -h /mnt/nfs1/
<span class="go">Filesystem         Size  Used Avail Use% Mounted on</span>
<span class="gs">10.10.10.61:/vol2   39G  2.3G   37G   6% /mnt/nfs1</span><span class="go"></span>
<span class="gp">root@nfs $&gt;</span> <span class="nb">echo</span> <span class="s2">&quot;Hello world!&quot;</span> &gt; /mnt/nfs1/f1
<span class="gp">root@nfs $&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the pod, the claim and the persistent volume, and verify that the content is still on the nfs share</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete pod nfs shvol1
<span class="go">pod &quot;nfs&quot; deleted</span>
<span class="go">pod &quot;shvol1&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pvc nfs-pvc1
<span class="go">persistentvolumeclaim &quot;nfs-pvc1&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pv --all
<span class="go">persistentvolume &quot;pv0001&quot; deleted</span>
<span class="go">persistentvolume &quot;pv0002&quot; deleted</span>
<span class="go">persistentvolume &quot;pv0003&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> ssh service <span class="s2">&quot;cat /vol2/f1&quot;</span>
<span class="go">Warning: Permanently added &#39;service&#39; (ED25519) to the list of known hosts.</span>
<span class="gs">Hello world!</span><span class="go"></span>
</pre></div>
</div>
</section>
<section id="task-2-dynamically-provision-a-pvc">
<h3>Task 2:  Dynamically provision a PVC<a class="headerlink" href="#task-2-dynamically-provision-a-pvc" title="Permalink to this headline"></a></h3>
<p>Integrate <em>smb CSI driver</em> service to kubernetes cluster to dynamically manage/allocate storage capacity for PVs from a <em>cifs</em> server running on <em>service</em> node. Define a PVC and trigger this method of PV allocation.</p>
<ul class="simple">
<li><p>Install <em>smb CSI driver</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Persistent_storage
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f csi-driver-smb.yaml
<span class="go">serviceaccount/csi-smb-controller-sa created</span>
<span class="go">serviceaccount/csi-smb-node-sa created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/smb-external-provisioner-role created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/smb-csi-provisioner-binding created</span>
<span class="go">daemonset.apps/csi-smb-node created</span>
<span class="go">deployment.apps/csi-smb-controller created</span>
<span class="go">csidriver.storage.k8s.io/smb.csi.k8s.io created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all -n kube-system -l app.kubernetes.io/name<span class="o">=</span>csi-driver-smb
<span class="go">NAME                                      READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/csi-smb-controller-6dbcb8dbc8-ptw7r   3/3     Running   0          4m17s</span>
<span class="go">pod/csi-smb-node-74pqb                    3/3     Running   0          4m17s</span>
<span class="go">pod/csi-smb-node-87m7c                    3/3     Running   0          4m17s</span>
<span class="go">pod/csi-smb-node-9bmdh                    3/3     Running   0          4m17s</span>
<span class="go">pod/csi-smb-node-bw9xl                    3/3     Running   0          4m17s</span>

<span class="go">NAME                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="go">daemonset.apps/csi-smb-node   4         4         </span><span class="gs">4</span><span class="go">       4            4           kubernetes.io/os=linux   4m17s</span>

<span class="go">NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/csi-smb-controller   1/1     1            1           4m17s</span>

<span class="go">NAME                                            DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/csi-smb-controller-6dbcb8dbc8   1         1         1       4m17s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Add a <em>secret</em> resource to the cluster which contains credential to <em>cifs</em> server running on <em>service</em> node.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat smbcred.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Secret</span>
<span class="go">metadata:</span>
<span class="go">  name: smbcred</span>
<span class="go">  namespace: default</span>
<span class="go">type: Opaque</span>
<span class="go">data:</span>
<span class="go">  password: c3R1ZGVudDEyMw==</span>
<span class="go">  username: c3R1ZGVudA==</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f smbcred.yaml
<span class="go">secret/smbcred created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a <cite>StorageClass</cite> object to use <cite>smb CSI</cite> service to dynamically allocate PVs</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat smb-storage-class.yml
<span class="go">apiVersion: storage.k8s.io/v1</span>
<span class="go">kind: StorageClass</span>
<span class="go">metadata:</span>
<span class="go">  name: smb</span>
<span class="go">provisioner: smb.csi.k8s.io</span>
<span class="go">parameters:</span>
<span class="go">  source: &quot;//10.10.10.61/tmp&quot;</span>
<span class="gp">  #</span> <span class="k">if</span> csi.storage.k8s.io/provisioner-secret is provided, will create a sub directory
<span class="gp">  #</span> with PV name under <span class="nb">source</span>
<span class="go">  csi.storage.k8s.io/provisioner-secret-name: &quot;smbcred&quot;</span>
<span class="go">  csi.storage.k8s.io/provisioner-secret-namespace: &quot;default&quot;</span>
<span class="go">  csi.storage.k8s.io/node-stage-secret-name: &quot;smbcred&quot;</span>
<span class="go">  csi.storage.k8s.io/node-stage-secret-namespace: &quot;default&quot;</span>
<span class="go">reclaimPolicy: Delete  # available values: Delete, Retain</span>
<span class="go">volumeBindingMode: Immediate</span>
<span class="go">mountOptions:</span>
<span class="go">  - dir_mode=0777</span>
<span class="go">  - file_mode=0777</span>
<span class="go">  - uid=1000</span>
<span class="go">  - gid=1000</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f smb-storage-class.yml
<span class="go">storageclass.storage.k8s.io/smb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get storageclass
<span class="go">NAME   PROVISIONER      RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span>
<span class="go">smb    smb.csi.k8s.io   Delete          Immediate           false                  22s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a PVC and trigger <cite>smb</cite> StorageClass to allocate dynamically a PV for it</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat smb-pvc.yml
<span class="go">---</span>
<span class="go">kind: PersistentVolumeClaim</span>
<span class="go">apiVersion: v1</span>
<span class="go">metadata:</span>
<span class="go">  name: pvc-smb</span>
<span class="go">spec:</span>
<span class="go">  accessModes:</span>
<span class="go">    - ReadWriteMany</span>
<span class="go">  resources:</span>
<span class="go">    requests:</span>
<span class="go">      storage: 1Gi</span>
<span class="go">  storageClassName: smb</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f smb-pvc.yml
<span class="go">persistentvolumeclaim/pvc-smb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pvc
<span class="go">NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span>
<span class="go">pvc-smb   Bound    </span><span class="gs">pvc-d91b566a-60a0-494e-a2ac-c6509d4f906b</span><span class="go">   1Gi        RWX            smb            17s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pv
<span class="go">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE</span>
<span class="gs">pvc-d91b566a-60a0-494e-a2ac-c6509d4f906b</span><span class="go">   1Gi        RWX            Delete           Bound    default/pvc-smb   smb                     32s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the <cite>smb CSI</cite> created volume on the <cite>service</cite> node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> ssh service <span class="s2">&quot;ls /tmp/&quot;</span>
<span class="go">Warning: Permanently added &#39;service&#39; (ED25519) to the list of known hosts.</span>
<span class="gs">pvc-d91b566a-60a0-494e-a2ac-c6509d4f906b</span><span class="go">&quot;</span>
<span class="go">...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create pod which use this volume.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat smb-pod.yml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: smb-nginx</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - name: smb-nginx</span>
<span class="go">    image: nginx</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - mountPath: &quot;/mnt/smb&quot;</span>
<span class="go">      name: smb-share1</span>
<span class="go">  volumes:</span>
<span class="go">  - name: smb-share1</span>
<span class="go">    persistentVolumeClaim:</span>
<span class="gs">      claimName: pvc-smb</span><span class="go"></span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f smb-pod.yml
<span class="go">pod/smb-nginx created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME        READY   STATUS    RESTARTS   AGE</span>
<span class="go">smb-nginx   1/1     Running   0          19s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti smb-nginx -- df -h /mnt/smb
<span class="go">Filesystem                                                        Size  Used Avail Use% Mounted on</span>
<span class="go">//10.10.10.61/smb-share/</span><span class="gs">pvc-d91b566a-60a0-494e-a2ac-c6509d4f906b</span><span class="go">   39G  2.3G   37G   6% /mnt/smb</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Cleanup: Remove your pod, StorageClass, PersistentVolumeClaim and CSI driver.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete pod smb-nginx
<span class="go">pod &quot;smb-nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pvc pvc-smb
<span class="go">persistentvolumeclaim &quot;pvc-smb&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete storageclass smb
<span class="go">storageclass.storage.k8s.io &quot;smb&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod,pv,pvc,storageclass
<span class="go">No resources found</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete -f csi-driver-smb.yaml
<span class="go">serviceaccount &quot;csi-smb-controller-sa&quot; deleted</span>
<span class="go">serviceaccount &quot;csi-smb-node-sa&quot; deleted</span>
<span class="go">clusterrole.rbac.authorization.k8s.io &quot;smb-external-provisioner-role&quot; deleted</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io &quot;smb-csi-provisioner-binding&quot; deleted</span>
<span class="go">daemonset.apps &quot;csi-smb-node&quot; deleted</span>
<span class="go">deployment.apps &quot;csi-smb-controller&quot; deleted</span>
<span class="go">csidriver.storage.k8s.io &quot;smb.csi.k8s.io&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-3-set-the-root-password-for-a-mysql-pod-using-secrets">
<h3>Task 3:  Set the root password for a mysql pod using Secrets<a class="headerlink" href="#task-3-set-the-root-password-for-a-mysql-pod-using-secrets" title="Permalink to this headline"></a></h3>
<p>Start a MySQL server and set its root password.
The official MySQL image from Docker Hub requires the <em>MYSQL_ROOT_PASSWORD</em> environment variable to be set (see <a class="reference external" href="https://hub.docker.com/_/mysql/">https://hub.docker.com/_/mysql/</a>).</p>
<ul class="simple">
<li><p>Create a secret to store the value of the password.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create secret generic mysql --from-literal<span class="o">=</span><span class="nv">password</span><span class="o">=</span>TopSecret
<span class="go">secret/mysql created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get secret mysql
<span class="go">NAME                  TYPE                                  DATA      AGE</span>
<span class="go">mysql                 Opaque                                1         13s</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use this secret in a pod in order to set the value of the MYSQL_ROOT_PASSWORD environment variable.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat mysql.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: mysql</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - image: mysql:8.0</span>
<span class="go">    name: mysqldb</span>
<span class="go">    env:</span>
<span class="go">    - name: MYSQL_ROOT_PASSWORD</span>
<span class="go">      valueFrom:</span>
<span class="go">        secretKeyRef:</span>
<span class="go">          name: mysql</span>
<span class="go">          key: password</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f mysql.yaml
<span class="go">pod/mysql created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME      READY     STATUS    RESTARTS   AGE</span>
<span class="go">mysql     1/1       Running   0          52s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti mysql -- bash
<span class="gp">root@mysql #&gt;</span> mysql -p
<span class="go">Enter password: </span><span class="gs">TopSecret</span><span class="go"></span>
<span class="go">Welcome to the MySQL monitor.  Commands end with ; or \g.</span>
<span class="go">Your MySQL connection id is 1</span>
<span class="go">Server version: 8.0.33 MySQL Community Server (GPL)</span>

<span class="go">Copyright (c) 2000, 2023, Oracle and/or its affiliates. All rights reserved.</span>

<span class="go">Oracle is a registered trademark of Oracle Corporation and/or its</span>
<span class="go">affiliates. Other names may be trademarks of their respective</span>
<span class="go">owners.</span>

<span class="go">Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.</span>

<span class="go">mysql&gt; </span><span class="gs">show databases;</span><span class="go"></span>
<span class="go">+--------------------+</span>
<span class="go">| Database           |</span>
<span class="go">+--------------------+</span>
<span class="go">| information_schema |</span>
<span class="go">| mysql              |</span>
<span class="go">| performance_schema |</span>
<span class="go">| sys                |</span>
<span class="go">+--------------------+</span>
<span class="go">4 rows in set (0.00 sec)</span>

<span class="go">mysql&gt; </span><span class="gs">exit</span><span class="go"></span>
<span class="go">Bye</span>
<span class="gp">root@mysql #&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
</section>
<section id="task-4-use-configmap-to-pass-a-file-to-a-pod">
<h3>Task 4:  Use ConfigMap to pass a file to a pod<a class="headerlink" href="#task-4-use-configmap-to-pass-a-file-to-a-pod" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create file name myconf with some arbitrary content, and create a configMap named my-map</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">echo</span> <span class="s2">&quot;this is a demo file&quot;</span> &gt; myconf
<span class="gp">root@admin-ws $&gt;</span> kubectl create configmap my-map --from-file<span class="o">=</span>myconf
<span class="go">configmap/my-map created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get configmap my-map -o yaml
<span class="go">apiVersion: v1</span>
<span class="go">data:</span>
<span class="go">  myconf: |</span>
<span class="go">    </span><span class="gs">this is a demo file</span><span class="go"></span>
<span class="go">kind: ConfigMap</span>
<span class="go">metadata:</span>
<span class="go">  creationTimestamp: &quot;2024-02-02T14:41:19Z&quot;</span>
<span class="go">  name: my-map</span>
<span class="go">  namespace: default</span>
<span class="go">  resourceVersion: &quot;2984040&quot;</span>
<span class="go">  uid: b4aeed4d-2ea9-4750-bbdd-be7faf915517</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a pod that is using the config map as a volume mounted on /config, and check the content of the /config/myconf file</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat cmap-pod.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: configmap-test</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - image: busybox</span>
<span class="go">    command:</span>
<span class="go">     - sleep</span>
<span class="go">     - &quot;3600&quot;</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - mountPath: /config</span>
<span class="go">      name: map</span>
<span class="go">    name: busy</span>
<span class="go">  volumes:</span>
<span class="go">    - name: map</span>
<span class="go">      configMap:</span>
<span class="go">          name: my-map</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f cmap-pod.yaml
<span class="go">pod/configmap-test created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span>  configmap-test -- cat /config/myconf
<span class="gs">this is a demo file</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Cleanup: Remove all the resources created in this lab and wait for resource removal.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete pod configmap-test
<span class="go">pod &quot;configmap-test&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod mysql
<span class="go">pod &quot;mysql&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete secrets mysql
<span class="go">secret &quot;mysql&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get all
<span class="go">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   71d</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-7-kubernetes-special-workloads">
<h2>Lab 7:  Kubernetes special workloads<a class="headerlink" href="#lab-7-kubernetes-special-workloads" title="Permalink to this headline"></a></h2>
<section id="task-1-using-statefulsets">
<h3>Task 1:  Using StatefulSets<a class="headerlink" href="#task-1-using-statefulsets" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Prepare for monitoring StatefulSet operation</p></li>
</ul>
<p>Open a second terminal and start watching pods.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> watch -n2 kubectl get pods -o wide

<span class="go">Every 2.0s: kubectl get pods -o wide               admin-ws: Mon Feb  5 11:08:18 2024</span>

<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
<p>Keep the terminal open until the end of next task. Now return to the first terminal!</p>
<ul class="simple">
<li><p>Create a headless Service named <cite>nginx</cite> and a Statefulset named <cite>web</cite> that starts 2 nginx pods</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/sts-web.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat sts-web.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Service</span>
<span class="go">metadata:</span>
<span class="go">  name: nginx</span>
<span class="go">  labels:</span>
<span class="go">    app: nginx</span>
<span class="go">spec:</span>
<span class="go">  clusterIP: None</span>
<span class="go">  selector:</span>
<span class="go">    app: nginx</span>
<span class="go">---</span>
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: StatefulSet</span>
<span class="go">metadata:</span>
<span class="go">  name: web</span>
<span class="go">spec:</span>
<span class="go">  serviceName: &quot;nginx&quot;</span>
<span class="go">  replicas: 2</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">      app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: k8s.gcr.io/nginx-slim:0.8</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        ports:</span>
<span class="go">        - containerPort: 80</span>
<span class="go">          name: web</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f sts-web.yaml
<span class="go">service/nginx created</span>
<span class="go">statefulset.apps/web created</span>
</pre></div>
</div>
<p>Observe in the second terminal that the pod creation is a sequential process.
When the creation process has finished, scale it to have four replicas. Keep watching!</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get sts -o wide
<span class="go">NAME   READY   AGE   CONTAINERS   IMAGES</span>
<span class="go">web    2/2     85s   nginx        k8s.gcr.io/nginx-slim:0.8</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl scale statefulset --replicas<span class="o">=</span><span class="m">4</span> web
<span class="go">statefulset.apps/web scaled</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Remove the objects created in this task. But keep the second terminal open!</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete statefulset web
<span class="go">statefulset.apps &quot;web&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete service nginx
<span class="go">service &quot;nginx&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-2-using-statefulsets-with-pvc">
<h3>Task 2:  Using Statefulsets with PVC<a class="headerlink" href="#task-2-using-statefulsets-with-pvc" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Verify existing <em>storageclass</em>. The <em>smb</em> storageclass should exist.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get storageclass
<span class="go">NAME   PROVISIONER      RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span>
<span class="go">smb    smb.csi.k8s.io   Delete          Immediate           false                  12s</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <em>smb</em> storageclass doesn’t exist install it as in previous lab</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/csi-driver-smb.yaml
<span class="go">serviceaccount/csi-smb-controller-sa created</span>
<span class="go">serviceaccount/csi-smb-node-sa created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/smb-external-provisioner-role created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/smb-csi-provisioner-binding created</span>
<span class="go">daemonset.apps/csi-smb-node created</span>
<span class="go">deployment.apps/csi-smb-controller created</span>
<span class="go">csidriver.storage.k8s.io/smb.csi.k8s.io created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/smb-storage-class.yml
<span class="go">storageclass.storage.k8s.io/smb created</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>Copy sts-web.yaml to statefulset.yaml. Modify statefulset.yaml to include a volumeClaimTemplate named www and mount it on /usr/share/nginx/html or use statefulset.yaml from /labfiles/k8s/Special_workloads/ directory</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/statefulset.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat statefulset.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Service</span>
<span class="go">metadata:</span>
<span class="go">  name: nginx</span>
<span class="go">  labels:</span>
<span class="go">    app: nginx</span>
<span class="go">spec:</span>
<span class="go">  clusterIP: None</span>
<span class="go">  selector:</span>
<span class="go">    app: nginx</span>
<span class="go">---</span>
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: StatefulSet</span>
<span class="go">metadata:</span>
<span class="go">  name: web</span>
<span class="go">spec:</span>
<span class="go">  serviceName: &quot;nginx&quot;</span>
<span class="go">  replicas: 2</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">      app: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        app: nginx</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: k8s.gcr.io/nginx-slim:0.8</span>
<span class="go">        imagePullPolicy: IfNotPresent</span>
<span class="go">        ports:</span>
<span class="go">        - containerPort: 80</span>
<span class="go">          name: web</span>
<span class="go">        volumeMounts:</span>
<span class="go">        - name: www</span>
<span class="go">          mountPath: /usr/share/nginx/html</span>
<span class="go">  volumeClaimTemplates:</span>
<span class="go">  - metadata:</span>
<span class="go">      name: www</span>
<span class="go">    spec:</span>
<span class="go">      accessModes: [ &quot;ReadWriteOnce&quot; ]</span>
<span class="go">      storageClassName: &quot;smb&quot;</span>
<span class="go">      resources:</span>
<span class="go">        requests:</span>
<span class="go">          storage: 1Gi</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl create -f statefulset.yaml
<span class="go">service/nginx created</span>
<span class="go">statefulset.apps/web created</span>
</pre></div>
</div>
<p>Observe in the second terminal that the pod creation is a sequential process.
When the creation process has finished, scale it to have four replicas. Keep watching!</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get sts -o wide
<span class="go">NAME   READY   AGE   CONTAINERS   IMAGES</span>
<span class="go">web    2/2     85s   nginx        k8s.gcr.io/nginx-slim:0.8</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl scale statefulset --replicas<span class="o">=</span><span class="m">4</span> web
<span class="go">statefulset.apps/web scaled</span>
</pre></div>
</div>
<p>Now check the automatically created pv-s and pvc-s.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pv
<span class="go">NAME          CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM               STORAGECLASS</span>
<span class="go">pvc-23//--//9c 1Gi     RWO          Delete         Bound  default/www-web-0   smb</span>
<span class="go">pvc-81//--//6c 1Gi     RWO          Delete         Bound  default/www-web-3   smb</span>
<span class="go">pvc-dd//--//83 1Gi     RWO          Delete         Bound  default/www-web-1   smb</span>
<span class="go">pvc-fd//--//2a 1Gi     RWO          Delete         Bound  default/www-web-2   smb</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pvc
<span class="go">NAME        STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS     AGE</span>
<span class="go">www-web-0   Bound    pvc-23//--//9c   1Gi        RWO            smb   11m</span>
<span class="go">www-web-1   Bound    pvc-dd//--//83   1Gi        RWO            smb   9m</span>
<span class="go">www-web-2   Bound    pvc-fd//--//2a   1Gi        RWO            smb   6m26s</span>
<span class="go">www-web-3   Bound    pvc-81//--//6c   1Gi        RWO            smb   6m17s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check <strong>state</strong> handling possibilities in field of volume management</p></li>
</ul>
<p>Create a pod specific <cite>index.html</cite> file in /usr/share/nginx/html which is a <strong>mounted</strong> directory.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti web-0 -- bash
<span class="gp">root@web-0:/#&gt;</span> cat /etc/hosts
<span class="gp">#</span> Kubernetes-managed hosts file.
<span class="go">127.0.0.1       localhost</span>
<span class="go">::1     localhost ip6-localhost ip6-loopback</span>
<span class="go">fe00::0 ip6-localnet</span>
<span class="go">fe00::0 ip6-mcastprefix</span>
<span class="go">fe00::1 ip6-allnodes</span>
<span class="go">fe00::2 ip6-allrouters</span>
<span class="go">192.168.182.21  web-0.nginx.default.svc.cluster.local   web-0</span>
<span class="gp">root@web-0:/#&gt;</span> df -h
<span class="go">Filesystem               Size Used Avail Use% Mounted on</span>
<span class="go">overlay                   37G  4.6G   33G  13% /</span>
<span class="go">tmpfs                     64M    0   64M   0% /dev</span>
<span class="go">tmpfs                    748M    0  748M   0% /sys/fs/cgroup</span>
<span class="go">/dev/root                 37G 4.6G   33G  13% /etc/hosts</span>
<span class="go">shm                       64M    0   64M   0% /dev/shm</span>
<span class="go">//10.10.61/tmp/pvc-23... 1021M  43M  978M   5% /usr/share/nginx/html</span>
<span class="go">tmpfs                    748M  12K  748M   1% /run/secrets/kubernetes.io/serviceaccount</span>
<span class="go">tmpfs                    748M    0  748M   0% /proc/acpi</span>
<span class="go">tmpfs                    748M    0  748M   0% /proc/scsi</span>
<span class="go">tmpfs                    748M    0  748M   0% /sys/firmware</span>
<span class="gp">root@web-0:/#&gt;</span> ls /usr/share/nginx/html/
<span class="go">&lt; no output &gt;</span>
<span class="gp">root@web-0:/#&gt;</span> <span class="nb">echo</span> <span class="s1">&#39;&lt;html&gt; web-0 &lt;/html&gt;&#39;</span> &gt; /usr/share/nginx/html/index.html
<span class="gp">root@web-0:/#&gt;</span> <span class="nb">exit</span>
<span class="go">exit</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<p>Drop <cite>web-0</cite> and let the sts controller to recreate it! The controller recreates the pod, but
preserves the old <cite>web-0</cite> pods’ PVC, and remounts it in the recreated pod. This is the way how
mounted volumes suitable for state-saving. You simply should put interesting information, collected data,
to a mounted volume.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pods
<span class="go">NAME    READY   STATUS    RESTARTS   AGE</span>
<span class="go">web-0   1/1     Running   0          4h52m</span>
<span class="go">web-1   1/1     Running   0          4h52m</span>
<span class="go">web-2   1/1     Running   0          4h53m</span>
<span class="go">web-3   1/1     Running   0          4h53m</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod web-0
<span class="go">pod &quot;web-0&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pods
<span class="go">NAME    READY   STATUS              RESTARTS   AGE</span>
<span class="gs">web-0</span><span class="go">   0/1     </span><span class="gs">ContainerCreating</span><span class="go">   0          2s</span>
<span class="go">web-1   1/1     Running             0          4h53m</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pods
<span class="go">NAME    READY   STATUS    RESTARTS   AGE</span>
<span class="go">web-0   1/1     Running   0          22s</span>
<span class="go">web-1   1/1     Running   0          4h53m</span>
<span class="go">web-2   1/1     Running   0          4h53m</span>
<span class="go">web-3   1/1     Running   0          4h53m</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti web-0 -- bash
<span class="gp">root@web-0:/#&gt;</span> df -h
<span class="go">Filesystem               Size Used Avail Use% Mounted on</span>
<span class="go">overlay                   37G  4.6G   33G  13% /</span>
<span class="go">tmpfs                     64M    0   64M   0% /dev</span>
<span class="go">tmpfs                    748M    0  748M   0% /sys/fs/cgroup</span>
<span class="go">/dev/root                 37G 4.6G   33G  13% /etc/hosts</span>
<span class="go">shm                       64M    0   64M   0% /dev/shm</span>
<span class="go">//10.10.61/tmp/pvc-23... 1021M  43M  978M   5% /usr/share/nginx/html</span>
<span class="go">tmpfs                    748M  12K  748M   1% /run/secrets/kubernetes.io/serviceaccount</span>
<span class="go">tmpfs                    748M    0  748M   0% /proc/acpi</span>
<span class="go">tmpfs                    748M    0  748M   0% /proc/scsi</span>
<span class="go">tmpfs                    748M    0  748M   0% /sys/firmware</span>
<span class="gp">root@web-0:/#&gt;</span> cat /usr/share/nginx/html/index.html
<span class="gs">&lt;html&gt; web-0 &lt;/html&gt;</span><span class="go"></span>
<span class="gp">root@web-0:/#&gt;</span> <span class="nb">exit</span>
<span class="go">exit</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the headless Service.</p></li>
</ul>
<p><cite>web-0</cite> must be accessible from <cite>web-1</cite> by FQDN using kube-dns.
<code class="docutils literal notranslate"><span class="pre">Ping</span></code> and <code class="docutils literal notranslate"><span class="pre">curl</span></code> not installed in an nginx pod, so install it to test the headless service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti web-1 -- bash
<span class="gp">root@web-1:/#&gt;</span> ping
<span class="go">bash: ping: command not found</span>
<span class="gp">root@web-1:/#&gt;</span> apt update<span class="p">;</span> apt install -y iproute2 iputils-ping curl
<span class="go">... omitted lines ...</span>
<span class="gp">root@web-1:/#&gt;</span> cat /etc/hosts
<span class="gp">#</span> Kubernetes-managed hosts file.
<span class="go">127.0.0.1       localhost</span>
<span class="go">::1     localhost ip6-localhost ip6-loopback</span>
<span class="go">fe00::0 ip6-localnet</span>
<span class="go">fe00::0 ip6-mcastprefix</span>
<span class="go">fe00::1 ip6-allnodes</span>
<span class="go">fe00::2 ip6-allrouters</span>
<span class="go">192.168.189.84       </span><span class="gs">web-1.nginx.default.svc.cluster.local</span><span class="go">   web-1</span>
<span class="gp">root@web-1:/#&gt;</span> ping -c1 <span class="gs">web-0.nginx.default.svc.cluster.local</span>
<span class="go">PING web-0.nginx.default.svc.cluster.local (192.168.189.85) 56(84) bytes of data.</span>
<span class="go">64 bytes from web-0.nginx.default.svc.cluster.local (192.168.189.85): icmp_seq=1 &gt;&gt;</span>
<span class="go">                                                                ttl=64 time=2.84 ms</span>

<span class="go">--- web-0.nginx.default.svc.cluster.local ping statistics ---</span>
<span class="go">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="go">rtt min/avg/max/mdev = 2.847/2.847/2.847/0.000 ms</span>
<span class="gp">root@web-1:/#&gt;</span>
<span class="gp">root@web-1:/#&gt;</span> curl -s <span class="gs">web-0.nginx.default.svc.cluster.local</span>
<span class="go">&lt;html&gt; web-0 &lt;/html&gt;</span>
<span class="gp">root@web-1:/#&gt;</span> <span class="nb">exit</span>
<span class="go">exit</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Remove the objects created in this task. Now you can close the second terminal.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete statefulset web
<span class="go">statefulset.apps &quot;web&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete service nginx
<span class="go">service &quot;nginx&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pvc --all
<span class="go">persistentvolumeclaim &quot;www-web-0&quot; deleted</span>
<span class="go">persistentvolumeclaim &quot;www-web-1&quot; deleted</span>
<span class="go">persistentvolumeclaim &quot;www-web-2&quot; deleted</span>
<span class="go">persistentvolumeclaim &quot;www-web-3&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete storageclass smb
<span class="go">storageclass.storage.k8s.io &quot;smb&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-3-using-jobs">
<h3>Task 3:  Using Jobs<a class="headerlink" href="#task-3-using-jobs" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a Job named <cite>connection-test</cite> that start a pod which will send one ICMP Echo Request (ping) to www.google.com. The job should run 10 Pods to successful completion. (Use the busybox image)</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/job1.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat job1.yaml
<span class="go">apiVersion: batch/v1</span>
<span class="go">kind: Job</span>
<span class="go">metadata:</span>
<span class="go">  name: connection-test</span>
<span class="go">spec:</span>
<span class="go">      completions: 10</span>
<span class="go">      template:</span>
<span class="go">        spec:</span>
<span class="go">          containers:</span>
<span class="go">          - name: hello</span>
<span class="go">            image: busybox</span>
<span class="go">            args:</span>
<span class="go">            - /bin/ping</span>
<span class="go">            - -c</span>
<span class="go">            - &quot;1&quot;</span>
<span class="go">            - www.google.com</span>
<span class="go">          restartPolicy: OnFailure</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f job1.yaml
<span class="go">job.batch/connection-test created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Test the evolution of the job</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get job --watch
<span class="go">NAME              COMPLETIONS   DURATION   AGE</span>
<span class="go">connection-test   1/10          8s         8s</span>
<span class="go">connection-test   2/10          13s        13s</span>
<span class="go">connection-test   3/10          17s        17s</span>
<span class="go">connection-test   4/10          22s        22s</span>
<span class="go">connection-test   5/10          26s        26s</span>
<span class="go">connection-test   6/10          30s        30s</span>
<span class="go">connection-test   7/10          34s        34s</span>
<span class="go">connection-test   8/10          38s        38s</span>
<span class="go">connection-test   9/10          43s        43s</span>
<span class="go">connection-test   10/10         43s        43s</span>
<span class="go">^C</span>

<span class="gp">root@admin-ws $&gt;</span>  kubectl get pod
<span class="go">NAME                    READY     STATUS      RESTARTS   AGE</span>
<span class="go">connection-test-4dzrx   0/1       Completed   0          54s</span>
<span class="go">connection-test-5lls4   0/1       Completed   0          47s</span>
<span class="go">connection-test-5mxrj   0/1       Completed   0          1m</span>
<span class="go">connection-test-7xllv   0/1       Completed   0          1m</span>
<span class="go">connection-test-9hssg   0/1       Completed   0          34s</span>
<span class="go">connection-test-h4jtl   0/1       Completed   0          40s</span>
<span class="go">connection-test-pv8mc   0/1       Completed   0          1m</span>
<span class="go">connection-test-rb2zl   0/1       Completed   0          1m</span>
<span class="go">connection-test-tf46l   0/1       Completed   0          1m</span>
<span class="go">connection-test-tskbq   0/1       Completed   0          28s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the job, and verify that the Pods were deleted also</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete job connection-test
<span class="go">job.batch &quot;connection-test&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
</section>
<section id="task-4-using-cronjobs">
<h3>Task 4:  Using CronJobs<a class="headerlink" href="#task-4-using-cronjobs" title="Permalink to this headline"></a></h3>
<p>In this exercise, we create a CronJob that periodically deletes older files from the temporary files created by an application pod.</p>
<ul class="simple">
<li><p>Create a pod that creates files periodically in the /data directory.</p>
<ul>
<li><p>The /data directory is located on a PV served by a <em>smb</em> PVC.</p></li>
<li><p>The application is a single shell loop that creates a new file every 10 seconds.</p></li>
</ul>
</li>
</ul>
<p id="preparation">Preparation:</p>
<blockquote>
<div><ul class="simple">
<li><p>Create StorageClass and PVC.</p></li>
</ul>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/smb-storage-class.yml
<span class="go">storageclass.storage.k8s.io/smb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Special_workloads/smb-rwo-pvc.yml
<span class="go">persistentvolumeclaim/smb-rwo created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pvc
<span class="go">NAME       STATUS   VOLUME                               CAPACITY  ACCESS MODES STORAGECLASS   AGE</span>
<span class="go">smb-rwo   Bound    pvc-8ad30ae4-9e51-4da5-8e00-4c785a4f153a   1Gi    </span><span class="gs">RWO</span><span class="go">          smb         6s</span>
</pre></div>
</div>
<blockquote>
<div><ul>
<li><p>Create “application pod” with following parameters.</p>
<ul>
<li><p>name: tmpfiles</p></li>
<li><p>label: app: tmpfiles</p></li>
<li><p>container:</p>
<blockquote>
<div><ul class="simple">
<li><p>name: tmp</p></li>
<li><p>image: alpine</p></li>
<li><p>command: <em>export n=1;while :;do touch /data/file${n}; n=`expr $n + 1`;sleep 10;done</em></p></li>
<li><p>volume: from <em>smb-rwo</em> PVC, mountPath: <em>/data</em></p></li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
</ul>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span>
<span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/tempfiles-pod.yml .
<span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/purge-tmpfiles-cron.yml .
<span class="gp">root@admin-ws $&gt;</span> cat tempfiles-pod.yml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: tmpfiles</span>
<span class="go">  labels:</span>
<span class="go">    </span><span class="gs">app: tmpfiles</span><span class="go"></span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - name: tmp</span>
<span class="go">    image: alpine</span>
<span class="go">    </span><span class="gs">command: [&quot;/bin/sh&quot;]</span><span class="go"></span>
<span class="go">    </span><span class="gs">args: [&quot;-c&quot;, &#39;export n=1;while :;do touch /data/file${n}; n=`expr $n + 1`;sleep 10;done&#39; ]</span><span class="go"></span>
<span class="go">    volumeMounts:</span>
<span class="go">    </span><span class="gs">- mountPath: /data</span><span class="go"></span>
<span class="go">      name: data-vol</span>
<span class="go">  volumes:</span>
<span class="go">  - name: data-vol</span>
<span class="go">    persistentVolumeClaim:</span>
<span class="go">      </span><span class="gs">claimName: smb-rwo</span><span class="go"></span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f tempfiles-pod.yml
<span class="go">pod/tmpfiles created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">NAME       READY   STATUS    RESTARTS   AGE</span>
<span class="go">tmpfiles   1/1     Running   0          11s</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>Observe the file creation.</p></li>
</ul>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti tmpfiles -- sh -c <span class="s1">&#39;watch -n10 ls -lrt /data&#39;</span>
<span class="go">Every 10.0s: ls -lrt /data                                  2024-02-06 12:06:31</span>

<span class="go">total 0</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:03 file1</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:03 file2</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file3</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file4</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file5</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file6</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file7</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:04 file8</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:05 file9</span>
<span class="go">-rw-r--r--    1 root     2000             0 Jan 26 12:05 file10</span>

<span class="go">...</span>
</pre></div>
</div>
<p>Create a CronJob to purge files from <em>/data</em> directory older than 1 minute, and schedule it for every minutes.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>Since the volume access method is ReadWriteOnce (see at <a class="reference internal" href="#preparation">Preparation</a>), the application pod and the CronJob pod must run on the same node. Only this way can the CronJob pod access the file system used by the application pod.</p></li>
</ul>
</div>
<blockquote>
<div><ul class="simple">
<li><p>To allow the CronJob pod to use the same PV as the application pod, use podAffinity.</p></li>
<li><p>The command is the <em>find</em> command.</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>Open a <strong>second</strong> terminal window on <strong>admin-ws</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cat purge-tmpfiles-cron.yml
<span class="go">apiVersion: batch/v1</span>
<span class="go">kind: CronJob</span>
<span class="go">metadata:</span>
<span class="go">  name: purge-tmpfiles</span>
<span class="go">spec:</span>
<span class="go">  </span><span class="gs">schedule: &quot;* * * * *&quot;</span><span class="go"></span>
<span class="go">  successfulJobsHistoryLimit: 3</span>
<span class="go">  failedJobsHistoryLimit: 1</span>
<span class="go">  concurrencyPolicy: Forbid</span>
<span class="go">  jobTemplate:</span>
<span class="go">    spec:</span>
<span class="go">      completions: 1</span>
<span class="go">      template:</span>
<span class="go">        metadata:</span>
<span class="go">          name: purge</span>
<span class="go">        spec:</span>
<span class="go">          affinity:</span>
<span class="go">            </span><span class="gs">podAffinity:</span><span class="go"></span>
<span class="go">              requiredDuringSchedulingIgnoredDuringExecution:</span>
<span class="go">              - labelSelector:</span>
<span class="go">                  matchExpressions:</span>
<span class="go">                  - key: app</span>
<span class="go">                    operator: In</span>
<span class="go">                    values:</span>
<span class="go">                    </span><span class="gs">- tmpfiles</span><span class="go"></span>
<span class="go">                topologyKey: kubernetes.io/hostname</span>
<span class="go">          containers:</span>
<span class="go">          - name: purge-old-files</span>
<span class="go">            image: ubuntu</span>
<span class="go">            imagePullPolicy: IfNotPresent</span>
<span class="go">            </span><span class="gs">command: [&quot;/bin/sh&quot;]</span><span class="go"></span>
<span class="go">            </span><span class="gs">args: [&quot;-c&quot;, &#39;find /data -cmin +1 -exec rm {} \;&#39;]</span><span class="go"></span>
<span class="go">            volumeMounts:</span>
<span class="go">            </span><span class="gs">- mountPath: /data</span><span class="go"></span>
<span class="go">              name: data-vol</span>
<span class="go">          restartPolicy: OnFailure</span>
<span class="go">          volumes:</span>
<span class="go">          - name: data-vol</span>
<span class="go">            persistentVolumeClaim:</span>
<span class="go">              </span><span class="gs">claimName: smb-rwo</span><span class="go"></span>

<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f purge-tmpfiles-cron.yml
<span class="go">cronjob.batch/purge-tmpfiles created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>In the next few minutes, you can watch the files being deleted in the first window and the jobs running in the second window.</p></li>
<li><p>In the second window</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get job -w
<span class="go">NAME                      COMPLETIONS   DURATION   AGE</span>
<span class="go">purge-tmpfiles-27912148   1/1           3s         2m10s</span>
<span class="go">purge-tmpfiles-27912149   1/1           3s         70s</span>
<span class="go">purge-tmpfiles-27912150   1/1           3s         10s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Press <em>ctrl c</em> in both window to stop outputs.</p></li>
<li><p>Cleanup</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete cronjob purge-tmpfiles
<span class="go">cronjob.batch &quot;purge-tmpfiles&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get job
<span class="go">No resources found in default namespace.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod tmpfiles
<span class="go">pod &quot;tmpfiles&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pvc smb-rwo
<span class="go">persistentvolumeclaim &quot;smb-rwo&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete storageclass smb
<span class="go">storageclass.storage.k8s.io &quot;smb&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-5-using-daemonsets">
<h3>Task 5:  Using DaemonSets<a class="headerlink" href="#task-5-using-daemonsets" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Execute one instance of <code class="docutils literal notranslate"><span class="pre">nginx</span></code> on all nodes in the cluster. (Use daemonset for it.)</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Special_workloads/ds1.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat ds1.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: DaemonSet</span>
<span class="go">metadata:</span>
<span class="go">  name: ds-demo</span>
<span class="go">spec:</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">      appname: nginx</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        appname: nginx</span>
<span class="go">    spec:</span>
<span class="go">      containers:</span>
<span class="go">      - name: nginx</span>
<span class="go">        image: nginx</span>
<span class="go">      tolerations:</span>
<span class="go">      - effect: NoSchedule</span>
<span class="go">        key: node-role.kubernetes.io/control-plane</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f ds1.yaml
<span class="go">daemonset.apps/ds-demo created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify the status of the DaemonSet, and that the nginx has been started on all nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get ds
<span class="go">NAME      DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span>
<span class="go">ds-demo   4         4         4         4            4           &lt;none&gt;          44s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME            READY     STATUS   RESTARTS   AGE       IP              NODE    ...</span>
<span class="go">ds-demo-82zzh   1/1       Running  0          1m        192.168.137.69  c-plane1 ...</span>
<span class="go">ds-demo-b7hcr   1/1       Running  0          1m        192.168.235.147 worker1 ...</span>
<span class="go">ds-demo-b829w   1/1       Running  0          1m        192.168.189.96  worker2 ...</span>
<span class="go">ds-demo-x7ddx   1/1       Running  0          1m        192.168.182.23  worker3 ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Delete the daemon set, and make sure that the Pods have been deleted also.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete daemonset ds-demo
<span class="go">daemonset.apps &quot;ds-demo&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get daemonset
<span class="go">No resources found in default namespace.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod
<span class="go">No resources found in default namespace.</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-8-logging-monitoring-kubernetes">
<h2>Lab 8:  Logging, monitoring kubernetes<a class="headerlink" href="#lab-8-logging-monitoring-kubernetes" title="Permalink to this headline"></a></h2>
<section id="task-1-investigate-the-logging-in-kubernetes">
<h3>Task 1:  Investigate the logging in kubernetes<a class="headerlink" href="#task-1-investigate-the-logging-in-kubernetes" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a <cite>logtest</cite> pod using the <cite>nginx</cite> image.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl run --image<span class="o">=</span>nginx logtest
<span class="go">pod/logtest created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Identify the IP Address, and the node for the pod.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get pod -o wide
<span class="go">NAME      READY   STATUS    RESTARTS   AGE     IP               NODE    //</span>
<span class="go">logtest   1/1     Running   0          3m29s   </span><span class="gs">192.168.235.132   worker1</span><span class="go"> //</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Access the selected nginx instance using curl</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> ssh c-plane1 curl -s <span class="m">192</span>.168.235.132<span class="p">|</span>grep title
<span class="go">Warning: Permanently added &#39;c-plane1&#39; (ED25519) to the list of known hosts.</span>
<span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check the logs of the selected pod</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl logs logtest
<span class="go">/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration</span>
<span class="go">/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh</span>
<span class="go">10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf</span>
<span class="go">10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh</span>
<span class="go">/docker-entrypoint.sh: Configuration complete; ready for start up</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: using the &quot;epoll&quot; event method</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: nginx/1.25.1</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: OS: Linux 5.15.0-91-generic</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: start worker processes</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: start worker process 29</span>
<span class="gs">192.168.13.0 - - [05/Feb/2024:12:42:34 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.81.0&quot; &quot;-&quot;</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>On the node where the identified pod runs, check the current system journal file, and verify that the log message is there:</p></li>
</ul>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Prepare nodes (c-plane1, worker1, worker2, worker3) to use crictl</p>
<ul class="simple">
<li><p>Verify the <em>crictl</em> configuration on worker nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@dmin-ws $&gt;</span> <span class="k">for</span> node <span class="k">in</span> worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> ssh <span class="si">${</span><span class="nv">node</span><span class="si">}</span> <span class="s2">&quot;crictl config --get runtime-endpoint&quot;</span><span class="p">;</span><span class="k">done</span>
<span class="go">unix:///run/containerd/containerd.sock</span>
<span class="go">unix:///run/containerd/containerd.sock</span>
<span class="go">unix:///run/containerd/containerd.sock</span>
</pre></div>
</div>
<ul class="simple">
<li><p>If the <em>runtime-endpoint</em> is not configured run the following command.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@dmin-ws $&gt;</span> <span class="k">for</span> node <span class="k">in</span> worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> ssh <span class="si">${</span><span class="nv">node</span><span class="si">}</span> <span class="s2">&quot;crictl config runtime-endpoint unix:///run/containerd/containerd.sock&quot;</span><span class="p">;</span><span class="k">done</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> ssh <span class="gs">worker1</span>

<span class="gp">root@worker1 $&gt;</span> crictl ps --name logtest
<span class="go">CONTAINER     IMAGE         CREATED        STATE   NAME    ATTEMPT POD ID</span>
<span class="gs">effe09570e288</span><span class="go"> de2543b9436b7 4 minutes ago  Running logtest 0       c2120df669f47</span>

<span class="gp">root@worker1 $&gt;</span> crictl logs <span class="gs">effe09570e288</span>
<span class="go">/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration</span>
<span class="go">/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh</span>
<span class="go">10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf</span>
<span class="go">10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh</span>
<span class="go">/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh</span>
<span class="go">/docker-entrypoint.sh: Configuration complete; ready for start up</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: using the &quot;epoll&quot; event method</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: nginx/1.23.3</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6)</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: OS: Linux 5.15.0-53-generic</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: start worker processes</span>
<span class="go">2024/02/05 12:41:53 [notice] 1#1: start worker process 29</span>
<span class="go">192.168.13.2 - - [05/Feb/2024:12:42:34 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.81.0&quot; &quot;-&quot;</span>


<span class="gp">root@worker1 $&gt;</span> crictl inspect <span class="gs">effe09570e288</span> <span class="p">|</span> grep logPath
<span class="go">  &quot;logPath&quot;: &quot;</span><span class="gs">/var/log/pods/default_logtest_751ea8e3-94b8-4655-b8d3-7694f63ed0cb/logtest/0.log</span><span class="go">&quot;</span>
<span class="gp">root@worker1 $&gt;</span> cat <span class="gs">/var/log/pods/default_logtest_751ea8e3-----b8d3-7694f63ed0cb/logtest/0.log</span>
<span class="go">2024-02-05T12:41:53.30258954Z stdout F /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration</span>
<span class="go">2024-02-05T12:41:53.302656982Z stdout F /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/</span>
<span class="go">2024-02-05T12:41:53.304658657Z stdout F /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh</span>
<span class="go">2024-02-05T12:41:53.310352453Z stdout F 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf</span>
<span class="go">2024-02-05T12:41:53.316277372Z stdout F 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf</span>
<span class="go">2024-02-05T12:41:53.316483856Z stdout F /docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh</span>
<span class="go">2024-02-05T12:41:53.316635886Z stdout F /docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh</span>
<span class="go">2024-02-05T12:41:53.318727446Z stdout F /docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh</span>
<span class="go">2024-02-05T12:41:53.319767925Z stdout F /docker-entrypoint.sh: Configuration complete; ready for start up</span>
<span class="go">2024-02-05T12:41:53.326047048Z stderr F 2024/02/05 12:41:53 [notice] 1#1: using the &quot;epoll&quot; event method</span>
<span class="go">2024-02-05T12:41:53.326137398Z stderr F 2024/02/05 12:41:53 [notice] 1#1: nginx/1.25.3</span>
<span class="go">2024-02-05T12:41:53.326183072Z stderr F 2024/02/05 12:41:53 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)</span>
<span class="go">2024-02-05T12:41:53.326231347Z stderr F 2024/02/05 12:41:53 [notice] 1#1: OS: Linux 5.15.0-91-generic</span>
<span class="go">2024-02-05T12:41:53.326269256Z stderr F 2024/02/05 12:41:53 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576</span>
<span class="go">2024-02-05T12:41:53.326379878Z stderr F 2024/02/05 12:41:53 [notice] 1#1: start worker processes</span>
<span class="go">2024-02-05T12:41:53.326531895Z stderr F 2024/02/05 12:41:53 [notice] 1#1: start worker process 29</span>
<span class="go">2024-02-05T12:42:34.83808102Z stdout F 192.168.13.0 - - [05/Feb/2024:12:42:34 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.81.0&quot; &quot;-&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Erase the content of the file, and check the POD’s log again</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1 $&gt;</span>  cat /dev/null &gt; <span class="gs">/var/log/pods/default_logtest_751ea8e3-----ed0cb/logtest/0.log</span>
<span class="gp">root@worker1 $&gt;</span> <span class="nb">logout</span>
<span class="go">Connection to worker1 closed.</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl logs logtest
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
</section>
<section id="task-2-processing-logs-in-a-pod-using-sidecar-containers">
<h3>Task 2:  Processing logs in a pod using sidecar containers<a class="headerlink" href="#task-2-processing-logs-in-a-pod-using-sidecar-containers" title="Permalink to this headline"></a></h3>
<p>Let’s examine the manifest file bellow. It creates a pod with 4 containers. <strong>Count</strong> does the main job. The rest 3 countainers functions as 3 sidecar containers. They process the the two output files <cite>1.log</cite> and <cite>2.log</cite>.</p>
<dl class="simple">
<dt>The functions are:</dt><dd><ul class="simple">
<li><p><strong>count</strong> does the main job: It counts upward and prints the counted value in two different format to 1.log and 2.log files.</p></li>
<li><p><strong>count-log-1</strong> forwards last new line of 1.log to standard output. So it will be logged by container engine and therefore it can be read as kubernetes log.</p></li>
<li><p><strong>count-log-2</strong> forwards last new line of 2.log to standard output. So it will be logged by container engine and therefore it can be read as kubernetes log.</p></li>
<li><p><strong>logrotate</strong> keeps the size of 1.log and 2.log files less than 20 kbyte and handles 5 rotates. See details in manifest file. (Side effect: It manages all files in an ephemeral directory on the node where pod is running)</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Logging_and_monitoring/logrotate-two-files-counter-streaming-sidecar.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat logrotate-two-files-counter-streaming-sidecar.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: counter</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - name: </span><span class="gs">count</span><span class="go"></span>
<span class="go">    image: busybox</span>
<span class="go">    args:</span>
<span class="go">    - /bin/sh</span>
<span class="go">    - -c</span>
<span class="go">    - &gt;</span>
<span class="go">      i=0;</span>
<span class="go">      while true;</span>
<span class="go">      do</span>
<span class="go">        echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log;</span>
<span class="go">        echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log;</span>
<span class="go">        i=$((i+1));</span>
<span class="go">        sleep 1;</span>
<span class="go">      done</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - name: varlog</span>
<span class="go">      mountPath: /var/log</span>
<span class="go">  - name: </span><span class="gs">count-log-1</span><span class="go"></span>
<span class="go">    image: busybox</span>
<span class="go">    args: [/bin/sh, -c, &#39;tail -n+1 -f /var/log/1.log&#39;]</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - name: varlog</span>
<span class="go">      mountPath: /var/log</span>
<span class="go">  - name: </span><span class="gs">count-log-2</span><span class="go"></span>
<span class="go">    image: busybox</span>
<span class="go">    args: [/bin/sh, -c, &#39;tail -n+1 -f /var/log/2.log&#39;]</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - name: varlog</span>
<span class="go">      mountPath: /var/log</span>
<span class="go">  - name: </span><span class="gs">logrotate</span><span class="go"></span>
<span class="go">    image: blacklabelops/logrotate</span>
<span class="go">    env:</span>
<span class="go">    - name: LOGROTATE_INTERVAL</span>
<span class="go">      value: &quot;hourly&quot;</span>
<span class="go">    - name: LOGS_DIRECTORIES</span>
<span class="go">      value: &quot;/var/log&quot;</span>
<span class="go">    - name: LOGROTATE_CRONSCHEDULE</span>
<span class="go">      value: &quot;* * * * * *&quot;</span>
<span class="go">    - name: LOG_FILE</span>
<span class="go">      value: &quot;/logrotate-status/logrotate.log&quot;</span>
<span class="go">    - name: LOGROTATE_DATEFORMAT</span>
<span class="go">      value: &quot;-%Y%m%d-%s&quot;</span>
<span class="go">    - name: LOGROTATE_SIZE</span>
<span class="go">      value: &quot;20k&quot;</span>
<span class="go">    - name: LOGROTATE_COPIES</span>
<span class="go">      value: &quot;5&quot;</span>
<span class="go">    - name: LOGROTATE_LOGFILE</span>
<span class="go">      value: &quot;/logrotate-status/logrotatecron.log&quot;</span>
<span class="go">    volumeMounts:</span>
<span class="go">    - name: varlog</span>
<span class="go">      mountPath: /var/log</span>
<span class="go">  volumes:</span>
<span class="go">  - name: varlog</span>
<span class="go">    emptyDir:</span>
<span class="go">      sizeLimit: 100Mi</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the <strong>counter</strong> pod and let it run for 10-15 minutes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create -f logrotate-two-files-counter-streaming-sidecar.yaml
<span class="go">pod/counter created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod counter -o wide
<span class="go">NAME      READY   STATUS    RESTARTS   AGE   IP               NODE</span>
<span class="go">counter   4/4     Running   0          75s   192.168.189.70   worker2</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the <strong>count-log-1</strong> and <strong>count-log-2</strong> sidecar containers are making the content of the log files available through the <cite>kubectl logs</cite> command</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl logs counter count
<span class="gp">root@admin-ws $&gt;</span> kubectl logs counter count-log-1
<span class="go">---- output omitted ----</span>
<span class="go">3: Mon Feb  5 12:51:27 UTC 2024</span>
<span class="go">---- output omitted ----</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl logs counter count-log-2
<span class="go">---- output omitted ----</span>
<span class="go">Mon Feb  5 12:51:27 UTC 2024 INFO 3</span>
<span class="go">---- output omitted ----</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify the rotation of the log files that the <strong>count</strong> container creates (<cite>1.log</cite> and <cite>2.log</cite>).</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti counter -c count -- sh
<span class="gp">root@counter / #&gt;</span> tail -n2 /var/log/1.log
<span class="go">131: Mon Feb  5 12:53:36 UTC 2024</span>
<span class="go">132: Mon Feb  5 12:53:37 UTC 2024</span>
<span class="gp">root@counter / #&gt;</span> tail -n2 /var/log/2.log
<span class="go">Mon Feb  5 12:53:48 UTC 2024 INFO 143</span>
<span class="go">Mon Feb  5 12:53:49 UTC 2024 INFO 144</span>
<span class="gp">root@counter / #&gt;</span>
<span class="gp">root@counter / #&gt;</span> ls -l /var/log/<span class="o">[</span><span class="m">12</span><span class="o">]</span>*
<span class="go">-rw-r--r--    1 root     root          6928 Feb  5 12:54 /var/log/1.log</span>
<span class="go">-rw-r--r--    1 root     root          7756 Feb  5 12:54 /var/log/2.log</span>
<span class="gp">root@counter / #&gt;</span> sleep <span class="m">600</span>
<span class="gp">root@counter / #&gt;</span> ls -l /var/log/<span class="o">[</span><span class="m">12</span><span class="o">]</span>*
<span class="go">-rw-r--r--    1 root     root          8364 Feb  5 13:05 /var/log/1.log</span>
<span class="go">-rw-r--r--    1 root     root         20494 Feb  5 13:01 /var/log/1.log-20240205-1707138094</span>
<span class="go">-rw-r--r--    1 root     root         11780 Feb  5 13:05 /var/log/2.log</span>
<span class="go">-rw-r--r--    1 root     root         20486 Feb  5 13:00 /var/log/2.log-20240205-1707138029</span>
<span class="gp">root@counter / #&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
</section>
<section id="task-3-processing-logs-on-nodes">
<h3>Task 3:  Processing logs on nodes<a class="headerlink" href="#task-3-processing-logs-on-nodes" title="Permalink to this headline"></a></h3>
<p>Implement logrotate using a daemonset on each node. The <strong>daemonset</strong> described in manifest file <cite>daemonset-logrotate.yaml</cite> tolarates <strong>c-plane1</strong> node’s <strong>NoSchedule</strong> taints. So it launches a pod on <strong>c-plane1</strong> node also. It uses <strong>hostpath type volumes</strong> to access the nodes’ local file system. It logrotates files in <cite>/var/log/</cite> directory. It makes ‘house-keeping’ function, so it is recommended to run it in <strong>kube-system namespace</strong>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> cp /labfiles/k8s/Logging_and_monitoring/daemonset-logrotate.yaml .
<span class="gp">root@admin-ws $&gt;</span> cat daemonset-logrotate.yaml
<span class="go">apiVersion: apps/v1</span>
<span class="go">kind: DaemonSet</span>
<span class="go">metadata:</span>
<span class="go">  name: logrotate</span>
<span class="go">  namespace: </span><span class="gs">kube-system</span><span class="go"></span>
<span class="go">  labels:</span>
<span class="go">    k8s-app: logrotate</span>
<span class="go">spec:</span>
<span class="go">  selector:</span>
<span class="go">    matchLabels:</span>
<span class="go">q      name: logrotate</span>
<span class="go">  template:</span>
<span class="go">    metadata:</span>
<span class="go">      labels:</span>
<span class="go">        name: </span><span class="gs">logrotate</span><span class="go"></span>
<span class="go">    spec:</span>
<span class="go">      </span><span class="gs">tolerations:</span><span class="go"></span>
<span class="go">      - key: node-role.kubernetes.io/control-plane</span>
<span class="go">        effect: NoSchedule</span>
<span class="go">      containers:</span>
<span class="go">      - name: logrotate</span>
<span class="go">        image: blacklabelops/logrotate</span>
<span class="go">        resources:</span>
<span class="go">          limits:</span>
<span class="go">            memory: 200Mi</span>
<span class="go">          requests:</span>
<span class="go">            cpu: 100m</span>
<span class="go">            memory: 200Mi</span>
<span class="go">        env:</span>
<span class="go">        - name: LOGROTATE_INTERVAL</span>
<span class="go">          value: &quot;hourly&quot;</span>
<span class="go">        - name: LOGS_DIRECTORIES</span>
<span class="go">          value: &quot;/var/log&quot;</span>
<span class="go">        - name: LOGROTATE_CRONSCHEDULE</span>
<span class="go">          value: &quot;* * * * * *&quot;</span>
<span class="go">        - name: LOG_FILE</span>
<span class="go">          value: &quot;/logrotate-status/logrotate.log&quot;</span>
<span class="go">        - name: LOGROTATE_DATEFORMAT</span>
<span class="go">          value: </span><span class="gs">&quot;-%s-%Y%m%d&quot;</span><span class="go"></span>
<span class="go">        - name: LOGROTATE_SIZE</span>
<span class="go">          value: &quot;20k&quot;</span>
<span class="go">        - name: LOGROTATE_COPIES</span>
<span class="go">          value: &quot;5&quot;</span>
<span class="go">        - name: LOGROTATE_LOGFILE</span>
<span class="go">          value: &quot;/logrotate-status/logrotatecron.log&quot;</span>
<span class="go">        volumeMounts:</span>
<span class="go">        - name: varlog</span>
<span class="go">          mountPath: /var/log</span>
<span class="go">        - name: varlogpods</span>
<span class="go">          mountPath: /var/log/pods</span>
<span class="go">          readOnly: true</span>
<span class="go">      terminationGracePeriodSeconds: 30</span>
<span class="go">      volumes:</span>
<span class="go">      - name: varlog</span>
<span class="go">        hostPath:</span>
<span class="go">          path: /var/log</span>
<span class="go">      - name: varlogpods</span>
<span class="go">        hostPath:</span>
<span class="go">          path: /var/log/pods</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Apply this manifest file. <cite>logrotate-xxxxx</cite> pods should appear on all nodes including the <strong>c-plane1</strong> node as well.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f daemonset-logrotate.yaml
<span class="go">daemonset.apps/logrotate created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get ds logrotate --namespace<span class="o">=</span>kube-system
<span class="go">NAME        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span>
<span class="go">logrotate   4         4         4       4            4           &lt;none&gt;          2m33s</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl describe ds logrotate -n kube-system
<span class="go">Name:           logrotate</span>
<span class="go">Selector:       name=logrotate</span>
<span class="go">Node-Selector:  &lt;none&gt;</span>
<span class="go">Labels:         k8s-app=logrotate</span>
<span class="go">Annotations:    deprecated.daemonset.template.generation: 1</span>
<span class="go">Desired Number of Nodes Scheduled: 4</span>
<span class="go">Current Number of Nodes Scheduled: 4</span>
<span class="go">Number of Nodes Scheduled with Up-to-date Pods: 4</span>
<span class="go">Number of Nodes Scheduled with Available Pods: 4</span>
<span class="go">Number of Nodes Misscheduled: 0</span>
<span class="go">Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed</span>
<span class="go">Pod Template:</span>
<span class="go">  Labels:  name=logrotate</span>
<span class="go">  Containers:</span>
<span class="go">   logrotate:</span>
<span class="go">    Image:      blacklabelops/logrotate</span>
<span class="go">    Port:       &lt;none&gt;</span>
<span class="go">    Host Port:  &lt;none&gt;</span>
<span class="go">    Limits:</span>
<span class="go">      memory:  200Mi</span>
<span class="go">    Requests:</span>
<span class="go">      cpu:     100m</span>
<span class="go">      memory:  200Mi</span>
<span class="go">    Environment:</span>
<span class="go">      LOGROTATE_INTERVAL:      hourly</span>
<span class="go">      LOGS_DIRECTORIES:        /var/log</span>
<span class="go">      LOGROTATE_CRONSCHEDULE:  * * * * * *</span>
<span class="go">      LOG_FILE:                /logrotate-status/logrotate.log</span>
<span class="go">      LOGROTATE_DATEFORMAT:    -%s-%Y%m%d</span>
<span class="go">      LOGROTATE_SIZE:          20k</span>
<span class="go">      LOGROTATE_COPIES:        5</span>
<span class="go">      LOGROTATE_LOGFILE:       /logrotate-status/logrotatecron.log</span>
<span class="go">    Mounts:</span>
<span class="go">     /var/log from varlog (rw)</span>
<span class="go">     /var/log/pods from varlogpods (ro)</span>
<span class="go"> Volumes:</span>
<span class="go">  varlog:</span>
<span class="go">   Type:          HostPath (bare host directory volume)</span>
<span class="go">   Path:          /var/log</span>
<span class="go">   HostPathType:</span>
<span class="go">  varlogpods:</span>
<span class="go">   Type:          HostPath (bare host directory volume)</span>
<span class="go">   Path:          /var/log/pods</span>
<span class="go">   HostPathType:</span>
<span class="go"> Events:</span>
<span class="go"> Type    Reason            Age   From                  Message</span>
<span class="go"> ----    ------            ----  ----                  -------</span>
<span class="go"> Normal  SuccessfulCreate  51m   daemonset-controller  Created pod: logrotate-nx7gx</span>
<span class="go"> Normal  SuccessfulCreate  51m   daemonset-controller  Created pod: logrotate-cnfqv</span>
<span class="go"> Normal  SuccessfulCreate  51m   daemonset-controller  Created pod: logrotate-s7b52</span>
<span class="go"> Normal  SuccessfulCreate  51m   daemonset-controller  Created pod: logrotate-xqb9h</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get pods -o wide -n kube-system -l <span class="nv">name</span><span class="o">=</span>logrotate
<span class="go">NAME              READY   STATUS    RESTARTS   AGE   IP                NODE</span>
<span class="go">logrotate-cnfqv   1/1     Running   0          54m   192.168.189.72    worker2</span>
<span class="go">logrotate-nx7gx   1/1     Running   0          54m   192.168.13.2      c-plane1</span>
<span class="go">logrotate-s7b52   1/1     Running   0          54m   192.168.235.134   worker1</span>
<span class="go">logrotate-xqb9h   1/1     Running   0          54m   192.168.182.8     worker3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Apply this manifest file and check log rotations on each node.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<blockquote>
<div><ul class="simple">
<li><p>If time allows you can modify the LOGS_DIRECTORIES directive in manifest file to include additional directories. eg. <cite>/var/log/pods</cite></p></li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">LOGS_DIRECTORIES</span>
  <span class="n">value</span><span class="p">:</span> <span class="s2">&quot;/var/log /var/log/pods&quot;</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>In order to grow public readable log file please run the <em>/labfiles/k8s/Logging_and_monitoring/fill_package_log.sh</em> script on all nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="k">for</span> i <span class="k">in</span> c-plane1 worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> ssh <span class="si">${</span><span class="nv">i</span><span class="si">}</span> <span class="s2">&quot;/labfiles/k8s/Logging_and_monitoring/fill_package_log.sh&quot;</span><span class="p">;</span><span class="k">done</span>
<span class="go">Warning: Permanently added &#39;c-plane1&#39; (ED25519) to the list of known hosts.</span>
<span class="go">c-plane1</span>

<span class="go">c-plane1 done</span>

<span class="go">worker1</span>

<span class="go">worker1 done</span>

<span class="go">worker2</span>

<span class="go">worker2 done</span>

<span class="go">worker3</span>

<span class="go">worker3 done</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>Give some time to <strong>logrotate</strong> containers to operate and complete.</p></li>
</ul>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="k">for</span> i <span class="k">in</span> c-plane1 worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span><span class="k">do</span> ssh <span class="si">${</span><span class="nv">i</span><span class="si">}</span> <span class="s2">&quot;ls -l /var/log|egrep &#39;\-202[[:digit:]]+&#39;&quot;</span><span class="p">;</span><span class="k">done</span>
<span class="go">-rw-r--r--  1 root      root             23990 Feb  6 09:14 dpkg.log-1707210891-20240206</span>
<span class="go">-rw-r--r--  1 root      root             23493 Feb  6 09:15 dpkg.log-1707210931-20240206</span>
<span class="go">-rw-r--r--  1 root      root             23722 Feb  6 09:16 dpkg.log-1707210970-20240206</span>
<span class="go">-rw-r--r--  1 root      root             23552 Feb  6 09:16 dpkg.log-1707211010-20240206</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl delete -f daemonset-logrotate.yaml
<span class="go">daemonset.apps &quot;logrotate&quot; deleted</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod counter
<span class="go">pod &quot;counter&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="task-4-monitoring-kubernetes-core-metrics-pipeline">
<h3>Task 4:  Monitoring kubernetes core metrics pipeline<a class="headerlink" href="#task-4-monitoring-kubernetes-core-metrics-pipeline" title="Permalink to this headline"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> installer has not set up IP SANs for the TLS certificates configured for the kubelets.
The Subject Alternative Name field lets you specify additional host names (sites, IP addresses, common names, etc.) to be protected by a single SSL Certificate.</p>
</div>
<blockquote>
<div><p>Create new certificates for the kubelets, and include the IPs as Subject Alternative Names. To simplify things we will use the <code class="docutils literal notranslate"><span class="pre">cfssl</span></code> and <code class="docutils literal notranslate"><span class="pre">cfssljson</span></code> tools.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> scp -r c-plane1:/etc/kubernetes /etc/

<span class="go">... omitted lines ....</span>

<span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Logging_and_monitoring/certs/
<span class="gp">root@admin-ws $&gt;</span> ./getcssl.sh
<span class="gp">  %</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                                 Dload  Upload   Total   Spent    Left  Speed</span>
<span class="go">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span>
<span class="go">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span>
<span class="go">100  9.8M  100  9.8M    0     0  7441k      0  0:00:01  0:00:01 --:--:-- 30.9M</span>
<span class="gp">  %</span> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
<span class="go">                                 Dload  Upload   Total   Spent    Left  Speed</span>
<span class="go">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span>
<span class="go">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span>
<span class="go">100 2224k  100 2224k    0     0  2532k      0 --:--:-- --:--:-- --:--:-- 14.3M</span>
<span class="go">2024/02/05 12:19:29 [INFO] generate received request</span>
<span class="go">2024/02/05 12:19:29 [INFO] received CSR</span>
<span class="go">2024/02/05 12:19:29 [INFO] generating key: rsa-2048</span>
<span class="go">2024/02/05 12:19:29 [INFO] encoded CSR</span>
<span class="go">2024/02/05 12:19:29 [INFO] signed certificate with serial number 339609860424946231699314318581888404263939148472</span>

<span class="go">... omitted lines ...</span>
</pre></div>
</div>
<p>Verify whether the kubelets are using the new certificates:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws certs$&gt;</span> openssl s_client -connect worker2:10250<span class="p">|</span> openssl x509 -noout -text
<span class="go">...</span>
<span class="go">            X509v3 Subject Alternative Name:</span>
<span class="go">                 DNS:c-plane1, DNS:worker1, DNS:worker2, DNS:worker3,</span>
<span class="go">                 DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc,</span>
<span class="go">                 DNS:kubernetes.default.svc.cluster, DNS:kubernetes.default.svc.cluster.local,</span>
<span class="go">                 IP Address:127.0.0.1, IP Address:10.10.10.51, IP Address:10.10.10.52,</span>
<span class="go">                 IP Address:10.10.10.53, IP Address:10.10.10.54</span>

<span class="go">...</span>
</pre></div>
</div>
<ul>
<li><p>Install the metrics server</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Logging_and_monitoring/</span></code> directory you will find the file needed to install the metrics server:</p>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Logging_and_monitoring
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f metrics-server.yaml
<span class="go">serviceaccount/metrics-server created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span>
<span class="go">service/metrics-server created</span>
<span class="go">deployment.apps/metrics-server created</span>
<span class="go">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span>
</pre></div>
</div>
<blockquote>
<div><p>Verify that the metrics server pod is running properly.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl -n kube-system get pod -l k8s-app<span class="o">=</span>metrics-server
<span class="go">NAME                              READY     STATUS    RESTARTS   AGE</span>
<span class="gs">metrics-server-6f6cdbf67d-vfnnl</span><span class="go">     1/1       Running   0          5m</span>
</pre></div>
</div>
<blockquote>
<div><p>List the metrics for the nodes:</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws metrics-server$&gt;</span> kubectl top node
<span class="go">NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span>
<span class="go">c-plane1   215m         10%    1463Mi          78%</span>
<span class="go">worker1    65m          6%     872Mi           63%</span>
<span class="go">worker2    67m          6%     878Mi           64%</span>
<span class="go">worker3    52m          5%     863Mi           62%</span>
</pre></div>
</div>
</section>
<section id="task-5-monitoring-kubernetes-full-metrics-pipeline-optional">
<h3>Task 5:  Monitoring kubernetes full metrics pipeline (<em>OPTIONAL</em>)<a class="headerlink" href="#task-5-monitoring-kubernetes-full-metrics-pipeline-optional" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Start a <code class="docutils literal notranslate"><span class="pre">tunnel</span></code> instance from your desktop.</p></li>
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">NodePort</span></code> type service for the kubernetes dashboard.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl --namespace<span class="o">=</span>kubernetes-dashboard get deployment
<span class="go">NAME                        READY   UP-TO-DATE   AVAILABLE     AGE</span>
<span class="go">dashboard-metrics-scraper   1/1     1            1             44d</span>
<span class="go">kubernetes-dashboard        1/1     1            1             44d</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl -n kubernetes-dashboard expose deployment kubernetes-dashboard --name<span class="o">=</span>dashboard --type<span class="o">=</span>NodePort
<span class="go">service/dashboard exposed</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Identify the port where the dashboard is exposed.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl --namespace<span class="o">=</span>kubernetes-dashboard get svc dashboard
<span class="go">NAME        TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="go">dashboard   NodePort   10.99.250.229   &lt;none&gt;        8443:</span><span class="gs">32242</span><span class="go">/TCP   64s</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As of release 1.7 Dashboard no longer has full admin privileges granted by default.
For these exercises we will allow full admin priviledges to the dashboard.</p>
</div>
<ul class="simple">
<li><p>Create a ClusterRoleBindig that binds the <code class="docutils literal notranslate"><span class="pre">cluster-admin</span></code> ClusterRole to the <code class="docutils literal notranslate"><span class="pre">admin-user</span></code> ServiceAccount.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws Logging_and_monitoring$&gt;</span> cat dashboard-rbac.yaml
<span class="go">apiVersion: v1</span>
<span class="go">kind: ServiceAccount</span>
<span class="go">metadata:</span>
<span class="go">  name: admin-user</span>
<span class="go">  namespace: kubernetes-dashboard</span>

<span class="go">---</span>

<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">kind: ClusterRoleBinding</span>
<span class="go">metadata:</span>
<span class="go">  name: admin-user</span>
<span class="go">roleRef:</span>
<span class="go">  apiGroup: rbac.authorization.k8s.io</span>
<span class="go">  kind: ClusterRole</span>
<span class="go">  name: cluster-admin</span>
<span class="go">subjects:</span>
<span class="go">- kind: ServiceAccount</span>
<span class="go">  name: admin-user</span>
<span class="go">  namespace: kubernetes-dashboard</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f dashboard-rbac.yaml
<span class="go">serviceaccount/admin-user created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create an authentication token for <cite>admin-user</cite> service account</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<blockquote>
<div><p>You can generate token for <cite>default</cite> or <cite>kubernetes-dashboard</cite> service accounts as well, but those will gain access only to kubernetes-dashboard namespace.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl describe serviceaccounts -n kubernetes-dashboard
<span class="go">Name:                admin-user</span>
<span class="go">Namespace:           kubernetes-dashboard</span>
<span class="go">Labels:              &lt;none&gt;</span>
<span class="go">Annotations:         &lt;none&gt;</span>
<span class="go">Image pull secrets:  &lt;none&gt;</span>
<span class="go">Mountable secrets:   &lt;none&gt;</span>
<span class="go">Tokens:              &lt;none&gt;</span>
<span class="go">Events:              &lt;none&gt;</span>


<span class="go">Name:                default</span>
<span class="go">Namespace:           kubernetes-dashboard</span>
<span class="go">Labels:              &lt;none&gt;</span>
<span class="go">Annotations:         &lt;none&gt;</span>
<span class="go">Image pull secrets:  &lt;none&gt;</span>
<span class="go">Mountable secrets:   &lt;none&gt;</span>
<span class="go">Tokens:              &lt;none&gt;</span>
<span class="go">Events:              &lt;none&gt;</span>


<span class="go">Name:                kubernetes-dashboard</span>
<span class="go">Namespace:           kubernetes-dashboard</span>
<span class="go">Labels:              k8s-app=kubernetes-dashboard</span>
<span class="go">Annotations:         &lt;none&gt;</span>
<span class="go">Image pull secrets:  &lt;none&gt;</span>
<span class="go">Mountable secrets:   &lt;none&gt;</span>
<span class="go">Tokens:              &lt;none&gt;</span>
<span class="go">Events:              &lt;none&gt;</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create token -n kubernetes-dashboard admin-user
<span class="gs">eyJhbGciOiJSUzI1NiIsImtpZCI6IjVxaERCWVF5WEdSV3EzQ3NMMF9VMlRHaWtOUjVSM1JDMzF4eXhISHpxTVkifQ.e</span><span class="go"></span>
<span class="gs">yJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjczNjA3NDU3</span><span class="go"></span>
<span class="gs">LCJpYXQiOjE2NzM2MDM4NTcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiw</span><span class="go"></span>
<span class="gs">ia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im</span><span class="go"></span>
<span class="gs">5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiZTk1YjczODEtMDRkMy00MjA1LWExOGMtNjliYjg3YjY5MjI3In19LCJuYmYiO</span><span class="go"></span>
<span class="gs">jE2NzM2MDM4NTcsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2Vy</span><span class="go"></span>
<span class="gs">In0.Cfh9JDay5CG9mgefcvvYf6z4_tVOk3lBV9-u9WUYkuKJPIk-SR4EZSdvOxCPz_fWWlaxTrOqofcjK36TBXc1jT0MBKR</span><span class="go"></span>
<span class="gs">t0hyJPdVpk11EbjWwL7hvbDTNo8OHXtdzUj1aoblLXTXL5O7e1UVfQL8g-Bo7rLib7rnQE1S41OyMORAzPq08EQGA39zoQI</span><span class="go"></span>
<span class="gs">nCXngwKfTy-RGHt32rxQsVGdTRm0YJxS-RVEhtM2oelyBCCpPUduSBa_RRjRRoP1veTOhgmWxP_3_WmNdUKhIU9Mu6ri0-K</span><span class="go"></span>
<span class="gs">WJGkEIJ82ye4vJ0Vw6NIRwWqkPdIcTsTgEuWbjSL5vvNRaB_UtDujULv4BxtQ</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>On your remote lab desktop open a browser and connect to the address <a class="reference external" href="https://10.10.10.51:xxxxxx">https://10.10.10.51:xxxxxx</a> on the identified port.
Accept the self-signed certificate. Choose “Token” for authentication/authorization, and copy/paste the newly generated token.
Browse your dashboard!</p></li>
</ul>
<figure class="align-default" id="id7">
<a class="reference internal image-reference" href="_images/Dashboard.png"><img alt="_images/Dashboard.png" src="_images/Dashboard.png" style="width: 631.1999999999999px; height: 469.79999999999995px;" /></a>
<figcaption>
<p><span class="caption-text">Kubernetes Dashboard.</span><a class="headerlink" href="#id7" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Install <cite>influxdb</cite>, <cite>grafana</cite>, and <cite>heapster</cite> using the templates from the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Logging_and_monitoring</span></code> directory.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> ls
<span class="go">grafana.yaml  heapster_with_RBAC.yaml  influxdb.yaml ...</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f influxdb.yaml
<span class="go">deployment.apps/monitoring-influxdb created</span>
<span class="go">service/monitoring-influxdb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f grafana.yaml
<span class="go">deployment.apps/monitoring-grafana created</span>
<span class="go">service/monitoring-grafana created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f heapster_with_RBAC.yaml
<span class="go">serviceaccount/heapster created</span>
<span class="go">deployment.apps/heapster created</span>
<span class="go">service/heapster created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/heapster created</span>
</pre></div>
</div>
<p>Verify the status of the pods created for influxdb, grafana, heapster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl -n kube-system get pod -l <span class="nv">task</span><span class="o">=</span>monitoring
<span class="go">NAME                                   READY  STATUS    RESTARTS   AGE</span>
<span class="gs">heapster-5c9b97d48d-hz4xc</span><span class="go">              1/1    Running   0          7s</span>
<span class="gs">monitoring-grafana-845bc8df5f-dvs7g</span><span class="go">    1/1    Running   0          14s</span>
<span class="gs">monitoring-influxdb-56d9446bd9-f9mvb</span><span class="go">   1/1    Running   0          22s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl -n kube-system logs monitoring-influxdb-56d9446bd9-f9mvb

<span class="go"> 8888888           .d888 888                   8888888b.  888888b.</span>
<span class="go">   888            d88P&quot;  888                   888  &quot;Y88b 888  &quot;88b</span>
<span class="go">   888            888    888                   888    888 888  .88P</span>
<span class="go">   888   88888b.  888888 888 888  888 888  888 888    888 8888888K.</span>
<span class="go">   888   888 &quot;88b 888    888 888  888  Y8bd8P&#39; 888    888 888  &quot;Y88b</span>
<span class="go">   888   888  888 888    888 888  888   X88K   888    888 888    888</span>
<span class="go">   888   888  888 888    888 Y88b 888 .d8&quot;&quot;8b. 888  .d88P 888   d88P</span>
<span class="go"> 8888888 888  888 888    888  &quot;Y88888 888  888 8888888P&quot;  8888888P&quot;</span>

<span class="go">[I] 2024-02-05T12:53:05Z InfluxDB starting, version unknown, branch unknown, commit unknown</span>
<span class="go">[I] 2024-02-05T12:53:05Z Go version go1.8.3, GOMAXPROCS set to 1</span>
<span class="go">[I] 2024-02-05T12:53:05Z Using configuration at: /etc/config.toml</span>
<span class="go">[I] 2024-02-05T12:53:05Z Using data dir: /data/data service=store</span>
<span class="go">[I] 2024-02-05T12:53:05Z opened service service=subscriber</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting monitor system service=monitor</span>
<span class="go">[I] 2024-02-05T12:53:05Z &#39;build&#39; registered for diagnostics monitoring service=monitor</span>
<span class="go">[I] 2024-02-05T12:53:05Z &#39;runtime&#39; registered for diagnostics monitoring service=monitor</span>
<span class="go">[I] 2024-02-05T12:53:05Z &#39;network&#39; registered for diagnostics monitoring service=monitor</span>
<span class="go">[I] 2024-02-05T12:53:05Z &#39;system&#39; registered for diagnostics monitoring service=monitor</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting precreation service with check interval of 10m0s, advance period of 30m0s service=shard-precreation</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting snapshot service service=snapshot</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting continuous query service service=continuous_querier</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting HTTP service service=httpd</span>
<span class="go">[I] 2024-02-05T12:53:05Z Authentication enabled:false service=httpd</span>
<span class="go">[I] 2024-02-05T12:53:05Z Listening on HTTP:[::]:8086 service=httpd</span>
<span class="go">[I] 2024-02-05T12:53:05Z Starting retention policy enforcement service with check interval of 30m0s service=retention</span>
<span class="gs">[I] 2024-02-05T12:53:05Z Listening for signals</span><span class="go"></span>

<span class="go">...</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl -n kube-system logs monitoring-grafana-845bc8df5f-dvs7g<span class="p">|</span>tail
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Created default admin user: admin&quot;</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Starting plugin search&quot; logger=plugins</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=warn msg=&quot;Plugin dir does not exist&quot; logger=plugins dir=/usr/share/grafana/data/plugins</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Plugin dir created&quot; logger=plugins dir=/usr/share/grafana/data/plugins</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Initializing Stream Manager&quot;</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Initializing HTTP Server&quot; logger=http.server address=0.0.0.0:3000 protocol=http subUrl= socket=</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Initializing Alerting&quot; logger=alerting.engine</span>
<span class="go">t=2024-02-05T12:53:19+0000 lvl=info msg=&quot;Initializing CleanUpService&quot; logger=cleanup</span>
<span class="go">Connected to the Grafana dashboard.</span>
<span class="gs">The datasource for the Grafana dashboard is now set</span><span class="go"></span>

<span class="gp">root@admin-ws $&gt;</span> kubectl -n kube-system logs heapster-848fd8b656-h8nbp <span class="p">|</span> tail
<span class="go">E0113  13:08:05.005760      1 manager.go:101] </span><span class="gs">Error in scraping containers</span><span class="go"> from kubelet_summary:10.10.10.54:10250: request failed - &quot;403 Forbidden&quot;, response: &quot;Forbidden (user=system:serviceaccount:kube-system:heapster, verb=get, resource=nodes, subresource=stats)&quot;</span>
<span class="go">W0113  13:09:25.000426      1 manager.go:152] </span><span class="gs">Failed to get all responses </span><span class="go"> in time (got 0/4)</span>
<span class="go">...</span>
</pre></div>
</div>
<blockquote>
<div><p>The heapster pod <strong>can’t collect</strong> the metrics now:</p>
<p>The <code class="docutils literal notranslate"><span class="pre">system:heapster</span></code> ClusterRole associated with the ServiceAccount used by heapster is not allowed to retrieve the <code class="docutils literal notranslate"><span class="pre">stats</span></code> subresource of the <code class="docutils literal notranslate"><span class="pre">node</span></code> resources. We need to adjust the role to allow read access to the stats.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws ~$&gt;</span> kubectl edit clusterrole system:heapster

<span class="gp">#</span> Please edit the object below. Lines beginning with a <span class="s1">&#39;#&#39;</span> will be ignored,
<span class="gp">#</span> and an empty file will abort the edit. If an error occurs <span class="k">while</span> saving this file will be
<span class="gp">#</span> reopened with the relevant failures.
<span class="gp">#</span>
<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">kind: ClusterRole</span>
<span class="go">metadata:</span>
<span class="go">  annotations:</span>
<span class="go">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span>
<span class="go">  creationTimestamp: &quot;2024-02-05T11:31:49Z&quot;</span>
<span class="go">  labels:</span>
<span class="go">    kubernetes.io/bootstrapping: rbac-defaults</span>
<span class="go">  name: system:heapster</span>
<span class="go">  resourceVersion: &quot;62&quot;</span>
<span class="go">  uid: ce68fba7-8443-11e8-b8b7-080027000101</span>
<span class="go">rules:</span>
<span class="go">- apiGroups:</span>
<span class="go">  - &quot;&quot;</span>
<span class="go">  resources:</span>
<span class="go">  - events</span>
<span class="go">  - namespaces</span>
<span class="go">  - nodes</span>
<span class="go">  - </span><span class="gs">nodes/stats</span><span class="go"></span>
<span class="go">  - pods</span>
<span class="go">  verbs:</span>
<span class="go">  - get</span>
<span class="go">  - list</span>
<span class="go">  - watch</span>
<span class="go">- apiGroups:</span>
<span class="go">  - extensions</span>
<span class="go">  resources:</span>
<span class="go">  - deployments</span>
<span class="go">  verbs:</span>
<span class="go">  - get</span>
<span class="go">  - list</span>
<span class="go">  - watch</span>
</pre></div>
</div>
<blockquote>
<div><p>Wait a minute and verify whether there are <strong>no new error messages logged</strong> by the heapster pod:</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws ~$&gt;</span> sleep <span class="m">60</span><span class="p">;</span> date<span class="p">;</span> kubectl -n kube-system logs heapster-5c9b97d48d-hz4xc <span class="p">|</span> tail -1
<span class="go">Mon Feb 05 </span><span class="gs">13:12:17</span><span class="go"> UTC 2024</span>
<span class="go">W0614 </span><span class="gs">13:10:25.000687</span><span class="go">       1 manager.go:152] Failed to get all responses in time (got 0/4)</span>
</pre></div>
</div>
<blockquote>
<div><p>No new error messages were logged, so we should be able to visualize the data collected by heapster.</p>
</div></blockquote>
<ul class="simple">
<li><p>Identify the port where the grafana is exposed on the nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl --namespace<span class="o">=</span>kube-system get svc monitoring-grafana
<span class="go">NAME                 TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)              AGE</span>
<span class="go">monitoring-grafana   NodePort   10.103.118.232   &lt;none&gt;        80:</span><span class="gs">32076</span><span class="go">/TCP   28m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Open a new tab in the browser on your remote desktop and connect to the <a class="reference external" href="http://10.10.10.51:yyyyy">http://10.10.10.51:yyyyy</a> on the identified port. The grafana interface should appear. Here in the <strong>Home</strong> menu select “Pods”, then select the “kube-system” namespace and the monitoring-grafana POD.</p></li>
<li><p>Reload several times the dashboard and grafana tabs in your browser and observe how the graphs are evolving.</p></li>
</ul>
<figure class="align-default" id="id8">
<a class="reference internal image-reference" href="_images/Grafana.png"><img alt="_images/Grafana.png" src="_images/Grafana.png" style="width: 632.4px; height: 469.2px;" /></a>
<figcaption>
<p><span class="caption-text">Grafana desktop</span><a class="headerlink" href="#id8" title="Permalink to this image"></a></p>
<div class="legend">
</div>
</figcaption>
</figure>
<ul class="simple">
<li><p>In your terminal list the resource usage of the pods running in the <cite>kube-system</cite> namespace using the <cite>kubectl top</cite> command.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl top pod --namespace<span class="o">=</span>kube-system
<span class="go">NAME                                    CPU(cores)   MEMORY(bytes)</span>
<span class="go">...</span>
<span class="go">monitoring-grafana-973508798-h0815      0m           11Mi</span>
<span class="go">kube-controller-manager-c-plane1        8m           44Mi</span>
<span class="go">...</span>
</pre></div>
</div>
</section>
<section id="task-6-debug-running-pods">
<h3>Task 6:  Debug running pods<a class="headerlink" href="#task-6-debug-running-pods" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><dl class="simple">
<dt>The <strong>kubectl debug</strong> offers some debugging features:</dt><dd><ul>
<li><p>Adding ephemeral container to the pod</p></li>
<li><p>Using a copy of the pod</p></li>
<li><p>Using a shell on the node</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Adding ephemeral container to the pod</p></li>
</ul>
<p>You can use the kubectl debug command to add ephemeral containers to a running Pod. First, create a pod for the example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl run ephemeral-demo --image<span class="o">=</span>k8s.gcr.io/pause:3.1 --restart<span class="o">=</span>Never
<span class="go">pod/ephemeral-demo created</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -it ephemeral-demo -- sh
<span class="go">error: Internal error occurred: error executing command in container: failed to exec in</span>
<span class="go"> container: failed  to start exec &quot;ce36-----c0a45d9dd254f581f&quot;: OCI runtime exec failed:</span>
<span class="go"> exec failed: container_linux.go:380: starting container process caused: exec: &quot;sh&quot;:</span>
<span class="go"> executable file not found in $PATH: unknown</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl debug -it ephemeral-demo --image<span class="o">=</span>busybox:1.28 --target<span class="o">=</span>ephemeral-demo
<span class="go">Targeting container &quot;ephemeral-demo&quot;. If you don&#39;t see processes from this container it</span>
<span class="go">may be because the container runtime doesn&#39;t support this feature.</span>
<span class="go">Defaulting debug container name to </span><span class="gs">debugger-qmhgm</span><span class="go">.</span>
<span class="go">If you don&#39;t see a command prompt, try pressing enter.</span>
<span class="gp">root@/debugger-qmhgm #&gt;</span> ps ax
<span class="go">PID   USER     TIME  COMMAND</span>
<span class="go">    1 root      0:00 /pause</span>
<span class="go">   17 root      0:00 sh</span>
<span class="go">   23 root      0:00 ps ax</span>
<span class="gp">root@/debugger-qmhgm #&gt;</span> <span class="nb">exit</span>
</pre></div>
</div>
<p>This command adds a new busybox container and attaches to it. The <code class="docutils literal notranslate"><span class="pre">--target</span></code> parameter targets the process namespace of another container. It’s necessary here because kubectl run does not enable process namespace sharing in the pod it creates.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--target</span></code> parameter must be supported by the Container Runtime. When not supported, the Ephemeral Container may not be started, or it may be started with an isolated process namespace so that ps does not reveal processes in other containers.</p>
</div>
<p>You can view the state of the newly created ephemeral container using kubectl describe:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws:~#</span> kubectl describe pod ephemeral-demo
<span class="go">--- omitted lines ----</span>
<span class="go">Containers:</span>
<span class="go">  ephemeral-demo:</span>
<span class="go">    Container ID:   containerd://c1e0408957a907fd6e373afe-----3d89348ad7c643f853297d97703</span>
<span class="go">    Image:          k8s.gcr.io/pause:3.1</span>
<span class="go">    Image ID:       k8s.gcr.io/pause@sha256:f78411e19d84a-----983a2c2eeed83929b888179acea</span>
<span class="go">    Port:           &lt;none&gt;</span>
<span class="go">    Host Port:      &lt;none&gt;</span>
<span class="go">    State:          Running</span>
<span class="go">      Started:      Tue, 06 Feb 2024 08:27:43 +0000</span>
<span class="go">    Ready:          True</span>
<span class="go">    Restart Count:  0</span>
<span class="go">    Environment:    &lt;none&gt;</span>
<span class="go">    Mounts:</span>
<span class="go">      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-js66s (ro)</span>
<span class="go">Ephemeral Containers:</span>
<span class="go">  debugger-qmhgm:</span>
<span class="go">    Container ID:   containerd://b0abd26f8ca574fbf58eb2f9d9-----c56da2867e35817f1e17d5fd3</span>
<span class="go">    Image:          busybox:1.28</span>
<span class="go">    Image ID:       docker.io/library/busybox@sha256:141c25-----b6df416dea4f41046e0f37d47</span>
<span class="go">    Port:           &lt;none&gt;</span>
<span class="go">    Host Port:      &lt;none&gt;</span>
<span class="go">    State:          Terminated</span>
<span class="go">      Reason:       Completed</span>
<span class="go">      Exit Code:    0</span>
<span class="go">      Started:      Tue, 06 Feb 2024 08:28:12 +0000</span>
<span class="go">      Finished:     Tue, 06 Feb 2024 08:28:36 +0000</span>
<span class="go">    Ready:          False</span>
<span class="go">    Restart Count:  0</span>
<span class="go">    Environment:    &lt;none&gt;</span>
<span class="go">    Mounts:         &lt;none&gt;</span>

<span class="go">Events:</span>
<span class="go">  Type    Reason     Age   From               Message</span>
<span class="go">  ----    ------     ----  ----               -------</span>
<span class="go">  Normal  Scheduled  62s   default-scheduler  Successfully assigned</span>
<span class="go">                                                      default/ephemeral-demo to worker2</span>
<span class="go">  Normal  Pulling    61s   kubelet            Pulling image &quot;k8s.gcr.io/pause:3.1&quot;</span>
<span class="go">  Normal  Pulled     59s   kubelet            Successfully pulled image</span>
<span class="go">                                                       &quot;k8s.gcr.io/pause:3.1&quot; in 1.884s</span>
<span class="go">  Normal  Created    59s   kubelet            Created container ephemeral-demo</span>
<span class="go">  Normal  Started    59s   kubelet            Started container ephemeral-demo</span>
<span class="go">  Normal  Pulling    39s   kubelet            Pulling image &quot;busybox:1.28&quot;</span>
<span class="go">  Normal  Pulled     35s   kubelet            Successfully pulled image &quot;busybox:1.28&quot;</span>
<span class="go">                                                                        in 3.220500321s</span>
<span class="go">  Normal  Created    35s   kubelet            Created container debugger-qmhgm</span>
<span class="go">  Normal  Started    35s   kubelet            </span><span class="gs">Started container debugger-qmhgm</span><span class="go"></span>
<span class="gp">root@admin-ws:~#</span> kubectl delete pod ephemeral-demo
<span class="go">pod &quot;ephemeral-demo&quot; deleted</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Using a copy of the pod</p></li>
</ul>
<p>Adding a new container can be useful when your application is running but not behaving as you expect and you’d like to add additional troubleshooting utilities to the Pod.
For example, maybe your application’s container images are built on busybox but you need debugging utilities not included in busybox.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl run <span class="gs">myapp</span> --image<span class="o">=</span>busybox:1.28 --restart<span class="o">=</span>Never -- sleep <span class="m">3600</span>
<span class="go">pod/myapp created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl debug <span class="gs">myapp</span> -it --image<span class="o">=</span>ubuntu --share-processes --copy-to<span class="o">=</span><span class="gs">myapp-debug</span>
<span class="go">Defaulting debug container name to </span><span class="gs">debugger-w7xmf</span><span class="go">.</span>
<span class="go">If you don&#39;t see a command prompt, try pressing enter.</span>
<span class="gp">root@myapp-debug #&gt;</span> ps ax
<span class="go">  PID TTY      STAT   TIME COMMAND</span>
<span class="go">    1 ?        Ss     0:00 /pause</span>
<span class="go">    7 ?        Ss     0:00 </span><span class="gs">sleep 3600</span><span class="go"></span>
<span class="go">   15 pts/0    Ss     0:00 bash</span>
<span class="go">   25 pts/0    R+     0:00 ps ax</span>

<span class="gp">root@myapp-debug #&gt;</span> <span class="nb">exit</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl describe pod myapp-debug
<span class="go">--- lines omitted ---</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">debug</span></code> automatically generates a container name if you don’t choose one using the <code class="docutils literal notranslate"><span class="pre">--container</span></code> flag.
The -i flag causes kubectl debug to attach to the new container by default. You can prevent this by specifying <code class="docutils literal notranslate"><span class="pre">--attach=false</span></code>. If your session becomes disconnected you can reattach using kubectl attach.
The <code class="docutils literal notranslate"><span class="pre">--share-processes</span></code> allows the containers in this Pod to see processes from the other containers in the Pod. For more information about how this works, see Share Process Namespace between Containers in a Pod.</p>
</div>
<p>Don’t forget to clean up the debugging Pod when you’re finished with it:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl delete pod <span class="gs">myapp</span> <span class="gs">myapp-debug</span>
<span class="go">pod &quot;myapp&quot; deleted</span>
<span class="go">pod &quot;myapp-debug&quot; deleted</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Using a shell on the node</p></li>
</ul>
<p>You can find the Node on which the Pod is running and create a privileged Pod running in the host namespaces.
To create an interactive shell (debugging pod) on a node using kubectl debug, run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl debug <span class="gs">node/worker1</span> -it --image<span class="o">=</span>ubuntu
<span class="go">Creating debugging pod </span><span class="gs">node-debugger-worker1-pdx84</span><span class="go"> with container debugger on node </span><span class="gs">worker1</span><span class="go">.</span>
<span class="go">If you don&#39;t see a command prompt, try pressing enter.</span>
<span class="gp">root@worker1 $&gt;</span>
</pre></div>
</div>
<p>When creating a debugging session on a node, keep in mind that:</p>
<ul class="simple">
<li><p>kubectl debug automatically generates the name of the new Pod based on the name of the Node.</p></li>
<li><p>The container runs in the host IPC, Network, and PID namespaces.</p></li>
<li><p>The root filesystem of the Node will be mounted at <code class="docutils literal notranslate"><span class="pre">/host</span></code>.</p></li>
</ul>
<p>Don’t forget to clean up the debugging Pod when you’re finished with it:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1 $&gt;</span> <span class="nb">exit</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod <span class="gs">node-debugger-worker1-pdx84</span>
</pre></div>
</div>
</section>
<section id="task-7-managing-etcd">
<h3>Task 7:  Managing ETCD<a class="headerlink" href="#task-7-managing-etcd" title="Permalink to this headline"></a></h3>
<p>Let’s connect to ETCD service from <strong>c-plane1</strong> node</p>
<ul class="simple">
<li><p>Install etcd client locally</p></li>
<li><p>Generate a signed certificate to access etcd</p></li>
<li><p>Connect and list members of the etcd service</p></li>
<li><p>Create an etcdrc file</p></li>
</ul>
<p>Install etcd client locally</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We need the <em>etcdctl</em> command to manage the etcd containerized service on the control-plane node. The command is in the etcd-client package.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt list -a etcd-client
<span class="go">Listing... Done</span>
<span class="go">etcd-client/jammy 3.3.25+dfsg-7 amd64</span>
<span class="gp">root@c-plane1 $&gt;</span> apt install etcd-client
<span class="go">Reading package lists... Done</span>
<span class="go">Building dependency tree</span>
<span class="go">Reading state information... Done</span>
<span class="go">The following NEW packages will be installed:</span>
<span class="go">  etcd-client</span>

<span class="go">Setting up etcd-client (3.3.25+dfsg-7) ...</span>
<span class="go">Processing triggers for man-db (2.10.2-1) ...</span>
<span class="go">...</span>
</pre></div>
</div>
<p>Generate a signed certificate to access etcd</p>
<ul class="simple">
<li><p>Generate a 2048 long rsa key</p></li>
<li><p>Generate a certificate request</p></li>
<li><p>Sign the request with etcd-ca</p></li>
</ul>
<p>Change to /etc/kubernetes/pki/etcd/ and generate the key</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> <span class="nb">cd</span> /etc/kubernetes/pki/etcd/
<span class="gp">root@c-plane1 etcd $&gt;</span> openssl genrsa -out my-client.key <span class="m">2048</span>
</pre></div>
</div>
<p>Generate the certificate signing request. Use my-clinet.key. Fill in the request fields according to next output. Check your my-clinet.csr</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 etcd $&gt;</span> openssl req -out my-client.csr -key my-client.key -new -sha256
<span class="go">You are about to be asked to enter information that will be incorporated</span>
<span class="go">into your certificate request.</span>
<span class="go">What you are about to enter is what is called a Distinguished Name or a DN.</span>
<span class="go">There are quite a few fields but you can leave some blank</span>
<span class="go">For some fields there will be a default value,</span>
<span class="go">If you enter &#39;.&#39;, the field will be left blank.</span>
<span class="go">-----</span>
<span class="go">Country Name (2 letter code) [XX]:</span><span class="gs">.</span><span class="go"></span>
<span class="go">State or Province Name (full name) []:</span><span class="gs">.</span><span class="go"></span>
<span class="go">Locality Name (eg, city) []:</span><span class="gs">.</span><span class="go"></span>
<span class="go">Organization Name (eg, company) [Internet Widgits Pty Ltd]:</span><span class="gs">system:masters</span><span class="go"></span>
<span class="go">Organizational Unit Name (eg, section) []:</span><span class="gs">.</span><span class="go"></span>
<span class="go">Common Name (eg, server FQDN or YOUR name) []:</span><span class="gs">my-client</span><span class="go"></span>
<span class="go">Email Address []:</span>

<span class="go">Please enter the following &#39;extra&#39; attributes</span>
<span class="go">to be sent with your certificate request</span>
<span class="go">A challenge password []:</span>
<span class="go">An optional company name []:</span>
<span class="gp">root@c-plane1 etcd $&gt;</span> openssl req -in my-client.csr -noout -text
<span class="go">Certificate Request:</span>
<span class="go">    Data:</span>
<span class="go">        Version: 0 (0x0)</span>
<span class="go">        Subject: O=system:masters, CN=my-client</span>
<span class="go">        Subject Public Key Info:</span>
<span class="go">            Public Key Algorithm: rsaEncryption</span>
<span class="go">                Public-Key: (2048 bit)</span>
<span class="go">                Modulus:</span>
<span class="go">                    00:f3:cf:ad:ed:dc:c6:66:18:4a:4a:dc:f2:c9:73:</span>
<span class="go">                    1b:e6:66:ac:c8:da:d3:ee:c1:14:dd:07:bf:be:b8:</span>
<span class="go">                    ca:fc:96:6c:b6:6a:9f:42:33:a2:7e:46:36:ae:ec:</span>
<span class="go">                    83:86:b1:ca:05:75:64:f8:0d:05:53:c2:d0:b6:3c:</span>
<span class="go">                    5a:93:95:bd:92:25:a5:1c:a7:d8:24:82:a6:88:18:</span>
<span class="go">                    f2:b7:9a:1d:2c:fd:24:65:f6:3e:1d:3a:43:90:b2:</span>
<span class="go">                    bd:8f:38:7c:8a:12:5f:ad:35:fb:6e:34:f7:0e:76:</span>
<span class="go">                    1f:1f:fe:00:57:d8:a5:67:93:4f:47:f3:c3:75:86:</span>
<span class="go">                    62:c6:aa:92:ea:02:77:aa:fb:ae:26:07:7d:92:51:</span>
<span class="go">                    b4:d3:9a:46:fb:a9:32:82:de:0c:0c:7c:87:53:33:</span>
<span class="go">                    78:9a:05:46:7c:9c:7d:8e:39:9d:5a:dd:04:fe:83:</span>
<span class="go">                    d9:7f:2e:2e:03:87:f1:48:b2:6e:a3:d7:c0:60:de:</span>
<span class="go">                    fb:5c:b3:22:a0:81:82:47:92:75:ad:ee:32:9d:0c:</span>
<span class="go">                    fd:2d:99:8b:99:5f:f6:3e:8d:b8:e2:01:bf:6e:c4:</span>
<span class="go">                    3d:44:b4:39:02:c5:fe:62:ab:9d:7f:4e:db:66:08:</span>
<span class="go">                    62:b3:31:ed:ef:f9:e9:68:b9:b9:e6:3c:4c:ba:b7:</span>
<span class="go">                    2c:c3:73:78:4f:c1:85:fd:b3:61:46:0a:ae:cc:49:</span>
<span class="go">                    04:55</span>
<span class="go">                Exponent: 65537 (0x10001)</span>
<span class="go">        Attributes:</span>
<span class="go">            a0:00</span>
<span class="go">    Signature Algorithm: sha256WithRSAEncryption</span>
<span class="go">         76:8f:9b:cf:5a:8b:1e:6b:aa:78:b2:98:89:0e:4e:a6:94:da:</span>
<span class="go">         ef:35:10:f3:f7:46:96:27:9a:e1:58:33:f7:58:ba:73:15:fa:</span>
<span class="go">         99:70:bf:76:c5:21:1c:fc:4c:c2:50:35:aa:92:9d:bb:fb:fa:</span>
<span class="go">         d3:be:09:29:36:c8:0b:73:e2:5f:c9:95:58:52:83:67:43:d3:</span>
<span class="go">         13:e5:5b:12:85:63:45:7a:ae:9f:de:5f:90:09:21:a2:e5:0a:</span>
<span class="go">         ed:b6:ad:e6:4f:4a:b8:60:45:13:76:b8:71:f5:1e:d1:90:a1:</span>
<span class="go">         e8:3c:a0:0e:1b:1b:c5:69:7d:5a:30:ba:75:f0:1e:ad:f9:db:</span>
<span class="go">         b0:40:00:89:2d:28:0f:95:3e:70:ad:f2:49:9d:17:73:fd:31:</span>
<span class="go">         50:7a:f8:54:28:9b:de:df:8f:40:df:11:87:67:1e:0e:ca:2b:</span>
<span class="go">         36:fe:73:28:31:46:e0:45:84:64:ce:36:fd:e0:6e:bd:a6:be:</span>
<span class="go">         a3:7b:b1:87:85:27:9c:d9:19:3e:88:44:d8:e1:22:88:6b:6f:</span>
<span class="go">         ae:0c:2a:41:5c:25:01:cb:cb:04:1a:be:53:31:c7:57:73:79:</span>
<span class="go">         14:13:3b:57:89:32:e4:94:e7:e1:e7:42:3d:3c:df:81:03:f8:</span>
<span class="go">         9d:36:ed:d6:5f:74:33:f9:89:9b:ba:eb:ed:5a:bc:b4:2a:0b:</span>
<span class="go">         95:15:4d:3a</span>
</pre></div>
</div>
<p>Sign the request with etcd-ca</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 etcd $&gt;</span> openssl x509 -req -days <span class="m">360</span> -sha256 -in my-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out my-client.crt
<span class="go">Certificate request self-signature ok</span>
<span class="go">subject=O = system:masters, CN = my-client</span>
</pre></div>
</div>
<p>Connect and list members of the etcd service</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 etcd $&gt;</span> <span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span><span class="m">10</span>.10.10.51:2379 --key<span class="o">=</span>/etc/kubernetes/pki/etcd/my-client.key --cert<span class="o">=</span>/etc/kubernetes/pki/etcd/my-client.crt --cacert<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt member list
<span class="go">e8326a5f94bd1125, </span><span class="gs">started,</span><span class="go"> </span><span class="gs">c-plane1,</span><span class="go"> https://10.10.10.51:2380, https://10.10.10.51:2379</span>
<span class="gp">root@c-plane1 etcd $&gt;</span> <span class="nb">cd</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<p>Use an etcdrc file</p>
<ul class="simple">
<li><p>Check the etcdrc file</p></li>
<li><p>Source etcdrc and test it</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> cat /labfiles/k8s/Logging_and_monitoring/etcd.rc
<span class="go">export ETCDCTL_API=3</span>
<span class="go">export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt</span>
<span class="go">export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/my-client.crt</span>
<span class="go">export ETCDCTL_ENDPOINTS=10.10.10.51:2379</span>
<span class="go">export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/my-client.key</span>
<span class="gp">root@c-plane1 $&gt;</span> <span class="nb">source</span> /labfiles/k8s/Logging_and_monitoring/etcd.rc
<span class="gp">root@c-plane1 $&gt;</span> etcdctl member list
<span class="go">e8326a5f94bd1125, started, c-plane1, https://10.10.10.51:2380, https://10.10.10.51:2379</span>
<span class="gp">root@c-plane1 $&gt;</span> etcdctl member list --write-out<span class="o">=</span>table
<span class="go">+------------------+---------+---------+--------------------------+--------------------------+</span>
<span class="go">|        ID        | STATUS  |  NAME   |        PEER ADDRS        |       CLIENT ADDRS       |</span>
<span class="go">+------------------+---------+---------+--------------------------+--------------------------+</span>
<span class="go">| e8326a5f94bd1125 | started | c-plane1 | https://10.10.10.51:2380 | https://10.10.10.51:2379 |</span>
<span class="go">+------------------+---------+---------+--------------------------+--------------------------+</span>
</pre></div>
</div>
</section>
<section id="task-8-create-and-restore-etcd-snapshot">
<h3>Task 8:  Create and restore ETCD snapshot<a class="headerlink" href="#task-8-create-and-restore-etcd-snapshot" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a deployment</p></li>
<li><p>Create a snapshot</p></li>
<li><p>Make changes in kubernetes</p></li>
<li><p>Restore the snapshot</p></li>
<li><p>Move the restored etcd database to /var/lib/etcd and restart master node</p></li>
<li><p>Check the restored etc and system</p></li>
</ul>
<dl class="simple">
<dt>Create a deployment</dt><dd><ul class="simple">
<li><p>Let’s create a new deployment named web-dep.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl create deploy web-dep --image<span class="o">=</span>nginx --replicas<span class="o">=</span><span class="m">2</span> --dry-run<span class="o">=</span>client -o yaml &gt; web-dep.yaml
<span class="gp">root@c-plane1 $&gt;</span> kubectl apply -f web-dep.yaml
<span class="go">deployment.apps/web-dep created</span>
<span class="gp">root@c-plane1 $&gt;</span> kubectl get pod,deploy -o wide
<span class="go">NAME                           READY   STATUS    RESTARTS  AGE   IP              NODE</span>
<span class="gs">pod/web-dep-5bb56f58f4-flfgr</span><span class="go">   1/1     Running   0         36s   192.168.235.150 worker1</span>
<span class="gs">pod/web-dep-5bb56f58f4-knggz</span><span class="go">   1/1     Running   0         36s   192.168.189.100 worker2</span>

<span class="go">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES</span>
<span class="go">deployment.apps/web-dep   2/2     2            2           36s   nginx        nginx</span>
</pre></div>
</div>
<dl class="simple">
<dt>Create a snapshot</dt><dd><ul class="simple">
<li><p>The snapshot goes to snapshot.db</p></li>
<li><p>Check its status</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> <span class="nb">source</span> /labfiles/k8s/Logging_and_monitoring/etcd.rc
<span class="gp">root@c-plane1 $&gt;</span> etcdctl snapshot save snapshot.db
<span class="go">...</span>
<span class="go">Snapshot saved at snapshot.db</span>
<span class="gp">root@c-plane1 $&gt;</span> etcdctl snapshot status snapshot.db --write-out<span class="o">=</span>table
<span class="go">+----------+----------+------------+------------+</span>
<span class="go">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</span>
<span class="go">+----------+----------+------------+------------+</span>
<span class="go">| 446a55c6 |   112338 |       1102 |      11 MB |</span>
<span class="go">+----------+----------+------------+------------+</span>
</pre></div>
</div>
<dl class="simple">
<dt>Make changes in kubernetes</dt><dd><ul class="simple">
<li><p>Delete the newly created web-dep deployment.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl delete deploy web-dep
<span class="go">deployment.apps &quot;web-dep&quot; deleted</span>
</pre></div>
</div>
<dl class="simple">
<dt>Restore the snapshot</dt><dd><ul class="simple">
<li><p>The snapshot will be restored into ‘’default.etcd’’ folder!</p></li>
<li><p>The restore process complains, but works!</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> etcdctl snapshot restore snapshot.db --skip-hash-check
<span class="go">2024-02-05 13:34:17.320131 I | mvcc: restore compact to 29236</span>
<span class="go">2024-02-05 13:34:17.331989 I | etcdserver/membership: added member 8e9e05c52164694d [http://local</span>
<span class="go">host:2380] to cluster cdf818194e3a8c32</span>
<span class="gp">root@c-plane1 $&gt;</span> ls
<span class="gs">default.etcd</span><span class="go">  etcd.rc  install_kubeadm.sh  snapshot.db  web-dep.yaml</span>
</pre></div>
</div>
<dl class="simple">
<dt>Move the restored etcd database to /var/lib/etcd and restart control plane components.</dt><dd><ul class="simple">
<li><p>Stop the control plane components</p></li>
<li><p>Move the restored database from local folder to its preconfigured place</p></li>
<li><p>Restart the control plane components.</p></li>
<li><p>Restart the kubelet service on <strong>all</strong> the nodes</p></li>
</ul>
</dd>
</dl>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> mkdir -p ~/manifests
<span class="gp">root@c-plane1 $&gt;</span> mv /etc/kubernetes/manifests/* ~/manifests/
<span class="gp">root@c-plane1 $&gt;</span> crictl ps <span class="p">|</span> egrep <span class="s1">&#39;apiserver|etcd&#39;</span>

<span class="gp">#</span> CAUTION: only proceed <span class="k">if</span> both processes have stopped, and this <span class="nb">command</span> prints nothing. You may need to reissue this <span class="nb">command</span> a few <span class="nb">times</span> <span class="k">until</span> you can see none of the processes.

<span class="gp">root@c-plane1 $&gt;</span> mv /var/lib/etcd/member /var/lib/etcd/member_orig
<span class="gp">root@c-plane1 $&gt;</span> cp -a ~/default.etcd/member /var/lib/etcd
<span class="gp">root@c-plane1 $&gt;</span> mv ~/manifests/* /etc/kubernetes/manifests/

<span class="gp">#</span> It may take a few minutes <span class="k">for</span> the control plane to start up.

<span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   44d   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          44d   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          44d   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          44d   v1.29.0</span>
<span class="gp">root@c-plane1 $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>kubectl get nodes -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items[*].metadata.name}&#39;</span><span class="k">)</span><span class="p">;</span> <span class="k">do</span> ssh <span class="nv">$i</span> systemctl restart kubelet<span class="p">;</span> <span class="k">done</span>
</pre></div>
</div>
<p>Check the restored etcd and system</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get pods -A

<span class="go">NAMESPACE              NAME                                         READY   STATUS</span>
<span class="go">default                </span><span class="gs">web-dep-5bb56f58f4-flfgr</span><span class="go">                     1/1     Running</span>
<span class="go">default                </span><span class="gs">web-dep-5bb56f58f4-knggz</span><span class="go">                     1/1     Running</span>
<span class="go">kube-system            calico-kube-controllers-6dfcd885bf-8q2xt     1/1     Running</span>
<span class="go">kube-system            calico-node-8m4dh                            1/1     Running</span>
<span class="go">kube-system            calico-node-jtvxf                            1/1     Running</span>
<span class="go">kube-system            calico-node-m7jh9                            1/1     Running</span>
<span class="go">kube-system            calico-node-vl54w                            1/1     Running</span>
<span class="go">kube-system            coredns-74ff55c5b-55jvm                      1/1     Running</span>
<span class="go">kube-system            coredns-74ff55c5b-bjdp7                      1/1     Running</span>
<span class="go">kube-system            default-http-backend-6d7b64b8d8-zhg9v        1/1     Running</span>
<span class="go">kube-system            etcd-c-plane1                                 1/1     Running</span>
<span class="go">kube-system            heapster-d767cc88f-ft44z                     1/1     Running</span>
<span class="go">kube-system            kube-apiserver-c-plane1                       1/1     Running</span>
<span class="go">kube-system            kube-controller-manager-c-plane1              1/1     Running</span>
<span class="go">kube-system            kube-proxy-56n4g                             1/1     Running</span>
<span class="go">kube-system            kube-proxy-67dwf                             1/1     Running</span>
<span class="go">kube-system            kube-proxy-r9zjb                             1/1     Running</span>
<span class="go">kube-system            kube-proxy-wpn5j                             1/1     Running</span>
<span class="go">kube-system            kube-scheduler-c-plane1                       1/1     Running</span>
<span class="go">kube-system            metrics-server-6b6f887dd-fsv2d               1/1     Running</span>
<span class="go">kube-system            monitoring-grafana-ff99567f4-zb45f           1/1     Running</span>
<span class="go">kube-system            monitoring-influxdb-5cf7f5bf76-jms48         1/1     Running</span>
<span class="go">kube-system            nginx-ingress-controller-667c5f79c-pw5q6     1/1     Running</span>
<span class="go">kubernetes-dashboard   dashboard-metrics-scraper-74db988864-jpq8z   1/1     Running</span>
<span class="go">kubernetes-dashboard   kubernetes-dashboard-84f46948d6-wxmnj        1/1     Running</span>
<span class="gp">root@c-plane1 $&gt;</span> kubectl get pods
<span class="go">pod/</span><span class="gs">web-dep-5bb56f58f4-flfgr</span><span class="go">   1/1     Running   0          8m34s</span>
<span class="go">pod/web-dep-5bb56f58f4-knggz   1/1     Running   0          8m34s</span>
<span class="gp">root@c-plane1 $&gt;</span> kubectl <span class="nb">exec</span> <span class="gs">web-dep-5bb56f58f4-flfgr</span> -- ls
<span class="go">bin</span>
<span class="go">boot</span>
<span class="go">dev</span>
<span class="go">docker-entrypoint.d</span>
<span class="go">docker-entrypoint.sh</span>
<span class="go">etc</span>
<span class="go">home</span>
<span class="go">lib</span>
<span class="go">lib64</span>
<span class="go">media</span>
<span class="go">mnt</span>
<span class="go">opt</span>
<span class="go">proc</span>
<span class="go">root</span>
<span class="go">run</span>
<span class="go">sbin</span>
<span class="go">srv</span>
<span class="go">sys</span>
<span class="go">tmp</span>
<span class="go">usr</span>
<span class="go">var</span>

<span class="gp">root@c-plane1 $&gt;</span> kubectl create deployment --image<span class="o">=</span>nginx new
<span class="go">deployment.apps/new created</span>
<span class="gp">root@c-plane1 $&gt;</span> kubectl get pods,deploy
<span class="go">NAME                           READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/new-6f68b5c794-rb7lf       1/1     Running   0          58s</span>
<span class="go">pod/web-dep-5bb56f58f4-flfgr   1/1     Running   0          8m34s</span>
<span class="go">pod/web-dep-5bb56f58f4-knggz   1/1     Running   0          8m34s</span>

<span class="go">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/new       1/1     1            1           58s</span>
<span class="go">deployment.apps/web-dep   2/2     2            2           8m34s</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-9-kubernetes-installation-and-upgrade">
<h2>Lab 9:  Kubernetes Installation and Upgrade<a class="headerlink" href="#lab-9-kubernetes-installation-and-upgrade" title="Permalink to this headline"></a></h2>
<section id="task-1-preparing-system-for-installation">
<h3>Task 1:  Preparing system for installation<a class="headerlink" href="#task-1-preparing-system-for-installation" title="Permalink to this headline"></a></h3>
<p>Before start of installation, you have to reset your nodes to initial, uninstalled state.</p>
<ul class="simple">
<li><p>Reset nodes by <cite>os_nodes</cite> script.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes reset_nodes
<span class="go">Domain &#39;c-plane1&#39; destroyed</span>

<span class="go">Domain &#39;worker1&#39; destroyed</span>

<span class="go">Domain &#39;worker2&#39; destroyed</span>

<span class="go">Domain &#39;worker3&#39; destroyed</span>

<span class="go">Domain &#39;service&#39; destroyed</span>

<span class="go">Domain &#39;admin-ws&#39; destroyed</span>

<span class="go">Domain &#39;c-plane1&#39; started</span>

<span class="go">Domain &#39;worker1&#39; started</span>

<span class="go">Domain &#39;worker2&#39; started</span>

<span class="go">Domain &#39;worker3&#39; started</span>

<span class="go">Domain &#39;service&#39; started</span>

<span class="go">Domain &#39;admin-ws&#39; started</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Wait a few seconds, and verify whether nodes are in running state</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes status
<span class="gs">admin-ws     running</span><span class="go"></span>
<span class="gs">c-plane1     running</span><span class="go"></span>
<span class="gs">worker1      running</span><span class="go"></span>
<span class="gs">worker2      running</span><span class="go"></span>
<span class="gs">worker3      running</span><span class="go"></span>
<span class="gs">service      running</span><span class="go"></span>
</pre></div>
</div>
</section>
<section id="task-2-prerequisites-to-be-verified">
<h3>Task 2:  Prerequisites - to be verified<a class="headerlink" href="#task-2-prerequisites-to-be-verified" title="Permalink to this headline"></a></h3>
<p>Based on kubernetes.io (<a class="reference external" href="https://goo.gl/ZhpXGT">https://goo.gl/ZhpXGT</a>) you can check a list of prerequisites.</p>
<ul class="simple">
<li><p>Verify memory allocation of your nodes</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="nb">echo</span> worker1 worker2 worker3 c-plane1 &gt; nodes
<span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> virsh dominfo <span class="nv">$i</span><span class="p">|</span>grep -E <span class="s1">&#39;Name|memory&#39;</span><span class="p">;</span><span class="k">done</span>
<span class="go">Name:           worker1</span>
<span class="go">Max memory:     1572864 KiB</span>
<span class="go">Used memory:    1572864 KiB</span>
<span class="go">Name:           worker2</span>
<span class="go">Max memory:     1572864 KiB</span>
<span class="go">Used memory:    1572864 KiB</span>
<span class="go">Name:           worker3</span>
<span class="go">Max memory:     1572864 KiB</span>
<span class="go">Used memory:    1572864 KiB</span>
<span class="go">Name:           c-plane1</span>
<span class="go">Max memory:     2097152 KiB</span>
<span class="go">Used memory:    2097152 KiB</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify the uniqueness of MAC addresses and product UUID-s of nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span>virsh domiflist <span class="nv">$i</span><span class="p">;</span><span class="k">done</span>
<span class="go">worker1</span>
<span class="go">Interface  Type       Source     Model       MAC</span>
<span class="go">-------------------------------------------------------</span>
<span class="go">vnet2      bridge     br_management virtio      52:54:00:00:02:01</span>

<span class="go">worker2</span>
<span class="go">Interface  Type       Source     Model       MAC</span>
<span class="go">-------------------------------------------------------</span>
<span class="go">vnet3      bridge     br_management virtio      52:54:00:00:02:02</span>

<span class="go">worker3</span>
<span class="go">Interface  Type       Source     Model       MAC</span>
<span class="go">-------------------------------------------------------</span>
<span class="go">vnet4      bridge     br_management virtio      52:54:00:00:04:01</span>

<span class="go">c-plane1</span>
<span class="go">Interface  Type       Source     Model       MAC</span>
<span class="go">-------------------------------------------------------</span>
<span class="go">vnet1      bridge     br_management virtio      52:54:00:00:01:01</span>

<span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span> ssh <span class="nv">$i</span> <span class="s1">&#39;cat /sys/class/dmi/id/product_uuid&#39;</span><span class="p">;</span><span class="k">done</span>
<span class="go">worker1</span>
<span class="go">23d9ff4f-b2d8-4c34-a88b-2a58616f0184</span>
<span class="go">worker2</span>
<span class="go">fc55c941-b74d-41ec-9d64-4f3b462ac362</span>
<span class="go">worker3</span>
<span class="go">a4b36a34-84fc-486f-aae2-a2787ffbe0b2</span>
<span class="go">c-plane1</span>
<span class="go">e69192fb-a9bd-439d-ac5b-1317cb3abe38</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The swapping has to be disabled, in order to kubelet to work fine. (swapon -s checks it only)</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span>ssh <span class="nv">$i</span> <span class="s1">&#39;swapon -s&#39;</span><span class="p">;</span><span class="k">done</span>
<span class="go">worker1</span>
<span class="go">worker2</span>
<span class="go">worker3</span>
<span class="go">c-plane1</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify whether all necessary input ports are open.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span>ssh <span class="nv">$i</span> <span class="s1">&#39;iptables -nvL INPUT&#39;</span><span class="p">;</span><span class="k">done</span>
<span class="go">worker1</span>
<span class="go">Chain INPUT (policy ACCEPT 0 packets, 0 bytes)</span>
<span class="go">pkts bytes target     prot opt in     out     source               destination</span>
<span class="go">worker2</span>
<span class="go">Chain INPUT (policy ACCEPT 0 packets, 0 bytes)</span>
<span class="go">pkts bytes target     prot opt in     out     source               destination</span>
<span class="go">worker3</span>
<span class="go">Chain INPUT (policy ACCEPT 0 packets, 0 bytes)</span>
<span class="go">pkts bytes target     prot opt in     out     source               destination</span>
<span class="go">c-plane1</span>
<span class="go">Chain INPUT (policy ACCEPT 0 packets, 0 bytes)</span>
<span class="go">pkts bytes target     prot opt in     out     source               destination</span>
</pre></div>
</div>
</section>
<section id="task-3-installing-containerd">
<h3>Task 3:  Installing Containerd<a class="headerlink" href="#task-3-installing-containerd" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Prepare system to support <em>br_netfilter</em> on all nodes</p></li>
<li><p>Run <em>install_containerd.sh</em> script from <em>/labfiles/k8s/Install_and_upgrade/</em> directory.</p></li>
</ul>
<p>The script will setup the kernel modules, the kernel parameters, and apply them.
Then setup the package repository and installs containerd package. Finally setup the containerd.</p>
<p>The content of the script is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="n">echo</span> <span class="s2">&quot;Setup the kernel modules and parameters&quot;</span>

<span class="n">cat</span> <span class="o">&lt;&lt;</span><span class="n">EOF</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">modules</span><span class="o">-</span><span class="n">load</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">k8s</span><span class="o">.</span><span class="n">conf</span>
<span class="n">br_netfilter</span>
<span class="n">overlay</span>
<span class="n">EOF</span>
<span class="n">modprobe</span> <span class="n">br_netfilter</span>

<span class="n">cat</span> <span class="o">&lt;&lt;</span><span class="n">EOF</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">sysctl</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">k8s</span><span class="o">.</span><span class="n">conf</span>
<span class="n">net</span><span class="o">.</span><span class="n">bridge</span><span class="o">.</span><span class="n">bridge</span><span class="o">-</span><span class="n">nf</span><span class="o">-</span><span class="n">call</span><span class="o">-</span><span class="n">ip6tables</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">net</span><span class="o">.</span><span class="n">bridge</span><span class="o">.</span><span class="n">bridge</span><span class="o">-</span><span class="n">nf</span><span class="o">-</span><span class="n">call</span><span class="o">-</span><span class="n">iptables</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">net</span><span class="o">.</span><span class="n">ipv4</span><span class="o">.</span><span class="n">ip_forward</span>                 <span class="o">=</span> <span class="mi">1</span>
<span class="n">EOF</span>

<span class="n">echo</span> <span class="s2">&quot;Loading the new kernel configurations&quot;</span>

<span class="n">sysctl</span> <span class="o">--</span><span class="n">system</span>

<span class="n">echo</span> <span class="s2">&quot;Setup package repository and install packages&quot;</span>

<span class="n">apt</span> <span class="n">update</span> <span class="o">&amp;&amp;</span> <span class="n">apt</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">ca</span><span class="o">-</span><span class="n">certificates</span> <span class="n">curl</span> <span class="n">gnupg</span> <span class="n">lsb</span><span class="o">-</span><span class="n">release</span>
<span class="n">curl</span> <span class="o">-</span><span class="n">fsSL</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">docker</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">linux</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">gpg</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">gpg</span> <span class="o">--</span><span class="n">dearmor</span> <span class="o">-</span><span class="n">o</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">keyrings</span><span class="o">/</span><span class="n">docker</span><span class="o">-</span><span class="n">archive</span><span class="o">-</span><span class="n">keyring</span><span class="o">.</span><span class="n">gpg</span>

<span class="n">echo</span> <span class="s2">&quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">apt</span><span class="o">/</span><span class="n">sources</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">docker</span><span class="o">.</span><span class="n">list</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span>

<span class="n">apt</span> <span class="n">update</span>
<span class="n">apt</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">containerd</span><span class="o">.</span><span class="n">io</span>

<span class="n">echo</span> <span class="s2">&quot;Setup containerd&quot;</span>

<span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">containerd</span>
<span class="n">containerd</span> <span class="n">config</span> <span class="n">default</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">containerd</span><span class="o">/</span><span class="n">config</span><span class="o">.</span><span class="n">toml</span>
<span class="n">sed</span> <span class="s1">&#39;s/SystemdCgroup = false/SystemdCgroup = true/g&#39;</span> <span class="o">-</span><span class="n">i</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">containerd</span><span class="o">/</span><span class="n">config</span><span class="o">.</span><span class="n">toml</span>
<span class="n">systemctl</span> <span class="n">restart</span> <span class="n">containerd</span>

</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="nb">echo</span> worker1 worker2 worker3 c-plane1 &gt; nodes
<span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span> ssh <span class="si">${</span><span class="nv">i</span><span class="si">}</span> <span class="s2">&quot;/labfiles/k8s/Install_and_upgrade/install_containerd.sh&quot;</span><span class="p">;</span><span class="k">done</span>
<span class="gs">worker1</span><span class="go"></span>
<span class="gs">Setup the kernel modules and parameters</span><span class="go"></span>
<span class="go">br_netfilter</span>
<span class="go">overlay</span>
<span class="go">net.bridge.bridge-nf-call-ip6tables = 1</span>

<span class="go">----- omitted lines ------</span>
<span class="go">[ttrpc]</span>
<span class="go">  address = &quot;&quot;</span>
<span class="go">  gid = 0</span>
<span class="go">  uid = 0</span>

<span class="gp">root@lab_machine $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Test changes made by  the script</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> ssh worker3 <span class="s2">&quot;egrep -i &#39;version|SystemdCgroup&#39; /etc/containerd/config.toml&quot;</span>
<span class="go">version = 2</span>
<span class="go">            </span><span class="gs">SystemdCgroup = true</span><span class="go"></span>
<span class="gp">root@lab_machine $&gt;</span>
<span class="gp">root@lab_machine $&gt;</span> ssh worker1 systemctl status containerd <span class="p">|</span> grep -C1 active
<span class="go">   Loaded: loaded (/lib/systemd/system/containerd.service; enabled; )</span>
<span class="go">   Active: </span><span class="gs">active</span><span class="go"> (</span><span class="gs">running</span><span class="go">) since Tue 2024-02-06 10:02:28 UTC; 1min 22s ago</span>
<span class="go">     Docs: https://containerd.io</span>
</pre></div>
</div>
</section>
<section id="task-4-install-kubelet-kubeadm-kubectl">
<h3>Task 4:  Install kubelet, kubeadm, kubectl<a class="headerlink" href="#task-4-install-kubelet-kubeadm-kubectl" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Download and add google gpg key, add kubernetes repo. Install kubelet,kubeadm and kubelet</p></li>
<li><p>Run <em>/labfiles/k8s/Install_and_upgrade/install_kubeadm.sh</em> which one will done all tasks.</p></li>
</ul>
<p>The content of script is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

if [ $# -ne 1 ]
  then
    echo &quot;Please specify Kubernetes version as the argument of script!&quot;
    echo &quot;Such as $0 1.27.0&quot;
    echo
    exit 1
fi

MAJOR_MINOR=$(echo $1|cut -d&quot;.&quot; -f1,2)
PATCH=$(echo $1|cut -d&quot;.&quot; -f3)

echo &quot;Setup the package repository and install the kubernetes packages&quot;
apt update
curl -fsSL https://pkgs.k8s.io/core:/stable:/v${MAJOR_MINOR}/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo &quot;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v${MAJOR_MINOR}/deb/ /&quot; | sudo tee /etc/apt/sources.list.d/kubernetes.list

apt update

PKG_VERSION=$(apt list -a kubeadm|grep $1|awk /amd64/&#39;{print $2}&#39;)

apt install -y kubelet=${PKG_VERSION} kubeadm=${PKG_VERSION} kubectl=${PKG_VERSION}
apt-mark hold kubelet kubeadm kubectl

</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span> ssh <span class="si">${</span><span class="nv">i</span><span class="si">}</span> <span class="s2">&quot;/labfiles/k8s/Install_and_upgrade/install_kubeadm.sh 1.29.0&quot;</span><span class="p">;</span><span class="k">done</span>
<span class="gs">worker1</span><span class="go"></span>
<span class="gs">Setup the package repository and install the kubernetes packages</span><span class="go"></span>

<span class="go">WARNING: apt does not have a stable CLI interface. Use with caution in scripts.</span>

<span class="go">Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease</span>


<span class="go">----- omitted lines -----</span>

<span class="go">kubelet set on hold.</span>
<span class="go">kubeadm set on hold.</span>
<span class="go">kubectl set on hold.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify kubelet service on all nodes</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> <span class="k">for</span> i <span class="k">in</span> <span class="k">$(</span>cat nodes<span class="k">)</span><span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">;</span> ssh <span class="nv">$i</span> <span class="s1">&#39;systemctl status kubelet&#39;</span> <span class="p">;</span> <span class="k">done</span>
<span class="go">worker1</span>
<span class="go"> kubelet.service - kubelet: The Kubernetes Node Agent</span>
<span class="go">     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)</span>
<span class="go">     Drop-In: /usr/lib/systemd/system/kubelet.service.d</span>
<span class="go">             └─10-kubeadm.conf</span>
<span class="go">     Active: </span><span class="gs">inactive (dead)</span><span class="go"></span>
<span class="go">       Docs: https://kubernetes.io/docs/</span>


<span class="go">----- omitted lines -----</span>
</pre></div>
</div>
</section>
<section id="task-5-initialize-the-c-plane1-master-node">
<h3>Task 5:  Initialize the c-plane1 (master) node<a class="headerlink" href="#task-5-initialize-the-c-plane1-master-node" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Run <em>kubeadm init</em> command on <em>c-plane1</em> node to initialize control plane.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> ssh c-plane1
<span class="gp">root@c-plane1 $&gt;</span> kubeadm config images pull --kubernetes-version <span class="m">1</span>.29.0
<span class="go">[config/images] Pulled registry.k8s.io/kube-apiserver:v1.29.0</span>
<span class="go">[config/images] Pulled registry.k8s.io/kube-controller-manager:v1.29.0</span>
<span class="go">[config/images] Pulled registry.k8s.io/kube-scheduler:v1.29.0</span>
<span class="go">[config/images] Pulled registry.k8s.io/kube-proxy:v1.29.0</span>
<span class="go">[config/images] Pulled registry.k8s.io/coredns/coredns:v1.11.1</span>
<span class="go">[config/images] Pulled registry.k8s.io/pause:3.9</span>
<span class="go">[config/images] Pulled registry.k8s.io/etcd:3.5.10-0</span>
<span class="gp">root@c-plane1 $&gt;</span> kubeadm init --kubernetes-version <span class="m">1</span>.29.0
<span class="go">[init] Using Kubernetes version: v1.29.0</span>
<span class="go">[preflight] Running pre-flight checks</span>
<span class="go">[preflight] Pulling images required for setting up a Kubernetes cluster</span>
<span class="go">[preflight] This might take a minute or two, depending on the speed of your internet connection</span>
<span class="go">[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;</span>
<span class="go">W0206 10:11:56.371667    3208 checks.go:835] detected that the sandbox image &quot;registry.k8s.io/pause:3.6&quot; of the container runtime is inconsistent with that used by kubeadm. It is recommended that using &quot;registry.k8s.io/pause:3.9&quot; as the CRI sandbox image.</span>
<span class="go">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span>
<span class="go">[certs] Generating &quot;ca&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;apiserver&quot; certificate and key</span>
<span class="go">[certs] apiserver serving cert is signed for DNS names [c-plane1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.10.10.51]</span>
<span class="go">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;etcd/ca&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;etcd/server&quot; certificate and key</span>
<span class="go">[certs] etcd/server serving cert is signed for DNS names [c-plane1 localhost] and IPs [10.10.10.51 127.0.0.1 ::1]</span>
<span class="go">[certs] Generating &quot;etcd/peer&quot; certificate and key</span>
<span class="go">[certs] etcd/peer serving cert is signed for DNS names [c-plane1 localhost] and IPs [10.10.10.51 127.0.0.1 ::1]</span>
<span class="go">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span>
<span class="go">[certs] Generating &quot;sa&quot; key and public key</span>
<span class="go">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span>
<span class="go">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span>
<span class="go">[kubeconfig] Writing &quot;super-admin.conf&quot; kubeconfig file</span>
<span class="go">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span>
<span class="go">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span>
<span class="go">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span>
<span class="go">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span>
<span class="go">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span>
<span class="go">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span>
<span class="go">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span>
<span class="go">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span>
<span class="go">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span>
<span class="go">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span>
<span class="go">[kubelet-start] Starting the kubelet</span>
<span class="go">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span>
<span class="go">[apiclient] All control plane components are healthy after 7.002967 seconds</span>
<span class="go">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span>
<span class="go">[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span>
<span class="go">[upload-certs] Skipping phase. Please see --upload-certs</span>
<span class="go">[mark-control-plane] Marking the node c-plane1 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span>
<span class="go">[mark-control-plane] Marking the node c-plane1 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]</span>
<span class="go">[bootstrap-token] Using token: e2k7l9.3lguvq31pu0e5bvt</span>
<span class="go">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span>
<span class="go">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes</span>
<span class="go">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span>
<span class="go">[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span>
<span class="go">[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span>
<span class="go">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span>
<span class="go">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span>
<span class="go">[addons] Applied essential addon: CoreDNS</span>
<span class="go">[addons] Applied essential addon: kube-proxy</span>

<span class="go">Your Kubernetes control-plane has initialized successfully!</span>

<span class="go">To start using your cluster, you need to run the following as a regular user:</span>

<span class="go">  mkdir -p $HOME/.kube</span>
<span class="go">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span>
<span class="go">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span>

<span class="go">Alternatively, if you are the root user, you can run:</span>

<span class="go">  export KUBECONFIG=/etc/kubernetes/admin.conf</span>

<span class="go">You should now deploy a pod network to the cluster.</span>
<span class="go">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span>
<span class="go">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span>

<span class="go">Then you can join any number of worker nodes by running the following on each as root:</span>

<span class="gs">kubeadm join 10.10.10.51:6443 --token e2k7l9.3lguvq31pu0e5bvt \ </span><span class="go"></span>
<span class="go">      </span><span class="gs">--discovery-token-ca-cert-hash sha256:a59844725c0c6f2232ec4b04e965429cbae7e672c5a6fe8e32d237ba5e0e0990</span><span class="go"></span>
<span class="gp">root@c-plane1 $&gt;</span> mkdir -p <span class="nv">$HOME</span>/.kube
<span class="gp">root@c-plane1 $&gt;</span> cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
<span class="gp">root@c-plane1 $&gt;</span> chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
<span class="gp">root@c-plane1 $&gt;</span> ssh admin-ws <span class="s1">&#39;mkdir -p /root/.kube&#39;</span>
<span class="go">Warning: Permanently added &#39;admin-ws&#39; (ED25519) to the list of known hosts.</span>
<span class="gp">root@c-plane1:~#</span> scp /etc/kubernetes/admin.conf admin-ws:/root/.kube/config
<span class="go">admin.conf                                                         100% 5639     3.4MB/s   00:00</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>At this point the control plane is ready</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get all --namespace<span class="o">=</span>kube-system
<span class="go">NAME                                   READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/coredns-787d4945fb-j2pmj           0/1     Pending   0          66s</span>
<span class="go">pod/coredns-787d4945fb-zs9xn           0/1     Pending   0          66s</span>
<span class="go">pod/etcd-c-plane1                      1/1     Running   0          71s</span>
<span class="go">pod/kube-apiserver-c-plane1            1/1     Running   0          71s</span>
<span class="go">pod/kube-controller-manager-c-plane1   1/1     Running   0          71s</span>
<span class="go">pod/kube-proxy-29vl5                   1/1     Running   0          67s</span>
<span class="go">pod/kube-scheduler-c-plane1            1/1     Running   0          71s</span>

<span class="go">NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span>
<span class="go">service/kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   72s</span>

<span class="go">NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="go">daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   72s</span>

<span class="go">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/coredns   0/2     2            0           72s</span>

<span class="go">NAME                                 DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/coredns-787d4945fb   2         2         0       67s</span>

<span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS     ROLES           AGE   VERSION</span>
<span class="go">c-plane1   </span><span class="gs">NotReady</span><span class="go">   control-plane   85s   v1.29.0</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Install the network add-on</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl apply -f https://docs.projectcalico.org/v3.25/manifests/calico.yaml
<span class="go">poddisruptionbudget.policy/calico-kube-controllers created</span>

<span class="go">----- omitted lines -----</span>

<span class="go">clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/calico-node created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/calico-node created</span>
<span class="go">daemonset.apps/calico-node created</span>
<span class="go">deployment.apps/calico-kube-controllers created</span>
<span class="gp">root@c-plane1 $&gt;</span>
<span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE    VERSION</span>
<span class="go">c-plane1   </span><span class="gs">Ready</span><span class="go">    control-plane   2m8s   v1.29.0</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
</section>
<section id="task-6-join-the-worker-nodes-to-the-cluster">
<h3>Task 6:  Join the worker nodes to the cluster<a class="headerlink" href="#task-6-join-the-worker-nodes-to-the-cluster" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>On each worker node run <em>kubeadm join</em> command copied from end of <em>kubeadm init</em> output.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> ssh worker1
<span class="gp">root@worker1 $&gt; #</span><span class="c1">### USE THE OUPUT OF KUBEADM INIT COMMAND #####</span>
<span class="gp">root@worker1 $&gt;</span> kubeadm join <span class="m">10</span>.10.10.51:6443 --token xxxxxxxxxx <span class="se">\</span>
<span class="gp">&gt;</span>--discovery-token-ca-cert-hash sha256:yyyyyyyyyyy
<span class="go">[preflight] Running pre-flight checks</span>
<span class="go">[preflight] Reading configuration from the cluster...</span>
<span class="go">[preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span class="go">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span>
<span class="go">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span>
<span class="go">[kubelet-start] Starting the kubelet</span>
<span class="go">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span>

<span class="go">This node has joined the cluster:</span>
<span class="go">* Certificate signing request was sent to apiserver and a response was received.</span>
<span class="go">* The Kubelet was informed of the new secure connection details.</span>

<span class="go">Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.</span>

<span class="gp">root@worker1 $&gt;</span> <span class="nb">exit</span>
<span class="go">logout</span>
<span class="go">Connection to worker1 closed.</span>

<span class="gp">root@c-plane1 $</span> kubectl get nodes
<span class="go">NAME       STATUS     ROLES           AGE     VERSION</span>
<span class="go">c-plane1   Ready      control-plane   5m36s   v1.29.0</span>
<span class="go">worker1    NotReady   &lt;none&gt;          11s     v1.29.0</span>

<span class="gp">root@c-plane1 $</span> kubectl get nodes
<span class="go">NAME       STATUS     ROLES           AGE     VERSION</span>
<span class="go">c-plane1   Ready      control-plane   5m36s   v1.29.0</span>
<span class="go">worker1    Ready      &lt;none&gt;          3m56s   v1.29.0</span>

<span class="gp">root@c-plane1 $</span> ssh worker2
<span class="gp">root@worker2 $&gt; #</span><span class="c1">### USE THE OUPUT OF KUBEADM INIT COMMAND #####</span>
<span class="gp">root@worker2 $&gt;</span> kubeadm join <span class="m">10</span>.10.10.51:6443 --token xxxxxxxxxx <span class="se">\</span>
<span class="gp">&gt;</span>--discovery-token-ca-cert-hash sha256:yyyyyyyyyyy
<span class="go">....</span>

<span class="gp">root@worker3 $&gt; #</span><span class="c1">### USE THE OUPUT OF KUBEADM INIT COMMAND #####</span>
<span class="gp">root@worker3 $&gt;</span> kubeadm join <span class="m">10</span>.10.10.51:6443 --token xxxxxxxxxx <span class="se">\</span>
<span class="gp">&gt;</span>--discovery-token-ca-cert-hash sha256:yyyyyyyyyyy
<span class="go">....</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify node version, pods and daemonsets</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS     ROLES           AGE     VERSION</span>
<span class="go">c-plane1   Ready      control-plane   6m51s   v1.29.0</span>
<span class="go">worker1    Ready      &lt;none&gt;          86s     v1.29.0</span>
<span class="go">worker2    Ready      &lt;none&gt;          46s     v1.29.0</span>
<span class="go">worker3    NotReady   &lt;none&gt;          19s     v1.29.0</span>

<span class="gp">root@admin-ws $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE     VERSION</span>
<span class="go">c-plane1   Ready    control-plane   7m34s   </span><span class="gs">v1.29.0</span><span class="go"></span>
<span class="go">worker1    Ready    &lt;none&gt;          2m9s    </span><span class="gs">v1.29.0</span><span class="go"></span>
<span class="go">worker2    Ready    &lt;none&gt;          89s     </span><span class="gs">v1.29.0</span><span class="go"></span>
<span class="go">worker3    Ready    &lt;none&gt;          62s     </span><span class="gs">v1.29.0</span><span class="go"></span>


<span class="gp">root@c-plane1 $&gt;</span> kubectl get -n kube-system pod,ds -o wide

<span class="go">NAME                                          READY   STATUS    RESTARTS   AGE     IP             NODE       NOMINATED NODE   READINESS GATES</span>
<span class="go">pod/calico-kube-controllers-7bdbfc669-f6hm8   1/1     Running   0          6m11s   192.168.13.1   c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/calico-node-6p9kp                         1/1     Running   0          102s    10.10.10.53    worker2    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/calico-node-9p97z                         1/1     Running   0          75s     10.10.10.54    worker3    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/calico-node-l4zwt                         1/1     Running   0          2m22s   10.10.10.52    worker1    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/calico-node-r5lvv                         1/1     Running   0          6m11s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/coredns-787d4945fb-j2pmj                  1/1     Running   0          7m39s   192.168.13.3   c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/coredns-787d4945fb-zs9xn                  1/1     Running   0          7m39s   192.168.13.2   c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/etcd-c-plane1                             1/1     Running   0          7m44s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-apiserver-c-plane1                   1/1     Running   0          7m44s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-controller-manager-c-plane1          1/1     Running   0          7m44s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-proxy-29vl5                          1/1     Running   0          7m40s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-proxy-f4m9n                          1/1     Running   0          102s    10.10.10.53    worker2    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-proxy-lc5sr                          1/1     Running   0          2m22s   10.10.10.52    worker1    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-proxy-whsqh                          1/1     Running   0          75s     10.10.10.54    worker3    &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pod/kube-scheduler-c-plane1                   1/1     Running   0          7m44s   10.10.10.51    c-plane1   &lt;none&gt;           &lt;none&gt;</span>

<span class="go">NAME                         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE     CONTAINERS    IMAGES                               SELECTOR</span>
<span class="go">daemonset.apps/calico-node   4         4         4       4            4           kubernetes.io/os=linux   6m11s   calico-node   docker.io/calico/node:v3.25.0        k8s-app=calico-node</span>
<span class="go">daemonset.apps/kube-proxy    4         4         4       4            4           kubernetes.io/os=linux   7m45s   kube-proxy    registry.k8s.io/kube-proxy:v1.29.0   k8s-app=kube-proxy</span>
</pre></div>
</div>
</section>
<section id="task-7-install-dashboard">
<h3>Task 7:  Install dashboard<a class="headerlink" href="#task-7-install-dashboard" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Install <em>kubernetes-dashboard</em>, and check it.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
<span class="go">namespace/kubernetes-dashboard created</span>
<span class="go">serviceaccount/kubernetes-dashboard created</span>
<span class="go">service/kubernetes-dashboard created</span>
<span class="go">secret/kubernetes-dashboard-certs created</span>
<span class="go">secret/kubernetes-dashboard-csrf created</span>
<span class="go">secret/kubernetes-dashboard-key-holder created</span>
<span class="go">configmap/kubernetes-dashboard-settings created</span>
<span class="go">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span>
<span class="go">deployment.apps/kubernetes-dashboard created</span>
<span class="go">service/dashboard-metrics-scraper created</span>
<span class="go">deployment.apps/dashboard-metrics-scraper created</span>
<span class="gp">root@c-plane1 $&gt;</span>

<span class="gp">root@c-plane1 $&gt;</span> kubectl get -n kubernetes-dashboard all
<span class="go">NAME                                            READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/dashboard-metrics-scraper-7bc864c59-l6b88   1/1     Running   0          15s</span>
<span class="go">pod/kubernetes-dashboard-6c7ccbcf87-fshkp       1/1     Running   0          15s</span>

<span class="go">NAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE</span>
<span class="go">service/dashboard-metrics-scraper   ClusterIP   10.109.162.13    &lt;none&gt;        8000/TCP   15s</span>
<span class="go">service/kubernetes-dashboard        ClusterIP   10.107.239.167   &lt;none&gt;        443/TCP    15s</span>

<span class="go">NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="go">deployment.apps/dashboard-metrics-scraper   1/1     1            1           15s</span>
<span class="go">deployment.apps/kubernetes-dashboard        1/1     1            1           15s</span>

<span class="go">NAME                                                  DESIRED   CURRENT   READY   AGE</span>
<span class="go">replicaset.apps/dashboard-metrics-scraper-7bc864c59   1         1         1       15s</span>
<span class="go">replicaset.apps/kubernetes-dashboard-6c7ccbcf87       1         1         1       15s</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
</section>
<section id="task-8-preparing-system-for-upgrade">
<h3>Task 8:  Preparing system for upgrade<a class="headerlink" href="#task-8-preparing-system-for-upgrade" title="Permalink to this headline"></a></h3>
<p>Before start upgrade, you have to restore your nodes to initially installed state.</p>
<ul class="simple">
<li><p>Restore nodes by <cite>os_nodes</cite> script.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes restore_nodes
<span class="go">Domain c-plane1 destroyed</span>

<span class="go">Domain worker1 destroyed</span>

<span class="go">Domain worker2 destroyed</span>

<span class="go">Domain worker3 destroyed</span>

<span class="go">Domain service destroyed</span>

<span class="go">Domain admin-ws destroyed</span>

<span class="go">Domain c-plane1 started</span>

<span class="go">Domain worker1 started</span>

<span class="go">Domain worker2 started</span>

<span class="go">Domain worker3 started</span>

<span class="go">Domain service started</span>

<span class="go">Domain admin-ws started</span>

<span class="go">Waiting for nodes c-plane1  worker1 worker2 worker3 service admin-ws ...</span>
<span class="go">Node c-plane1 ready.</span>
<span class="go">Node worker1 ready.</span>
<span class="go">Node worker2 ready.</span>
<span class="go">Node worker3 ready.</span>
<span class="go">service is not a kubernetes node, skipping...</span>
<span class="go">admin-ws is not a kubernetes node, skipping...</span>
<span class="go">Nodes booted up in 61 seconds.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Wait a few seconds, and verify whether nodes are in running state</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes status
<span class="gs">c-plane1 running</span><span class="go"></span>
<span class="gs">worker1 running</span><span class="go"></span>
<span class="gs">worker2 running</span><span class="go"></span>
<span class="gs">worker3 running</span><span class="go"></span>
<span class="gs">service  running</span><span class="go"></span>
<span class="gs">admin-ws running</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check current cluster version and grab ssh keys from worker nodes on <em>c-plane1</em> node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> ssh c-plane1
<span class="gp">root@c-plane1 $&gt;</span> kubectl get node
<span class="go">NAME       STATUS   ROLES           AGE    VERSION</span>
<span class="go">c-plane1   Ready    control-plane   126d   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          126d   v1.29.0</span>

<span class="gp">root@c-plane1 $&gt;</span> <span class="k">for</span> i <span class="k">in</span> worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> ssh <span class="nv">$i</span> hostname <span class="p">;</span> <span class="k">done</span>
<span class="go">worker1</span>
<span class="go">worker2</span>
<span class="go">worker3</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
</section>
<section id="task-9-search-for-and-select-a-newer-version">
<h3>Task 9:  Search for and select a newer version<a class="headerlink" href="#task-9-search-for-and-select-a-newer-version" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Refresh the repository and check available packages.</p>
<p>Choose a <em>kubeadm</em> version, which complies the upgrade crtiteria. This says that <em>kubeadm</em> can upgrade to the next patch level or next minor version and patch level only, otherwise you should upgrade each component manually.</p>
</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you would like to upgrade to different <em>minor</em> release, you must add an extra repository url to apt source list file or change the url to point to new version.</p>
<ul class="simple">
<li><p>Check your kubernetes source list file on <em>c-plane1</em> node.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> cat /etc/apt/sources.list.d/kubernetes.list
<span class="go">deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="gs">1.29</span><span class="go">/deb/ /</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Add a new line to file, check it and copy the file into worker nodes.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> <span class="nb">echo</span> <span class="s1">&#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="gs">1.30</span><span class="s1">/deb/ /&#39;</span> &gt;&gt; /etc/apt/sources.list.d/kubernetes.list
<span class="gp">root@c-plane1 $&gt;</span> cat /etc/apt/sources.list.d/kubernetes.list
<span class="go">deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /</span>
<span class="go">deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /</span>
<span class="gp">root@c-plane1 $&gt;</span> <span class="k">for</span> i <span class="k">in</span> worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> scp /etc/apt/sources.list.d/kubernetes.list <span class="si">${</span><span class="nv">i</span><span class="si">}</span>:/etc/apt/sources.list.d/kubernetes.list<span class="p">;</span><span class="k">done</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt update
<span class="go">---- output omitted ----</span>
<span class="gp">root@c-plane1 $&gt;</span> apt list -a kubeadm <span class="p">|</span> grep amd64<span class="p">|</span>head

<span class="go">WARNING: apt does not have a stable CLI interface. Use with caution in scripts.</span>

<span class="gs">kubeadm/unknown 1.30.0-1.1 amd64 [upgradable from: 1.29.0-1.1]</span><span class="go"></span>
<span class="go">kubeadm/unknown 1.29.4-2.1 amd64</span>
<span class="go">kubeadm/unknown 1.29.3-1.1 amd64</span>
<span class="go">kubeadm/unknown 1.29.2-1.1 amd64</span>
<span class="go">kubeadm/unknown 1.29.1-1.1 amd64</span>
<span class="gs">kubeadm/unknown,now 1.29.0-1.1 amd64 [installed,upgradable to: 1.30.0-1.1]</span><span class="go"></span>
</pre></div>
</div>
<blockquote>
<div><p>Check <em>kubelet</em> and <em>kubectl</em> also</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt list -a kubelet <span class="p">|</span> grep amd64<span class="p">|</span>head

<span class="go">WARNING: apt does not have a stable CLI interface. Use with caution in scripts.</span>

<span class="gs">kubelet/unknown 1.30.0-1.1 amd64 [upgradable from: 1.29.0-1.1]</span><span class="go"></span>
<span class="go">kubelet/unknown 1.29.4-2.1 amd64</span>
<span class="go">kubelet/unknown 1.29.3-1.1 amd64</span>
<span class="go">kubelet/unknown 1.29.2-1.1 amd64</span>
<span class="go">kubelet/unknown 1.29.1-1.1 amd64</span>
<span class="gs">kubelet/unknown,now 1.29.0-1.1 amd64 [installed,upgradable to: 1.30.0-1.1]</span><span class="go"></span>

<span class="gp">root@c-plane1 $&gt;</span> apt list -a kubectl <span class="p">|</span> grep amd64<span class="p">|</span>head

<span class="go">WARNING: apt does not have a stable CLI interface. Use with caution in scripts.</span>

<span class="gs">kubectl/unknown 1.30.0-1.1 amd64 [upgradable from: 1.29.0-1.1]</span><span class="go"></span>
<span class="go">kubectl/unknown 1.29.4-2.1 amd64</span>
<span class="go">kubectl/unknown 1.29.3-1.1 amd64</span>
<span class="go">kubectl/unknown 1.29.2-1.1 amd64</span>
<span class="go">kubectl/unknown 1.29.1-1.1 amd64</span>
<span class="gs">kubectl/unknown,now 1.29.0-1.1 amd64 [installed,upgradable to: 1.30.0-1.1]</span><span class="go"></span>
</pre></div>
</div>
</section>
<section id="task-10-upgrade-the-c-plane1-master-node">
<h3>Task 10:  Upgrade the c-plane1 (master) node<a class="headerlink" href="#task-10-upgrade-the-c-plane1-master-node" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Upgrade kubeadm</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt install --allow-change-held-packages -y <span class="nv">kubeadm</span><span class="o">=</span><span class="m">1</span>.30.0-1.1
<span class="go">----- omitted lines -----</span>
<span class="go">Setting up kubeadm (1.30.0-1.1) ...</span>
</pre></div>
</div>
<ul>
<li><p>Check upgrade plan</p>
<p>This command checks that your cluster can be upgraded, and fetches the versions you can upgrade to. It also shows a table with the component config version states. Double check whether no manual steps listed</p>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubeadm upgrade plan
<span class="go">[upgrade/config] Making sure the configuration is correct:</span>
<span class="go">[preflight] Running pre-flight checks.</span>
<span class="go">[upgrade/config] Reading configuration from the cluster...</span>
<span class="go">[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span class="go">[upgrade] Running cluster health checks</span>
<span class="go">[upgrade] Fetching available versions to upgrade to</span>
<span class="go">[upgrade/versions] Cluster version: 1.29.0</span>
<span class="go">[upgrade/versions] kubeadm version: v1.30.0</span>
<span class="go">[upgrade/versions] Target version: v1.30.0</span>
<span class="go">[upgrade/versions] Latest version in the v1.29 series: v1.29.4</span>

<span class="go">Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:</span>
<span class="go">COMPONENT   NODE       CURRENT   TARGET</span>
<span class="go">kubelet     c-plane1   v1.29.0   v1.29.4</span>
<span class="go">kubelet     worker1    v1.29.0   v1.29.4</span>
<span class="go">kubelet     worker2    v1.29.0   v1.29.4</span>
<span class="go">kubelet     worker3    v1.29.0   v1.29.4</span>

<span class="go">Upgrade to the latest version in the v1.29 series:</span>

<span class="go">COMPONENT                 NODE       CURRENT    TARGET</span>
<span class="go">kube-apiserver            c-plane1   v1.29.0    v1.29.4</span>
<span class="go">kube-controller-manager   c-plane1   v1.29.0    v1.29.4</span>
<span class="go">kube-scheduler            c-plane1   v1.29.0    v1.29.4</span>
<span class="go">kube-proxy                           1.29.0     v1.29.4</span>
<span class="go">CoreDNS                              v1.11.1    v1.11.1</span>
<span class="go">etcd                      c-plane1   3.5.10-0   3.5.12-0</span>

<span class="go">You can now apply the upgrade by executing the following command:</span>

<span class="go">      kubeadm upgrade apply v1.29.4</span>

<span class="go">_____________________________________________________________________</span>

<span class="go">Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:</span>
<span class="go">COMPONENT   NODE       CURRENT   TARGET</span>
<span class="go">kubelet     c-plane1   v1.29.0   v1.30.0</span>
<span class="go">kubelet     worker1    v1.29.0   v1.30.0</span>
<span class="go">kubelet     worker2    v1.29.0   v1.30.0</span>
<span class="go">kubelet     worker3    v1.29.0   v1.30.0</span>

<span class="go">Upgrade to the latest stable version:</span>

<span class="go">COMPONENT                 NODE       CURRENT    TARGET</span>
<span class="go">kube-apiserver            c-plane1   v1.29.0    v1.30.0</span>
<span class="go">kube-controller-manager   c-plane1   v1.29.0    v1.30.0</span>
<span class="go">kube-scheduler            c-plane1   v1.29.0    v1.30.0</span>
<span class="go">kube-proxy                           1.29.0     v1.30.0</span>
<span class="go">CoreDNS                              v1.11.1    v1.11.1</span>
<span class="go">etcd                      c-plane1   3.5.10-0   3.5.12-0</span>

<span class="go">You can now apply the upgrade by executing the following command:</span>

<span class="go">      </span><span class="gs">kubeadm upgrade apply v1.30.0</span><span class="go"></span>

<span class="go">_____________________________________________________________________</span>


<span class="go">The table below shows the current state of component configs as understood by this version of kubeadm.</span>
<span class="go">Configs that have a &quot;yes&quot; mark in the &quot;MANUAL UPGRADE REQUIRED&quot; column require manual config upgrade or</span>
<span class="go">resetting to kubeadm defaults before a successful upgrade can be performed. The version to manually</span>
<span class="go">upgrade to is denoted in the &quot;PREFERRED VERSION&quot; column.</span>

<span class="go">API GROUP                 CURRENT VERSION   PREFERRED VERSION   MANUAL UPGRADE REQUIRED</span>
<span class="go">kubeproxy.config.k8s.io   v1alpha1          v1alpha1            no</span>
<span class="go">kubelet.config.k8s.io     v1beta1           v1beta1             no</span>
<span class="go">_____________________________________________________________________</span>
</pre></div>
</div>
<ul>
<li><p>Choose and apply a suitable apply plan</p>
<p><em>kubeadm upgrade</em> also automatically renews the certificates that it manages on this node.</p>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubeadm upgrade apply --yes <span class="gs">v1.30.0</span>

<span class="go">----- omitted lines -----</span>

<span class="go">[addons] Applied essential addon: CoreDNS</span>
<span class="go">[addons] Applied essential addon: kube-proxy</span>

<span class="go">[upgrade/successful] </span><span class="gs">SUCCESS! Your cluster was upgraded to &quot;v1.30.0&quot;. Enjoy!</span><span class="go"></span>

<span class="go">[upgrade/kubelet] Now that your control plane is upgraded, &gt;&gt;</span>
<span class="go">         </span><span class="gs">please proceed with upgrading your kubelets</span><span class="go"> if you haven&#39;t already done so.</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul>
<li><p>Upgrade CNI (Conatiner Network Interface) addon if necessary.</p>
<p>Check the <a class="reference external" href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">addons</a> page to find your CNI provider and see whether additional upgrade steps are required.</p>
</li>
<li><p>Drain the node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl drain c-plane1 --ignore-daemonsets
<span class="go">node/c-plane1 cordoned</span>
<span class="go">Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-vcdnr, kube-system/kube-proxy-cncq5</span>
<span class="go">evicting pod kube-system/calico-kube-controllers-798cc86c47-zpwpv</span>
<span class="go">pod/calico-kube-controllers-798cc86c47-zpwpv evicted</span>
<span class="go">node/c-plane1 drained</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Upgrade kubectl and kubelet</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>During the installation you get a service restart window. Please deselect kubelet service
You can move with TAB, arrow keys, and deselect with the Space key</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt install -y --allow-change-held-packages <span class="nv">kubelet</span><span class="o">=</span><span class="m">1</span>.30.0-1.1 <span class="nv">kubectl</span><span class="o">=</span><span class="m">1</span>.30.0-1.1
<span class="go">----- omitted lines -----</span>
<span class="go">Setting up kubectl (1.30.0-1.1) ...</span>
<span class="go">Setting up kubelet (1.30.0-1.1) ..</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Restart kubelet</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> systemctl daemon-reload
<span class="gp">root@c-plane1 $&gt;</span> systemctl restart kubelet
</pre></div>
</div>
<ul class="simple">
<li><p>Uncordon master node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl uncordon c-plane1
<span class="go">node/c-plane1 uncordoned</span>
</pre></div>
</div>
<ul>
<li><p>Check the node</p>
<p>After one minute the cluster finishes transients and <em>c-plane1</em> node runs the new version.</p>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker1    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
</section>
<section id="task-11-upgrade-worker-nodes">
<h3>Task 11:  Upgrade worker nodes<a class="headerlink" href="#task-11-upgrade-worker-nodes" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Upgrade kubeadm</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1 $&gt;</span> apt update <span class="p">;</span> apt install -y --allow-change-held-packages <span class="nv">kubeadm</span><span class="o">=</span><span class="m">1</span>.30.0-1.1
<span class="go">----- omitted lines -----</span>
<span class="go">Unpacking kubeadm (1.30.0-1.1) over (1.29.0-1.1) ...</span>
<span class="go">Setting up kubeadm (1.30.0-1.1) ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Apply node upgrade</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1 $&gt;</span> kubeadm upgrade node
<span class="go">[upgrade] Reading configuration from the cluster...</span>
<span class="go">[upgrade] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span class="go">[preflight] Running pre-flight checks</span>
<span class="go">[preflight] Skipping prepull. Not a control plane node.</span>
<span class="go">[upgrade] Skipping phase. Not a control plane node.</span>
<span class="go">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span>
<span class="go">[upgrade] The configuration for this node was successfully updated!</span>
<span class="go">[upgrade] Now you should go ahead and upgrade the kubelet package using your package manager.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Drain worker node from the <strong>c-plane1</strong> node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl drain worker1 --ignore-daemonsets --delete-emptydir-data<span class="o">=</span><span class="nb">true</span>
<span class="gs">node/worker1 cordoned</span><span class="go"></span>
<span class="go">Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-zfnrz, kube-system/kube-proxy-rf52m</span>
<span class="go">evicting pod kubernetes-dashboard/kubernetes-dashboard-5c8bd6b59-6gl9k</span>
<span class="go">pod/kubernetes-dashboard-5c8bd6b59-6gl9k evicted</span>
<span class="gs">node/worker1 drained</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Upgrade kubelet</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> ssh worker1
<span class="gp">root@worker1 $&gt;</span> apt install -y --allow-change-held-packages <span class="nv">kubelet</span><span class="o">=</span><span class="m">1</span>.30.0-1.1 <span class="nv">kubectl</span><span class="o">=</span><span class="m">1</span>.30.0-1.1
<span class="go">----- omitted lines -----</span>
<span class="go">Setting up kubectl (1.30.0-1.1) ...</span>
<span class="go">Setting up kubelet (1.30.0-1.1) ...</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Restart kubelet</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@worker1 $&gt;</span> systemctl daemon-reload
<span class="gp">root@worker1 $&gt;</span> systemctl restart kubelet
</pre></div>
</div>
<ul class="simple">
<li><p>Uncordon worker node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl uncordon worker1
<span class="go">node/worker1 uncordoned</span>
</pre></div>
</div>
<blockquote>
<div><p>After one minute the cluster finishes transients and <em>worker</em> node runs the new version.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker1    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker2    Ready    &lt;none&gt;          126d   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          126d   v1.29.0</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Repeat this task for</strong> <code class="docutils literal notranslate"><span class="pre">worker2</span></code> <strong>and</strong> <code class="docutils literal notranslate"><span class="pre">worker3</span></code> <strong>nodes</strong></p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> ssh worker2

<span class="go">... omitted lines ...</span>

<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul>
<li><p>Verify the status of the upgraded cluster</p>
<p>After upgrading <strong>all the worker nodes</strong> you should check the state of the cluster.</p>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> kubectl get nodes
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker1    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker2    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker3    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<blockquote>
<div><p>If you have any problems with the upgrade exercise… Please, repeat <em>“Preparing system for upgrade”</em> task and run <em>kbs-upgrade.sh</em></p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> /labfiles/k8s/Install_and_upgrade/kbs-upgrade.sh <span class="m">1</span>.30.0
<span class="go">----- omitted lines -----</span>
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker1    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker2    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
<span class="go">worker3    Ready    &lt;none&gt;          126d   </span><span class="gs">v1.30.0</span><span class="go"></span>
</pre></div>
</div>
</div>
</section>
<section id="task-12-clean-up">
<h3>Task 12:  Clean up<a class="headerlink" href="#task-12-clean-up" title="Permalink to this headline"></a></h3>
<p>Before continuing the course, you have to restore your nodes to initially installed state. That state is supposed to have in lab exercises.</p>
<ul class="simple">
<li><p>Restore nodes by <cite>os_nodes</cite> script.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes restore_nodes
<span class="go">Domain c-plane1 destroyed</span>

<span class="go">Domain worker1 destroyed</span>

<span class="go">Domain worker2 destroyed</span>

<span class="go">Domain worker3 destroyed</span>

<span class="go">Domain service destroyed</span>

<span class="go">Domain admin-ws destroyed</span>

<span class="go">Domain c-plane1 started</span>

<span class="go">Domain worker1 started</span>

<span class="go">Domain worker2 started</span>

<span class="go">Domain worker3 started</span>

<span class="go">Domain service started</span>

<span class="go">Domain admin-ws started</span>

<span class="go">Waiting for nodes c-plane1  worker1 worker2 worker3 service admin-ws ...</span>
<span class="go">Node c-plane1 ready.</span>
<span class="go">Node worker1 ready.</span>
<span class="go">Node worker2 ready.</span>
<span class="go">Node worker3 ready.</span>
<span class="go">service is not a kubernetes node, skipping...</span>
<span class="go">admin-ws is not a kubernetes node, skipping...</span>
<span class="go">Nodes booted up in 54 seconds.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Wait a few seconds, and verify whether nodes are in running state</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> os_nodes status
<span class="gs">c-plane1 running</span><span class="go"></span>
<span class="gs">worker1 running</span><span class="go"></span>
<span class="gs">worker2 running</span><span class="go"></span>
<span class="gs">worker3 running</span><span class="go"></span>
<span class="gs">service  running</span><span class="go"></span>
<span class="gs">admin-ws   running</span><span class="go"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check current cluster version and grab ssh keys from worker nodes on <em>c-plane1</em> node</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@lab_machine $&gt;</span> ssh c-plane1
<span class="gp">root@c-plane1 $&gt;</span> kubectl get node
<span class="go">NAME       STATUS   ROLES           AGE   VERSION</span>
<span class="go">c-plane1   Ready    control-plane   14d   v1.29.0</span>
<span class="go">worker1    Ready    &lt;none&gt;          14d   v1.29.0</span>
<span class="go">worker2    Ready    &lt;none&gt;          14d   v1.29.0</span>
<span class="go">worker3    Ready    &lt;none&gt;          14d   v1.29.0</span>

<span class="gp">root@c-plane1 $&gt;</span> <span class="k">for</span> i <span class="k">in</span> worker<span class="o">{</span><span class="m">1</span>..3<span class="o">}</span><span class="p">;</span> <span class="k">do</span> ssh <span class="nv">$i</span> hostname <span class="p">;</span> <span class="k">done</span>
<span class="go">worker1</span>
<span class="go">worker2</span>
<span class="go">worker3</span>
<span class="gp">root@c-plane1 $&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Update your credentials on admin-ws</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> scp c-plane1:/etc/kubernetes/admin.conf /root/.kube/config
<span class="go">admin.conf                                                   100% 5635     7.4MB/s   00:00</span>
<span class="gp">root@admin-ws $&gt;</span>
</pre></div>
</div>
</section>
</section>
<section id="lab-10-final-all-in-one-lab">
<h2>Lab 10:  Final all-in-one lab<a class="headerlink" href="#lab-10-final-all-in-one-lab" title="Permalink to this headline"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please make sure that you have performed the cleanup from the previous lab before you would start this one.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>A possible solution of the following lab tasks is located in next chapter <em>Solutions 11</em>.</p>
</div>
<p>In this lab you should use all the concepts discussed throughout the training and run an application that will be reachable to external clients. The application will list the course catalog of a training company.</p>
<p>The starting point provides:</p>
<blockquote>
<div><ul class="simple">
<li><p>A vanilla Kubernetes cluster accessible from the <code class="docutils literal notranslate"><span class="pre">admin-ws</span></code> machine</p></li>
<li><p>A smb storage system being available on the <code class="docutils literal notranslate"><span class="pre">service</span></code> machine that can be accessed using the username: <em>student</em> and the password: <em>student123</em></p></li>
<li><p>A range of IP addresses that can be used to expose services towards the clients outside the cluster: 10.10.10.110-10.10.10.120</p></li>
<li><p>The application code written in Python which is found in the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Final_all-in-one/myapp/</span></code> directory.</p></li>
</ul>
</div></blockquote>
<section id="task-1-prepare-the-cluster">
<h3>Task 1:  Prepare the cluster<a class="headerlink" href="#task-1-prepare-the-cluster" title="Permalink to this headline"></a></h3>
<p>In this task you are required to prepare the environment that can support the other tasks in this lab.</p>
<ul class="simple">
<li><p>Deploy the <em>smb CSI  driver</em> and and the storageclass.</p></li>
<li><p>Deploy the <em>metallb</em> load-balancer and the <em>ingress-controller</em>.</p></li>
<li><p>Create a <em>namespace</em> called <em>my-ns</em>, and a <em>ServiceAccount</em> <em>app-admin</em> in it.</p></li>
<li><p>Create role named <em>app-admin</em> to enable the management of all resources in <em>my-ns</em> namespace.</p></li>
<li><p>Authorize the <em>app-admin</em> service account to manage all resources inside of <em>my-ns</em> and to view all resources in the cluster.</p></li>
<li><p>Create a <em>kubectl</em> client config file, which provides ability to connect to the cluster as <em>app-admin</em> in <em>my-ns</em> namespace.</p></li>
</ul>
</section>
<section id="task-2-building-the-docker-image">
<h3>Task 2:  Building the docker image<a class="headerlink" href="#task-2-building-the-docker-image" title="Permalink to this headline"></a></h3>
<p>In this task you need to build the container image of <em>myapp</em> and push it into the private registry.</p>
<ul class="simple">
<li><p>Build the container image from the application located in <em>/labfiles/k8s/Final_all-in-one/myapp/</em>.</p></li>
<li><p>Push the image into the private registry.</p></li>
</ul>
<p>The registry information are:</p>
<blockquote>
<div><p>registry server:          <a class="reference external" href="service:5000">service:5000</a></p>
<p>user name:                student</p>
<p>password:                 student123</p>
</div></blockquote>
</section>
<section id="task-3-creating-the-deployment">
<h3>Task 3:  Creating the deployment<a class="headerlink" href="#task-3-creating-the-deployment" title="Permalink to this headline"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Reference the client config file in your <em>.bashrc</em> so you will use correct context in next lab exercises.</p>
</div>
<p>Now everything is available in your system to create the Kubernetes resources.</p>
<ul>
<li><p>First, create a secret resource so the kubernetes can use a private registry.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can create it on <strong>admin-ws</strong> from the <em>/root/.docker/config.json</em> file or using raw data.</p>
</div>
</li>
</ul>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can check every phases of your deployment with the <strong>links</strong> browser from any node of cluster. The links brower is not installed on your system, you can install it with <em>apt</em> utility.</p>
</div>
<ul>
<li><p>Create a simple deployment exposed by a ClusterIP service using the container image created in the previous task.</p>
<ul class="simple">
<li><p>For security reason set user to <em>1001</em>, because the Dockerfile did not specify it.</p></li>
</ul>
</li>
<li><p>Add <em>liveness</em> and <em>readiness</em> probes to the deployment to ensure the control of running container.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Probe on the <strong>8080/TCP</strong> port</p>
</div>
</li>
<li><p>Modify your deployment so that you can set the web page type using the DATA_FILE environment variable.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>See source code of <em>myapp</em> in <em>/labfiles/k8s/Final_all-in-one/myapp/</em> directory</p>
<p>The possible values of <em>DATA_FILE</em> variable are: <strong>/course_data/course.csv</strong> or <strong>/course_data/course2.csv</strong></p>
</div>
</li>
<li><p>Create a <em>configmap</em> from course csv files and configure your deployment to use this configmap as <em>volume</em>.</p>
<blockquote>
<div><p>These files are located in <em>/labfiles/k8s/Final_all-in-one/myapp/course_data</em> directory.</p>
</div></blockquote>
</li>
</ul>
</section>
<section id="task-4-expose-your-deployment-using-a-load-balancer-and-ingress">
<h3>Task 4:  Expose your deployment using a <em>load-balancer</em> and <em>Ingress</em><a class="headerlink" href="#task-4-expose-your-deployment-using-a-load-balancer-and-ingress" title="Permalink to this headline"></a></h3>
<p>In this lab you need to configure external access to <em>myapp</em> webpage using <em>ingress</em> and <em>load-balancer</em>.</p>
<ul class="simple">
<li><p>Check the load-balancer’s <strong>external IP address</strong>.</p></li>
<li><p>Configure an <em>ingress</em> resource points to your deployment’s <em>clusterIP</em> using <em>nip.io</em> wildcard DNS for <em>host</em> parameter.</p></li>
<li><p>Check your webpage from outside of cluster.</p></li>
</ul>
</section>
<section id="task-5-configure-network-policy">
<h3>Task 5:  Configure network policy<a class="headerlink" href="#task-5-configure-network-policy" title="Permalink to this headline"></a></h3>
<p>Your application is accessible from outside. Now you need to think about the security. Network policies allows us to restrict what traffic is permitted for a pod.</p>
<ul>
<li><p>Configure network policy in order to restrict access to <em>myapp</em> pod from <em>ingress controller pod</em> only.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Optionally you can restrict the outbound traffic as well.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Because the ingress controller running inside of another namespace, you can use <em>namespace selector</em> too.</p>
</div>
</li>
<li><p>Test your configuration. Try to access your <em>application pod</em> from a pod other than the <em>ingress controller</em> pod.</p></li>
</ul>
</section>
<section id="task-6-using-pvc">
<h3>Task 6:  Using PVC<a class="headerlink" href="#task-6-using-pvc" title="Permalink to this headline"></a></h3>
<p>The content of your web page is rather static, and it’s hard to change the content because the source csv files are stored in a configmap, which is read-only in the pod. You need to use PVC where the files are read-write accessible. When the pod is started, the contents of the configmap must be copied to the PV to provide the initial contents.</p>
<ul class="simple">
<li><p>Create a <em>PVC</em> using <em>smb</em> storage class created at Task 1.</p></li>
<li><p>Modify your deployment to use files on a <em>PV</em> and create an <em>initcontainer</em> to copy files from the <em>configmap</em> to the <em>PV</em>.</p></li>
</ul>
</section>
</section>
<section id="solutions-1-final-all-in-one-lab-solutions">
<h2>Solutions 1:  Final all-in-one lab solutions<a class="headerlink" href="#solutions-1-final-all-in-one-lab-solutions" title="Permalink to this headline"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please make sure that you have performed the cleanup from the previous lab before you would start this one.</p>
</div>
<p>In this lab you should use all the concepts discussed throughout the training and run an application that will be reachable to external clients. The application will list the course catalog of a training company.</p>
<p>The starting point provides:</p>
<blockquote>
<div><ul class="simple">
<li><p>A vanilla Kubernetes cluster accessible from the <code class="docutils literal notranslate"><span class="pre">admin-ws</span></code> machine</p></li>
<li><p>A smb storage system being available on the <code class="docutils literal notranslate"><span class="pre">service</span></code> machine</p></li>
<li><p>A range of IP addresses that can be used to expose services towards the clients outside the cluster: 10.10.10.110-10.10.10.120</p></li>
<li><p>The application code written in Python which is found in the <code class="docutils literal notranslate"><span class="pre">/labfiles/k8s/Final_all-in-one/myapp/</span></code> directory.</p></li>
</ul>
</div></blockquote>
<section id="id2">
<h3>Task 1:  Prepare the cluster<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>In this task you are required to prepare the environment that can support the other tasks in this lab.</p>
<ul class="simple">
<li><p>Deploy the <em>smb CSI  driver</em> and the storageclass.</p></li>
<li><p>Deploy the <em>metallb</em> load-balancer and the <em>ingress-controller</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/csi-driver-smb.yaml
<span class="go">serviceaccount/csi-smb-controller-sa created</span>
<span class="go">serviceaccount/csi-smb-node-sa created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/smb-external-provisioner-role created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/smb-csi-provisioner-binding created</span>
<span class="go">daemonset.apps/csi-smb-node created</span>
<span class="go">deployment.apps/csi-smb-controller created</span>
<span class="go">csidriver.storage.k8s.io/smb.csi.k8s.io created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get po -n kube-system -l app.kubernetes.io/name<span class="o">=</span>csi-driver-smb
<span class="go">NAME                                  READY   STATUS    RESTARTS   AGE</span>
<span class="go">csi-smb-controller-6dbcb8dbc8-4pmlm   3/3     Running   0          118s</span>
<span class="go">csi-smb-node-2tb8j                    3/3     Running   0          117s</span>
<span class="go">csi-smb-node-7bm9v                    3/3     Running   0          117s</span>
<span class="go">csi-smb-node-j86gs                    3/3     Running   0          117s</span>
<span class="go">csi-smb-node-qtdtf                    3/3     Running   0          118s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/smbcred.yaml
<span class="go">secret/smbcred created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Persistent_storage/smb-storage-class.yml
<span class="go">storageclass.storage.k8s.io/smb created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get storageclass
<span class="go">NAME   PROVISIONER      RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span>
<span class="go">smb    smb.csi.k8s.io   Delete          Immediate           false                  22s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Accessing_applications/metallb-native.yaml
<span class="go">namespace/metallb-system created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/addresspools.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created</span>
<span class="go">serviceaccount/controller created</span>
<span class="go">serviceaccount/speaker created</span>
<span class="go">role.rbac.authorization.k8s.io/controller created</span>
<span class="go">role.rbac.authorization.k8s.io/pod-lister created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/metallb-system:controller created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/controller created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/pod-lister created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created</span>
<span class="go">secret/webhook-server-cert created</span>
<span class="go">service/webhook-service created</span>
<span class="go">deployment.apps/controller created</span>
<span class="go">daemonset.apps/speaker created</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get po -n metallb-system
<span class="go">NAME                          READY   STATUS    RESTARTS   AGE</span>
<span class="go">controller-68bf958bf9-nxwfj   1/1     Running   0          32s</span>
<span class="go">speaker-9mxz8                 1/1     Running   0          32s</span>
<span class="go">speaker-bg28q                 1/1     Running   0          32s</span>
<span class="go">speaker-hbb6b                 1/1     Running   0          32s</span>
<span class="go">speaker-qqgjg                 1/1     Running   0          32s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Accessing_applications/metallb-address-pool.yaml
<span class="go">ipaddresspool.metallb.io/first-pool created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Accessing_applications/metallb-advertise.yaml
<span class="go">l2advertisement.metallb.io/example created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl apply -f /labfiles/k8s/Accessing_applications/ingress-controller.yaml
<span class="go">namespace/ingress-nginx created</span>
<span class="go">serviceaccount/ingress-nginx created</span>
<span class="go">serviceaccount/ingress-nginx-admission created</span>
<span class="go">role.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">role.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span>
<span class="go">configmap/ingress-nginx-controller created</span>
<span class="go">service/ingress-nginx-controller created</span>
<span class="go">service/ingress-nginx-controller-admission created</span>
<span class="go">deployment.apps/ingress-nginx-controller created</span>
<span class="go">job.batch/ingress-nginx-admission-create created</span>
<span class="go">job.batch/ingress-nginx-admission-patch created</span>
<span class="gs">ingressclass.networking.k8s.io/nginx</span><span class="go"> created</span>
<span class="go">validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n ingress-nginx
<span class="go">NAME                                        READY   STATUS      RESTARTS   AGE</span>
<span class="go">ingress-nginx-admission-create-c4zfs        0/1     Completed   0          45s</span>
<span class="go">ingress-nginx-admission-patch-dp5qg         0/1     Completed   0          45s</span>
<span class="go">ingress-nginx-controller-79f766df89-ldp46   1/1     Running     0          45s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a namespace <em>my-ns</em> and create a <em>ServiceAccount</em> <em>app-admin</em> in it.</p></li>
<li><p>Create a role named <em>app-admin</em> to enable the managementof all resources in the <em>my-ns</em> namespace.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create namespace my-ns
<span class="go">namespace/my-ns created</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id9">
<div class="code-block-caption"><span class="caption-text">serviceaccount.yml</span><a class="headerlink" href="#id9" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f serviceaccount.yml
<span class="go">serviceaccount/app-admin created</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id10">
<div class="code-block-caption"><span class="caption-text">role.yml</span><a class="headerlink" href="#id10" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Role</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin-role</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">rules</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">apiGroups</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;*&quot;</span><span class="p p-Indicator">]</span>
    <span class="nt">resources</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;*&quot;</span><span class="p p-Indicator">]</span>
    <span class="nt">verbs</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;*&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f role.yml
<span class="go">role.rbac.authorization.k8s.io/app-admin-role created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Show the precofigured <em>clusterRole</em> named <em>view</em> which allows <em>view-only</em> access to all resources in the cluster.</p></li>
<li><p>Bind the role and the cluterrole to <em>serviceAccount</em> <em>app-admin</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get clusterrole view -o yaml
<span class="go">aggregationRule:</span>
<span class="go">  clusterRoleSelectors:</span>
<span class="go">  - matchLabels:</span>
<span class="go">      rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span>
<span class="go">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="go">kind: ClusterRole</span>
<span class="go">metadata:</span>
<span class="go">  annotations:</span>
<span class="go">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span>
<span class="go">  creationTimestamp: &quot;2023-12-14T13:44:54Z&quot;</span>
<span class="go">  labels:</span>
<span class="go">    kubernetes.io/bootstrapping: rbac-defaults</span>
<span class="go">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span>
<span class="go">  name: view</span>
<span class="go">  resourceVersion: &quot;291&quot;</span>
<span class="go">  uid: 29f1b8fe-42f7-40e4-bd67-9f12b3f0da18</span>
<span class="go">rules:</span>
<span class="go">- apiGroups:</span>
<span class="go">  - &quot;&quot;</span>
<span class="go">...</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id11">
<div class="code-block-caption"><span class="caption-text">rolebinding.yml</span><a class="headerlink" href="#id11" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">RoleBinding</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin-binding</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">roleRef</span><span class="p">:</span>
  <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Role</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin-role</span>
<span class="nt">subjects</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRoleBinding</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">view-all</span>
<span class="nt">roleRef</span><span class="p">:</span>
  <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRole</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">view</span>
<span class="nt">subjects</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f rolebinding.yml
<span class="go">rolebinding.rbac.authorization.k8s.io/admin-binding created</span>
<span class="go">clusterrolebinding.rbac.authorization.k8s.io/view-all created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the <em>kubectl</em> config file.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id12">
<div class="code-block-caption"><span class="caption-text">app-admin-token.yml</span><a class="headerlink" href="#id12" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin-token</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
  <span class="nt">annotations</span><span class="p">:</span>
     <span class="nt">kubernetes.io/service-account.name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app-admin</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes.io/service-account-token</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f app-admin-token.yml
<span class="go">secret/app-admin-token created</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id13">
<div class="code-block-caption"><span class="caption-text">create_config_file.sh</span><a class="headerlink" href="#id13" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1">#!/bin/bash</span>

<span class="l l-Scalar l-Scalar-Plain">clusterName=&#39;my-cluster&#39;</span>
<span class="l l-Scalar l-Scalar-Plain">server=&#39;https://10.10.10.51:6443&#39;</span>
<span class="l l-Scalar l-Scalar-Plain">serviceAccount=&#39;app-admin&#39;</span>
<span class="l l-Scalar l-Scalar-Plain">namespace=&#39;my-ns&#39;</span>
<span class="l l-Scalar l-Scalar-Plain">secretName=&#39;app-admin-token&#39;</span>
<span class="l l-Scalar l-Scalar-Plain">ca=$(kubectl --namespace=&quot;$namespace&quot; get secret/&quot;$secretName&quot; -o=jsonpath=&#39;{.data.ca\.crt}&#39;)</span>
<span class="l l-Scalar l-Scalar-Plain">token=$(kubectl --namespace=&quot;$namespace&quot; get secret/&quot;$secretName&quot; -o=jsonpath=&#39;{.data.token}&#39; | base64 --decode)</span>

<span class="l l-Scalar l-Scalar-Plain">echo &quot;</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Config</span>
<span class="nt">clusters</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${clusterName}</span>
    <span class="nt">cluster</span><span class="p">:</span>
      <span class="nt">certificate-authority-data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${ca}</span>
      <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${server}</span>
<span class="nt">contexts</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${serviceAccount}@${clusterName}</span>
    <span class="nt">context</span><span class="p">:</span>
      <span class="nt">cluster</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${clusterName}</span>
      <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${namespace}</span>
      <span class="nt">user</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${serviceAccount}</span>
<span class="nt">users</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${serviceAccount}</span>
    <span class="nt">user</span><span class="p">:</span>
      <span class="nt">token</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${token}</span>
<span class="nt">current-context</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${serviceAccount}@${clusterName}</span>
<span class="s">&quot;</span><span class="nv"> </span><span class="s">&gt;</span><span class="nv"> </span><span class="s">~/.kube/app-admin.conf</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> chmod +x ./create_config_file.sh
<span class="gp">root@admin-ws $&gt;</span> ./create_config_file.sh
<span class="gp">root@admin-ws $&gt;</span> cat ~/.kube/app-admin.conf

<span class="go">---</span>
<span class="go">apiVersion: v1</span>
<span class="go">kind: Config</span>
<span class="go">clusters:</span>
<span class="go">  - name: my-cluster</span>
<span class="go">    cluster:</span>
<span class="go">      certificate-authority-data: ...</span>
<span class="go">      server: https://10.10.10.51:6443</span>
<span class="go">contexts:</span>
<span class="go">  - name: app-admin@my-cluster</span>
<span class="go">    context:</span>
<span class="go">      cluster: my-cluster</span>
<span class="go">      namespace: my-ns</span>
<span class="go">      user: app-admin</span>
<span class="go">users:</span>
<span class="go">  - name: app-admin</span>
<span class="go">    user:</span>
<span class="go">      token: ...</span>
<span class="go">current-context: app-admin@my-cluster</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>Task 2:  Building the docker image<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span> /labfiles/k8s/Final_all-in-one/myapp/
<span class="gp">root@admin-ws $&gt;</span> cat Dockerfile
<span class="go">FROM python:3.9-slim-buster</span>
<span class="go">LABEL version v0.3</span>
<span class="go">LABEL maintained-by gabor@componentsoft.io</span>
<span class="go">RUN python -m pip install mysql-connector-python</span>
<span class="go">ENV DATA_FILE /course_data/course.csv</span>
<span class="go">ENV DATA_SOURCE file</span>
<span class="go">COPY myapp.py /</span>
<span class="go">COPY course_data /course_data</span>
<span class="go">CMD python3 /myapp.py</span>
<span class="go">EXPOSE 8080</span>
<span class="gp">root@admin-ws $&gt;</span> ls course_data/
<span class="go">course.csv  course2.csv</span>
<span class="gp">root@admin-ws $&gt;</span> docker build -t myapp .
<span class="go">ending build context to Docker daemon   7.68kB</span>
<span class="go">Step 1/10 : FROM python:3.9-slim-buster</span>
<span class="go">3.9-slim-buster: Pulling from library/python</span>
<span class="go">...</span>
<span class="go">Successfully tagged myapp:latest</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Login into local docker registry.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> docker login -u student service:5000
<span class="go">Password:</span><span class="gs">student123</span><span class="go"></span>
<span class="go">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span>
<span class="go">Configure a credential helper to remove this warning. See</span>
<span class="gp">https://docs.docker.com/engine/reference/commandline/login/#</span>credentials-store

<span class="go">Login Succeeded</span>
<span class="gp">root@admin-ws $&gt;</span> cat /root/.docker/config.json<span class="p">;</span><span class="nb">echo</span>
<span class="go">{</span>
<span class="go">      &quot;auths&quot;: {</span>
<span class="go">              &quot;service:5000&quot;: {</span>
<span class="go">                      &quot;auth&quot;: &quot;c3R1ZGVudDpzdHVkZW50MTIz&quot;</span>
<span class="go">              }</span>
<span class="go">      }</span>
<span class="go">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Push your image into the local registry.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> docker tag myapp:latest service:5000/myapp:latest
<span class="gp">root@admin-ws $&gt;</span> docker push service:5000/myapp
<span class="go">Using default tag: latest</span>
<span class="go">The push refers to repository [service:5000/myapp]</span>
<span class="go">197ad5be3374: Pushed</span>
<span class="go">...</span>
<span class="go">latest: digest: sha256:8a3a97b227ea87db1d01c504a0d8174978000dfae2b69220ea2f1afaedc1fbe3 size: 1996</span>
</pre></div>
</div>
</section>
<section id="id4">
<h3>Task 3:  Creating the deployment<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Use <em>app-admin</em> context to reduce rights on the cluster.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> <span class="nb">cd</span>
<span class="gp">root@admin-ws $&gt;</span> <span class="nb">export</span> <span class="nv">KUBECONFIG</span><span class="o">=</span>~/.kube/app-admin.conf
<span class="gp">root@admin-ws $&gt;</span> <span class="nb">echo</span> <span class="nb">export</span> <span class="nv">KUBECONFIG</span><span class="o">=</span>~/.kube/app-admin.conf &gt;&gt; ~/.bashrc
<span class="gp">root@admin-ws $&gt;</span> kubectl config get-contexts
<span class="go">CURRENT   NAME                   CLUSTER      AUTHINFO    NAMESPACE</span>
<span class="go">*         app-admin@my-cluster   my-cluster   app-admin   my-ns</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl auth can-i create deployments -n default
<span class="go">no</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl auth can-i create deployments -n my-ns
<span class="go">yes</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a secret in order to access the private registry</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create secret docker-registry registry-secret --docker-server<span class="o">=</span>service:5000 --docker-username<span class="o">=</span>student --docker-password<span class="o">=</span>student123
<span class="go">secret/registry-secret created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get secrets
<span class="go">NAME              TYPE                                  DATA   AGE</span>
<span class="go">app-admin-token   kubernetes.io/service-account-token   3      77m</span>
<span class="go">registry-secret   kubernetes.io/dockerconfigjson        1      2m7s</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you can access a docker login file, you can create secret from it</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl create secret generic registry-secret --from-file<span class="o">=</span>.dockerconfigjson<span class="o">=</span>/root/.docker/config.json --type<span class="o">=</span>kubernetes.io/dockerconfigjson
<span class="go">secret/registry-secret created</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>Create a deployment exposed by a ClusterIP service.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id14">
<div class="code-block-caption"><span class="caption-text">my-depl1.yml</span><a class="headerlink" href="#id14" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
<span class="hll">  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</span><span class="hll">    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
</span>  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="hll">  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
</span><span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
    <span class="nt">spec</span><span class="p">:</span>
<span class="hll">      <span class="nt">imagePullSecrets</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry-secret</span>
</span>      <span class="nt">containers</span><span class="p">:</span>
<span class="hll">      <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service:5000/myapp:latest</span>
</span><span class="hll">        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
</span><span class="hll">        <span class="nt">securityContext</span><span class="p">:</span>
</span><span class="hll">          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f my-depl1.yml
<span class="go">service/myapp-svc created</span>
<span class="go">deployment.apps/my-depl created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get po -n my-ns
<span class="go">NAME                       READY   STATUS    RESTARTS   AGE</span>
<span class="go">my-depl-54b747d469-j6dsn   1/1     Running   0          22s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get svc -n my-ns
<span class="go">NAME        TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="go">myapp-svc   ClusterIP   </span><span class="gs">10.99.246.21</span><span class="go">   &lt;none&gt;        80/TCP    118s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>From <strong>c-plane1</strong> check web-page on the <em>clusterIP</em> service.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@c-plane1 $&gt;</span> apt update <span class="o">&amp;&amp;</span> apt install -y links
<span class="go">&lt; output omitted &gt;</span>
<span class="gp">root@c-plane1 $&gt;</span> links <span class="m">10</span>.99.246.21

<span class="go">You can see the web-page.</span>

<span class="go">&lt; type Esc, Enter, and x to exit &gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Modify the deployment manifest file to use <em>liveness and readiness probes</em>.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id15">
<div class="code-block-caption"><span class="caption-text">my-depl2.yml</span><a class="headerlink" href="#id15" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">imagePullSecrets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry-secret</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service:5000/myapp:latest</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">securityContext</span><span class="p">:</span>
          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
<span class="hll">        <span class="nt">livenessProbe</span><span class="p">:</span>
</span><span class="hll">          <span class="nt">tcpSocket</span><span class="p">:</span>
</span><span class="hll">            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
</span><span class="hll">          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
</span><span class="hll">          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
</span><span class="hll">          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
</span><span class="hll">        <span class="nt">readinessProbe</span><span class="p">:</span>
</span><span class="hll">          <span class="nt">httpGet</span><span class="p">:</span>
</span><span class="hll">            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
</span><span class="hll">            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
</span><span class="hll">          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
</span><span class="hll">          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
</span><span class="hll">          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f my-depl2.yml
<span class="go">service/myapp-svc unchanged</span>
<span class="go">deployment.apps/my-depl configured</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n my-ns
<span class="go">NAME                       READY   STATUS        RESTARTS   AGE</span>
<span class="gs">my-depl-54b747d469-j6dsn   1/1     Terminating   0          36m</span><span class="go"></span>
<span class="go">my-depl-86b5cd667-kt2b2    1/1     Running       0          26s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n my-ns
<span class="go">NAME                      READY   STATUS    RESTARTS   AGE</span>
<span class="gs">my-depl-86b5cd667-kt2b2</span><span class="go">   1/1     Running   0          57s</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Customize your web-page using the <em>DATA_FILE</em> environment variable</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id16">
<div class="code-block-caption"><span class="caption-text">my-depl3.yml</span><a class="headerlink" href="#id16" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">imagePullSecrets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry-secret</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service:5000/myapp:latest</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">securityContext</span><span class="p">:</span>
          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
        <span class="nt">livenessProbe</span><span class="p">:</span>
          <span class="nt">tcpSocket</span><span class="p">:</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
        <span class="nt">readinessProbe</span><span class="p">:</span>
          <span class="nt">httpGet</span><span class="p">:</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="hll">        <span class="nt">env</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;DATA_FILE&quot;</span>
</span><span class="hll">          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;/course_data/course2.csv&quot;</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f my-depl3.yml
<span class="go">service/myapp-svc unchanged</span>
<span class="go">deployment.apps/my-depl configured</span>
</pre></div>
</div>
<p>Check new look of web-site on <em>c-plane1</em>.</p>
<ul class="simple">
<li><p>Create a <em>configmap</em> from course csv files and configure your deployment to use this configmap as <em>volume</em>.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id17">
<div class="code-block-caption"><span class="caption-text">course-data.yml</span><a class="headerlink" href="#id17" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-data</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="nt">course.csv</span><span class="p">:</span> <span class="p p-Indicator">|</span>
    <span class="no">Course Name,Course ID,Course Length,Course URL</span>
    <span class="no">Kubernetes Admin,KBS-103,3 days,&lt;a href=&quot;https://www.componentsoft.io/kbs-103-kubernetes-admin/&quot;&gt;https://www.componentsoft.io/kbs-103-kubernetes-admin/&lt;/a&gt;</span>
    <span class="no">Pyhton Intro,PTN-105,5 days,&lt;a href=&quot;https://www.componentsoft.io/ptn-105-python-programming/&quot;&gt;https://www.componentsoft.io/ptn-105-python-programming/&lt;/a&gt;</span>
    <span class="no">Docker,DCK-101,1 days,&lt;a href=&quot;https://www.componentsoft.io/dck-101-docker/&quot;&gt;https://www.componentsoft.io/dck-101-docker/&lt;/a&gt;</span>
    <span class="no">Openstack Admin,OST-104,4 day,&lt;a href=&quot;https://www.componentsoft.io/openstack-admin-coa-prep-ost-104/&quot;&gt;https://www.componentsoft.io/openstack-admin-coa-prep-ost-104/&lt;/a&gt;</span>
  <span class="nt">course2.csv</span><span class="p">:</span> <span class="p p-Indicator">|-</span>
    <span class="no">Course_Name,Course_ID,Course_Length</span>
    <span class="no">Kubernetes Intro,KBS-103,3 days</span>
    <span class="no">Kubernetes Combo,KBS-105,5 days</span>
    <span class="no">Docker,DCK-102,2 days</span>
    <span class="no">Helm,HLM-101,1 day</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f course-data.yml
<span class="go">configmap/course-data created</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id18">
<div class="code-block-caption"><span class="caption-text">my-depl4.yml</span><a class="headerlink" href="#id18" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">imagePullSecrets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry-secret</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service:5000/myapp:latest</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">securityContext</span><span class="p">:</span>
          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
        <span class="nt">livenessProbe</span><span class="p">:</span>
          <span class="nt">tcpSocket</span><span class="p">:</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
        <span class="nt">readinessProbe</span><span class="p">:</span>
          <span class="nt">httpGet</span><span class="p">:</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="hll">        <span class="nt">env</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;DATA_FILE&quot;</span>
</span><span class="hll">          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;/configmaps/course.csv&quot;</span>
</span><span class="hll">        <span class="nt">volumeMounts</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/configmaps</span>
</span><span class="hll">          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-files</span>
</span><span class="hll">      <span class="nt">volumes</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-files</span>
</span><span class="hll">          <span class="nt">configMap</span><span class="p">:</span>
</span><span class="hll">            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-data</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f my-depl4.yml
<span class="go">service/myapp-svc unchanged</span>
<span class="go">deployment.apps/my-depl configured</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n my-ns
<span class="go">NAME                       READY   STATUS        RESTARTS   AGE</span>
<span class="go">my-depl-686fc94ff7-tczgw   1/1     Terminating   0          9m7s</span>
<span class="go">my-depl-7ccbff5884-wr9bb   1/1     Running       0          24s</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n my-ns
<span class="go">NAME                       READY   STATUS    RESTARTS   AGE</span>
<span class="go">my-depl-7ccbff5884-wr9bb   1/1     Running   0          53s</span>
</pre></div>
</div>
<p>Check web-page with <em>links</em> on <em>c-plane1</em> node.</p>
</section>
<section id="task-4-expose-your-deployment-using-load-balancer-and-ingress">
<h3>Task 4:  Expose your deployment using <em>load-balancer</em> and <em>Ingress</em><a class="headerlink" href="#task-4-expose-your-deployment-using-load-balancer-and-ingress" title="Permalink to this headline"></a></h3>
<p>In this lab you need to configure external access to <em>myapp</em> webpage using <em>ingress</em>
and <em>load-balancer</em>.</p>
<ul class="simple">
<li><p>Check the load-balancer’s <strong>external IP address</strong>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get svc -n ingress-nginx
<span class="go">NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)                      AGE</span>
<span class="go">ingress-nginx-controller             </span><span class="gs">LoadBalancer</span><span class="go">   10.97.243.173    </span><span class="gs">10.10.10.110</span><span class="go">   80:32568/TCP,443:32381/TCP   4h24m</span>
<span class="go">ingress-nginx-controller-admission   ClusterIP      10.109.160.207   &lt;none&gt;         443/TCP                      4h24m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Configure an <em>ingress</em> resource points to your deployment’s <em>clusterIP</em> using <em>nip.io</em> wildcard DNS for <em>host</em> parameter.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id19">
<div class="code-block-caption"><span class="caption-text">ingress.yml</span><a class="headerlink" href="#id19" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ingress</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ingressClassName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
  <span class="nt">rules</span><span class="p">:</span>
<span class="hll">  <span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">www.10.10.10.110.nip.io</span>
</span>    <span class="nt">http</span><span class="p">:</span>
      <span class="nt">paths</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">backend</span><span class="p">:</span>
          <span class="nt">service</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
            <span class="nt">port</span><span class="p">:</span>
              <span class="nt">number</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
        <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
        <span class="nt">pathType</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Exact</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f ingress.yml
<span class="go">ingress.networking.k8s.io/my-ingress created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Check your webpage from outside of cluster.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> apt install -y links
<span class="go">&lt; output omitted &gt;</span>
<span class="gp">root@admin-ws $&gt;</span> links www.10.10.10.110.nip.io

<span class="go">You can see the web-page.</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>Task 5:  Configure network policy<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>Configure network policy in order to restrict access to <em>app</em> pod from <em>ingress controller pod</em> only.</p>
<ul class="simple">
<li><p>Show labels of your resources in order to use them at <em>selector</em>.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get po -n my-ns --show-labels
<span class="go">NAME                       READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="go">my-depl-7ccbff5884-wr9bb   1/1     Running   0          86m   </span><span class="gs">app=my-depl</span><span class="go">,pod-template-hash=7ccbff5884</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get po -n ingress-nginx --show-labels
<span class="go">NAME                                        READY   STATUS      RESTARTS   AGE     LABELS</span>
<span class="go">ingress-nginx-admission-create-c4zfs        0/1     Completed   0          4h37m   app.kubernetes.io/component=admission-webhook,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx,app.kubernetes.io/part-of=ingress-nginx,app.kubernetes.io/version=1.2.0,controller-uid=558e98bc-e4e8-44f6-b74e-054aa8efd196,job-name=ingress-nginx-admission-create</span>
<span class="go">ingress-nginx-admission-patch-dp5qg         0/1     Completed   0          4h37m   app.kubernetes.io/component=admission-webhook,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx,app.kubernetes.io/part-of=ingress-nginx,app.kubernetes.io/version=1.2.0,controller-uid=ff6a0f81-4bbe-43d1-94ad-1e2637f9b9ee,job-name=ingress-nginx-admission-patch</span>
<span class="gs">ingress-nginx-controller-79f766df89-ldp46</span><span class="go">   1/1     Running     0          4h37m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,</span><span class="gs">app.kubernetes.io/name=ingress-nginx</span><span class="go">,pod-template-hash=79f766df89</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get namespaces --show-labels
<span class="go">NAME                   STATUS   AGE     LABELS</span>
<span class="go">default                Active   28h     kubernetes.io/metadata.name=default</span>
<span class="gs">ingress-nginx</span><span class="go">          Active   4h47m   app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx,</span><span class="gs">kubernetes.io/metadata.name=ingress-nginx</span><span class="go"></span>
<span class="go">kube-node-lease        Active   28h     kubernetes.io/metadata.name=kube-node-lease</span>
<span class="go">kube-public            Active   28h     kubernetes.io/metadata.name=kube-public</span>
<span class="go">kube-system            Active   28h     kubernetes.io/metadata.name=kube-system</span>
<span class="go">kubernetes-dashboard   Active   28h     kubernetes.io/metadata.name=kubernetes-dashboard</span>
<span class="go">metallb-system         Active   4h49m   kubernetes.io/metadata.name=metallb-system,pod-security.kubernetes.io/audit=privileged,pod-security.kubernetes.io/enforce=privileged,pod-security.kubernetes.io/warn=privileged</span>
<span class="go">my-ns                  Active   23h     kubernetes.io/metadata.name=my-ns</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a <em>network policy</em> using the <em>pods</em> and the <em>ingress controller’s namespace</em> labels.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id20">
<div class="code-block-caption"><span class="caption-text">network-policy.yml</span><a class="headerlink" href="#id20" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NetworkPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-netpolicy</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="hll">  <span class="nt">podSelector</span><span class="p">:</span>
</span><span class="hll">    <span class="nt">matchLabels</span><span class="p">:</span>
</span><span class="hll">      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
</span>  <span class="nt">policyTypes</span><span class="p">:</span> 
<span class="hll">    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
</span>  <span class="nt">ingress</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">from</span><span class="p">:</span>
<span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">namespaceSelector</span><span class="p">:</span>
</span>            <span class="nt">matchLabels</span><span class="p">:</span> 
<span class="hll">              <span class="nt">kubernetes.io/metadata.name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ingress-nginx</span>
</span><span class="hll">          <span class="nt">podSelector</span><span class="p">:</span>
</span>            <span class="nt">matchLabels</span><span class="p">:</span>
<span class="hll">              <span class="nt">app.kubernetes.io/name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ingress-nginx</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f network-policy.yml
<span class="go">networkpolicy.networking.k8s.io/my-netpolicy created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Try to access your <em>application pod</em> from a pod other than the <em>ingress controller</em> pod.</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl get po -n my-ns -o wide
<span class="go">NAME                       READY   STATUS    RESTARTS   AGE    IP                NODE      NOMINATED NODE   READINESS GATES</span>
<span class="go">my-depl-7ccbff5884-wr9bb   1/1     Running   0          104m   </span><span class="gs">192.168.235.136</span><span class="go">   worker1   &lt;none&gt;           &lt;none&gt;</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl run --image<span class="o">=</span>alpine <span class="nb">test</span> -- sleep <span class="m">1200</span>
<span class="go">pod/test created</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -ti -n my-ns <span class="nb">test</span> -- sh
<span class="gp">$&gt;</span> nc <span class="m">192</span>.168.235.136 <span class="m">8080</span>
<span class="gs">GET / HTTP</span><span class="go"></span>

<span class="go">&lt; no answer &gt;</span>

<span class="go">&lt; press Ctrl+C &gt;</span>
<span class="gp">$&gt;</span> <span class="nb">exit</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl delete pod <span class="nb">test</span>
<span class="go">pod &quot;test&quot; deleted</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>Task 6:  Using PVC<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Create a PVC using the <em>smb</em> storageclass</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id21">
<div class="code-block-caption"><span class="caption-text">pvc.yml</span><a class="headerlink" href="#id21" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-pvc</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="nt">resources</span><span class="p">:</span>
    <span class="nt">requests</span><span class="p">:</span>
      <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10Mi</span>
  <span class="nt">storageClassName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smb</span>
</pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f pvc.yml
<span class="go">persistentvolumeclaim/my-pvc created</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use an <em>initcontainer</em> to copy the files from <em>configmap</em> to the <em>PV</em>. Modify the <em>DATA_FILE</em> environment variable to reference the file on the <em>PV</em>.</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id22">
<div class="code-block-caption"><span class="caption-text">my-depl5.yml</span><a class="headerlink" href="#id22" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-svc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-ns</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-depl</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">imagePullSecrets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry-secret</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service:5000/myapp:latest</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">securityContext</span><span class="p">:</span>
          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
        <span class="nt">livenessProbe</span><span class="p">:</span>
          <span class="nt">tcpSocket</span><span class="p">:</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
        <span class="nt">readinessProbe</span><span class="p">:</span>
          <span class="nt">httpGet</span><span class="p">:</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
            <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
          <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
          <span class="nt">periodSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
          <span class="nt">failureThreshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="hll">        <span class="nt">env</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;DATA_FILE&quot;</span>
</span><span class="hll">          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;/csv_files/course.csv&quot;</span>
</span>        <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/configmaps</span>
          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-files</span>
<span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/csv_files</span>
</span><span class="hll">          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">csv-files</span>
</span>      <span class="nt">volumes</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-files</span>
          <span class="nt">configMap</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-data</span>
<span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">csv-files</span> 
</span><span class="hll">          <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
</span><span class="hll">            <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-pvc</span>
</span><span class="hll">      <span class="nt">initContainers</span><span class="p">:</span>
</span><span class="hll">      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">copy-data</span>
</span><span class="hll">        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">alpine</span>
</span><span class="hll">        <span class="nt">securityContext</span><span class="p">:</span>
</span><span class="hll">          <span class="nt">runAsUser</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1001</span>
</span><span class="hll">        <span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;sh&quot;</span><span class="p p-Indicator">,</span><span class="s">&quot;-c&quot;</span><span class="p p-Indicator">,</span><span class="s">&quot;for</span><span class="nv"> </span><span class="s">f</span><span class="nv"> </span><span class="s">in</span><span class="nv"> </span><span class="s">`ls</span><span class="nv"> </span><span class="s">-1</span><span class="nv"> </span><span class="s">/configmaps`;do</span><span class="nv"> </span><span class="s">test</span><span class="nv"> </span><span class="s">-f</span><span class="nv"> </span><span class="s">/csv_files/$f</span><span class="nv"> </span><span class="s">||cp</span><span class="nv"> </span><span class="s">/configmaps/$f</span><span class="nv"> </span><span class="s">/csv_files/;done&quot;</span><span class="p p-Indicator">]</span>
</span><span class="hll">        <span class="nt">volumeMounts</span><span class="p">:</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/configmaps</span>
</span><span class="hll">          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">course-files</span>
</span><span class="hll">        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/csv_files</span>
</span><span class="hll">          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">csv-files</span>
</span></pre></div>
</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">root@admin-ws $&gt;</span> kubectl apply -f my-depl5.yml
<span class="go">service/myapp-svc unchanged</span>
<span class="go">deployment.apps/my-depl configured</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl get pod -n my-ns
<span class="go">NAME                       READY   STATUS    RESTARTS   AGE</span>
<span class="go">my-depl-5cc6747bcb-tmqjj   1/1     Running   0          25m</span>
<span class="gp">root@admin-ws $&gt;</span> kubectl <span class="nb">exec</span> -n my-ns my-depl-5cc6747bcb-tmqjj -- ls /csv_files
<span class="go">Defaulted container &quot;myapp&quot; out of: myapp, copy-data (init)</span>
<span class="go">course.csv</span>
<span class="go">course2.csv</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024Component Soft Ltd..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
